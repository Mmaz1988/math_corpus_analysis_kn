{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55abc806-08ba-4dbe-9554-a12a5d64218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02ce20f0-9c8c-41d5-b483-8016e4fd5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'gr3.tex'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "content_listed = list(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "508f386c-d23e-461e-b135-25acc7e65fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['% Chapter 1, Section 3 _Linear Algebra_ Jim Hefferon\\n', '%  http://joshua.smcvt.edu/linearalgebra\\n', '%  2001-Jun-09\\n', '\\\\section{Reduced Echelon Form}\\n', \"After developing the mechanics of Gauss's Method, \\n\", 'we observed that it can be done in more than one way.\\n', 'For example, from this matrix \\n', '\\\\begin{equation*}\\n', '    \\\\begin{mat}[r]\\n', '       2  &2  \\\\\\\\\\n', '       4  &3\\n', '    \\\\end{mat}\\n', '\\\\end{equation*}\\n', 'we could derive any of these three echelon form matrices.\\n', '\\\\begin{equation*}\\n', '    \\\\begin{mat}[r]\\n', '       2  &2  \\\\\\\\\\n', '       0  &-1\\n', '    \\\\end{mat}\\n', '    \\\\qquad\\n', '    \\\\begin{mat}[r]\\n', '       1  &1  \\\\\\\\\\n', '       0  &-1\\n', '    \\\\end{mat}\\n', '    \\\\qquad\\n', '    \\\\begin{mat}[r]\\n', '       2  &0  \\\\\\\\\\n', '       0  &-1\\n', '    \\\\end{mat}\\n', '\\\\end{equation*}\\n', 'The first results from $-2\\\\rho_1+\\\\rho_2$.\\n', 'The second comes from doing $(1/2)\\\\rho_1$ and then $-4\\\\rho_1+\\\\rho_2$.\\n', 'The third comes\\n', 'from $-2\\\\rho_1+\\\\rho_2$ followed by $2\\\\rho_2+\\\\rho_1$\\n', '(after the first row combination the matrix is already in\\n', 'echelon form \\n', 'but it is nonetheless a legal row operation).\\n', '\\n', \"In this chapter's first section we noted that\\n\", 'this raises questions.\\n', 'Will any two echelon form versions of a linear system have the same number of\\n', 'free variables?\\n', 'If yes, \\n', 'will the two have exactly the same free variables?\\n', 'In this section we will \\n', 'give a way to decide if one linear system \\n', 'can be derived from another by row operations.\\n', \"The answers to both questions, both ``yes,''\\n\", 'will follow from that.\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\\\subsection{Gauss-Jordan Reduction}%\\n', '% Gaussian elimination coupled with back-substitution\\n', '% solves linear systems but it is not the only method possible.\\n', \"Here is an extension of Gauss's Method that has some advantages.\\n\", '\\n', '\\\\begin{example} \\\\label{exm:GJRedReadOffSol}\\n', 'To solve\\n', '\\\\begin{equation*}\\n', '  \\\\begin{linsys}{3}\\n', '    x  &+  &y  &-  &2z  &=  &-2  \\\\\\\\\\n', '       &   &y  &+  &3z  &=  &7   \\\\\\\\\\n', '    x  &   &   &-  &z   &=  &-1  \\n', '  \\\\end{linsys}\\n', '\\\\end{equation*}\\n', 'we can start as usual by reducing it to echelon form.\\n', '\\\\begin{equation*}\\n', '  \\\\grstep{-\\\\rho_1+\\\\rho_3}\\n', '    \\\\begin{amat}[r]{3}\\n', '       1  &1  &-2 &-2  \\\\\\\\\\n', '       0  &1  &3  &7   \\\\\\\\\\n', '       0  &-1 &1  &1\\n', '    \\\\end{amat}\\n', '  \\\\grstep{\\\\rho_2+\\\\rho_3}\\n', '    \\\\begin{amat}[r]{3}\\n', '       1  &1  &-2 &-2  \\\\\\\\\\n', '       0  &1  &3  &7   \\\\\\\\\\n', '       0  &0  &4  &8\\n', '    \\\\end{amat}\\n', '\\\\end{equation*}\\n', 'We can keep going to a second stage\\n', \"by making the leading entries into \\\\( 1 \\\\)'s\\n\", '\\\\begin{equation*}\\n', '    \\\\grstep{(1/4)\\\\rho_3}\\n', '    \\\\begin{amat}[r]{3}\\n', '       1  &1  &-2 &-2  \\\\\\\\\\n', '       0  &1  &3  &7   \\\\\\\\\\n', '       0  &0  &1  &2\\n', '    \\\\end{amat}\\n', '\\\\end{equation*}\\n', 'and then to a third stage that uses the leading entries \\n', 'to eliminate all of the other entries in each column \\n', 'by combining upwards.\\n', '\\\\begin{equation*}\\n', '  \\\\grstep[2\\\\rho_3+\\\\rho_1]{-3\\\\rho_3+\\\\rho_2}\\n', '    \\\\begin{amat}[r]{3}\\n', '       1  &1  &0  &2   \\\\\\\\\\n', '       0  &1  &0  &1   \\\\\\\\\\n', '       0  &0  &1  &2\\n', '    \\\\end{amat}\\n', '  \\\\grstep{-\\\\rho_2+\\\\rho_1}\\n', '    \\\\begin{amat}[r]{3}\\n', '       1  &0  &0  &1   \\\\\\\\\\n', '       0  &1  &0  &1   \\\\\\\\\\n', '       0  &0  &1  &2\\n', '    \\\\end{amat}\\n', '\\\\end{equation*}\\n', 'The answer is \\\\( x=1 \\\\), \\\\( y=1 \\\\), and \\\\( z=2 \\\\).\\n', '\\\\end{example}\\n', '%<*Pivoting>\\n', 'Using one entry to clear out the rest of a column is\\n', '\\\\definend{pivoting}\\\\index{pivoting} on that entry.\\n', '%</Pivoting>\\n', '\\n', 'Notice that the row combination operations in the first stage move \\n', 'left to right \\n', 'while the combination operations in the third stage move right to left.\\n', '\\n', '\\\\begin{example}  \\\\label{exm:GJRedReadOffSolTwo}\\n', 'The middle stage operations that \\n', \"turn the leading entries into \\\\( 1 \\\\)'s\\n\", \"don't interact so we can combine multiple ones into a single step.\\n\", '\\\\begin{align*}\\n', '    \\\\begin{amat}[r]{2}\\n', '       2   &1   &7   \\\\\\\\\\n', '       4   &-2  &6\\n', '    \\\\end{amat}\\n', '  &\\\\grstep{-2\\\\rho_1+\\\\rho_2}\\n', '  \\\\begin{amat}[r]{2}\\n', '       2   &1   &7   \\\\\\\\\\n', '       0   &-4  &-8\\n', '    \\\\end{amat}                                   \\\\\\\\\\n', '  &\\\\grstep[(-1/4)\\\\rho_2]{(1/2)\\\\rho_1}\\n', '  \\\\begin{amat}[r]{2}\\n', '       1   &1/2   &7/2   \\\\\\\\\\n', '       0   &1     &2\\n', '    \\\\end{amat}                                    \\\\\\\\\\n', '  &\\\\grstep{-(1/2)\\\\rho_2+\\\\rho_1}\\n', '  \\\\begin{amat}[r]{2}\\n', '       1   &0   &5/2   \\\\\\\\\\n', '       0   &1   &2\\n', '    \\\\end{amat}\\n', '\\\\end{align*}\\n', 'The answer is $x=5/2$ and $y=2$.\\n', '\\\\end{example}\\n', '\\n', '%<*GaussJordanReduction>\\n', \"This extension of Gauss's Method is the \\n\", \"\\\\definend{Gauss-Jordan Method}\\\\index{Gauss's Method!Gauss-Jordan Method} or \\n\", \"\\\\definend{Gauss-Jordan reduction}.\\\\index{linear equation!solution of!Gauss-Jordan}\\\\index{Gauss's Method!Gauss-Jordan}\\n\", '%</GaussJordanReduction>\\n', '% It goes past echelon form to a more refined, more specialized,\\n', '% matrix form.\\n', '\\n', '\\\\begin{definition}\\\\label{def:RedEchForm}\\n', '%<*df:RedEchForm>\\n', 'A matrix or linear system is in\\n', '\\\\definend{reduced echelon form\\\\/}\\\\index{echelon form!reduced}\\\\index{reduced echelon form}\\n', 'if, in addition to being in echelon form, each leading entry is a~$1$ \\n', 'and is the only nonzero entry in its column.\\n', '%</df:RedEchForm>\\n', '\\\\end{definition}\\n', '\\n', '\\\\noindent\\n', '%<*CostRedEchForm>\\n', 'The cost of using Gauss-Jordan reduction to solve a system \\n', 'is the additional arithmetic.\\n', 'The benefit is that we can just read off the solution set\\n', 'description.\\n', '%</CostRedEchForm>\\n', '\\n', 'In any echelon form system, reduced or not, we can read off \\n', 'when the system has an empty\\n', 'solution set because there is a contradictory equation.\\n', 'We can read off \\n', 'when the system has a one-element solution set because there is no\\n', 'contradiction and every\\n', 'variable is the leading variable in some row.\\n', 'And, we can read off when the system has an infinite solution set because \\n', 'there is no contradiction and at least one variable is free.\\n', '\\n', 'However, in reduced echelon form we can read off not just the size of the  \\n', 'solution set but also its description.\\n', 'We have no trouble describing the solution set when it is empty, of course.\\n', '\\\\nearbyexample{exm:GJRedReadOffSol} and~\\\\ref{exm:GJRedReadOffSolTwo} \\n', 'show how in a single element solution set case the single element is\\n', 'in the column of constants.\\n', 'The next example shows how to read the parametrization\\n', 'of an infinite solution set.\\n', '\\n', '\\\\begin{example}\\n', '\\\\begin{multline*}\\n', '  \\\\begin{amat}[r]{4}\\n', '     2  &6  &1  &2  &5  \\\\\\\\\\n', '     0  &3  &1  &4  &1  \\\\\\\\\\n', '     0  &3  &1  &2  &5\\n', '  \\\\end{amat}\\n', '  \\\\grstep{-\\\\rho_2+\\\\rho_3}\\n', '  \\\\begin{amat}[r]{4}\\n', '     2  &6  &1  &2  &5  \\\\\\\\\\n', '     0  &3  &1  &4  &1  \\\\\\\\\\n', '     0  &0  &0  &-2 &4\\n', '  \\\\end{amat}                                        \\\\\\\\\\n', '  \\\\grstep[(1/3)\\\\rho_2 \\\\\\\\ -(1/2)\\\\rho_3]{(1/2)\\\\rho_1}\\n', '  \\\\repeatedgrstep[-\\\\rho_3+\\\\rho_1]{-(4/3)\\\\rho_3+\\\\rho_2}\\n', '  \\\\repeatedgrstep{-3\\\\rho_2+\\\\rho_1}\\n', '  \\\\begin{amat}[r]{4}\\n', '     1  &0  &-1/2  &0  &-9/2  \\\\\\\\\\n', '     0  &1  &1/3   &0  &3  \\\\\\\\\\n', '     0  &0  &0     &1  &-2\\n', '  \\\\end{amat}\\n', '\\\\end{multline*}\\n', 'As a linear system this is \\n', '\\\\begin{equation*}\\n', '  \\\\begin{linsys}{4}\\n', '     x_1  &&     &-&1/2x_3  &&   &= &-9/2  \\\\\\\\\\n', '          &&x_2  &+&1/3x_3  &&   &= &3  \\\\\\\\\\n', '          &&     &&        &{}\\\\hspace{.5em}{}&x_4 &= &-2    \\n', '  \\\\end{linsys}\\n', '\\\\end{equation*}\\n', 'so a solution set description is this.\\n', '\\\\begin{equation*}  \\n', '  S=\\\\set{\\\\colvec{x_1 \\\\\\\\ x_2 \\\\\\\\ x_3 \\\\\\\\ x_4}\\n', '                        =\\\\colvec[r]{-9/2 \\\\\\\\ 3 \\\\\\\\ 0 \\\\\\\\ -2}\\n', '                         +\\\\colvec[r]{1/2 \\\\\\\\ -1/3 \\\\\\\\ 1 \\\\\\\\ 0}x_3\\n', '                        \\\\suchthat x_3\\\\in\\\\Re}\\n', '\\\\end{equation*}\\n', '\\\\end{example}\\n', '\\n', \"Thus, echelon form isn't some kind of one best form for systems.\\n\", 'Other forms, such as reduced echelon form, have advantages and\\n', 'disadvantages.\\n', 'Instead of picturing linear systems (and the associated matrices) \\n', 'as things we operate on, \\n', 'always directed toward the goal of echelon form, we can think of \\n', 'them as interrelated, where\\n', 'we can get from one to another by row operations.\\n', 'The rest of this subsection develops this thought.\\n', '\\n', '\\\\begin{lemma} \\\\label{le:RowOpsRev}\\n', '%<*lm:RowOpsRev>\\n', 'Elementary row operations are reversible.\\n', '%</lm:RowOpsRev>\\n', '\\\\end{lemma}\\n', '\\n', '\\\\begin{proof}\\n', '%<*pf:RowOpsRev>\\n', 'For any matrix \\\\( A \\\\),\\n', 'the effect of swapping rows is reversed by swapping them back,\\n', 'multiplying a row by a nonzero \\\\( k \\\\) is undone by multiplying by\\n', '$1/k$,\\n', 'and adding a multiple of row \\\\( i \\\\) to row \\\\( j \\\\) (with $i\\\\neq j$)\\n', 'is undone by subtracting the same multiple of row \\\\( i \\\\) from row \\\\( j \\\\).\\n', '\\\\begin{equation*}\\n', '      A\\n', '     \\\\grstep{\\\\rho_i\\\\leftrightarrow\\\\rho_j}\\n', '     \\\\repeatedgrstep{\\\\rho_j\\\\leftrightarrow\\\\rho_i}\\n', '      A\\n', '  \\\\qquad\\n', '        A\\n', '     \\\\grstep{k\\\\rho_i}\\n', '     \\\\repeatedgrstep{(1/k)\\\\rho_i}\\n', '      A\\n', '  \\\\qquad\\n', '        A\\n', '     \\\\grstep{k\\\\rho_i+\\\\rho_j}\\n', '     \\\\repeatedgrstep{-k\\\\rho_i+\\\\rho_j}\\n', '      A                          \\n', '\\\\end{equation*}\\n', '%</pf:RowOpsRev>\\n', '(We need the $i\\\\neq j$ condition;\\n', 'see \\\\nearbyexercise{exer:INotJMakesRowOpsRev}.)\\n', '\\\\end{proof}\\n', '\\n', 'Again, the point of view that we are developing, supported now by the lemma,\\n', \"is that the term `reduces to' is misleading:~where\\n\", \"\\\\( A\\\\longrightarrow B \\\\), we shouldn't think of \\\\( B \\\\) as\\n\", 'after~\\\\( A \\\\) or simpler than~$A$.\\n', 'Instead we should think of the two matrices as interrelated.\\n', 'Below is a picture.\\n', 'It shows the matrices from the start of this section and their\\n', 'reduced echelon form version in a cluster, as\\n', 'interreducible. \\n', '\\\\begin{center}  \\n', '  \\\\includegraphics{gr/mp/ch1.28}\\n', '\\\\end{center}\\n', '\\n', '%<*EquivMatrices>\\n', 'We say \\n', 'that matrices that reduce to each other are equivalent with respect\\n', 'to the relationship of row reducibility.\\n', 'The next result justifies this, using the definition of \\n', 'an equivalence.\\\\appendrefs{equivalence relations}\\n', '%</EquivMatrices>\\n', '\\n', '\\\\begin{lemma} \\\\label{lm:ReducesToIsEqRel}\\n', '%<*lm:ReducesToIsEqRel>\\n', \"Between matrices, `reduces to' is an equivalence re\\\\-la\\\\-tion.\\n\", '%</lm:ReducesToIsEqRel>\\n', '\\\\end{lemma}\\n', '\\n', '\\\\begin{proof}\\n', '%<*pf:ReducesToIsEqRel0>\\n', 'We must check the conditions\\n', '(i)~reflexivity, that any matrix reduces to itself,\\n', '(ii)~symmetry, that if \\\\( A \\\\) reduces to \\\\( B \\\\) then\\n', '   \\\\( B \\\\) reduces to \\\\( A \\\\),\\n', 'and (iii)~transitivity, that if \\\\( A \\\\) reduces to \\\\( B \\\\) and\\n', '      \\\\( B \\\\) reduces to \\\\( C \\\\) then \\\\( A \\\\) reduces to\\n', '      \\\\( C \\\\).\\n', '%</pf:ReducesToIsEqRel0>\\n', '\\n', '%<*pf:ReducesToIsEqRel1>\\n', 'Reflexivity is easy; any  matrix reduces to itself in zero-many operations.\\n', '\\n', 'The relationship is symmetric by the prior lemma\\\\Dash if\\n', '\\\\( A \\\\) reduces to \\\\( B \\\\) by some row operations\\n', 'then also \\\\( B \\\\) reduces to \\\\( A \\\\) by reversing those operations.\\n', '%</pf:ReducesToIsEqRel1>\\n', '\\n', '%<*pf:ReducesToIsEqRel2>\\n', 'For transitivity, suppose that \\\\( A \\\\) reduces to \\\\( B \\\\) and\\n', 'that \\\\( B \\\\) reduces to \\\\( C \\\\).\\n', 'Following the reduction steps from $A \\\\rightarrow\\\\cdots\\\\rightarrow B$\\n', 'with those from  $B \\\\rightarrow\\\\cdots\\\\rightarrow C$ \\n', 'gives a reduction from \\\\( A \\\\) to \\\\( C \\\\).\\n', '%</pf:ReducesToIsEqRel2>\\n', '\\\\end{proof}\\n', '\\n', '\\\\begin{definition} \\\\label{df:RowEquivalence}\\n', '%<*df:RowEquivalence>\\n', 'Two matrices that are interreducible by elementary row operations\\n', 'are \\\\definend{row equivalent}.\\\\index{matrix!row equivalence}%\\n', '\\\\index{row equivalence}\\\\index{equivalence relation!row equivalence}\\n', '%</df:RowEquivalence>\\n', '\\\\end{definition}\\n', '\\n', '%<*RowEquivalanceClasses>\\n', 'The diagram below shows the collection of all matrices as a box.\\n', 'Inside that box each matrix lies in a class.\\n', 'Matrices are in the same class if and only if they are interreducible.\\n', 'The classes are disjoint\\\\Dash no matrix is in two distinct classes.\\n', 'We have partitioned the collection of matrices into \\n', '\\\\definend{row equivalence classes}.\\\\appendrefs{partitions and class representatives}\\\\index{partition!row equivalence classes}\\n', '%</RowEquivalanceClasses>\\n', '\\\\begin{center}\\n', '  \\\\includegraphics{gr/mp/ch1.27}\\n', '\\\\end{center}\\n', '\\\\noindent One of the classes is the\\n', 'cluster of interrelated \\n', 'matrices from the start of this section sketched above\\n', '(it includes all of the nonsingular $\\\\nbyn{2}$ matrices). \\n', '\\n', 'The next subsection proves that the reduced echelon form of a matrix is \\n', 'unique.\\n', 'Rephrased in terms of the row-equivalence relationship, \\n', 'we shall prove that every matrix is \\n', 'row equivalent to one and only one reduced echelon form matrix.\\n', 'In terms of the partition what we shall prove is:~every\\n', 'equivalence class contains one and only one reduced echelon form matrix.\\n', 'So each reduced echelon form matrix serves as a representative of its \\n', 'class.\\n', '\\n', '\\\\begin{exercises}\\n', '   \\\\recommended \\\\item \\n', '     Use Gauss-Jordan reduction to solve each system.\\n', '     \\\\begin{exparts*}\\n', '        \\\\partsitem \\\\(\\n', '          \\\\begin{linsys}[t]{2}\\n', '               x  &+  &y  &=  &2  \\\\\\\\\\n', '               x  &-  &y  &=  &0  \\n', '          \\\\end{linsys}   \\\\)\\n', '        \\\\partsitem \\\\(\\n', '          \\\\begin{linsys}[t]{3}\\n', '               x  &   &   &-  &z  &=  &4  \\\\\\\\\\n', '              2x  &+  &2y &   &   &=  &1  \\n', '          \\\\end{linsys}  \\\\)\\n', '        \\\\partsitem  \\\\(\\n', '           \\\\begin{linsys}[t]{2}\\n', '               3x  &-  &2y  &=  &1  \\\\\\\\\\n', '               6x  &+  &y   &=  &1/2 \\n', '           \\\\end{linsys}  \\\\)\\n', '        \\\\partsitem \\\\(\\n', '           \\\\begin{linsys}[t]{3}\\n', '              2x  &-  &y  &  &  &= &-1  \\\\\\\\\\n', '               x  &+  &3y &- &z &= &5   \\\\\\\\\\n', '                  &   &y  &+ &2z&= &5   \\n', '           \\\\end{linsys} \\\\)\\n', '     \\\\end{exparts*}\\n', '     \\\\begin{answer}\\n', '       These answers show only the Gauss-Jordan reduction.\\n', '       With it, describing the solution set is easy. \\n', '       \\\\begin{exparts}\\n', '         \\\\partsitem The solution set contains only a single element.\\n', '           \\\\begin{multline*}\\n', '             \\\\begin{amat}[r]{2}\\n', '               1  &1  &2  \\\\\\\\\\n', '               1  &-1 &0\\n', '             \\\\end{amat}\\n', '             \\\\grstep{-\\\\rho_1+\\\\rho_2}\\n', '             \\\\begin{amat}[r]{2}\\n', '               1  &1  &2  \\\\\\\\\\n', '               0  &-2 &-2\\n', '             \\\\end{amat}                          \\\\\\\\                       \\n', '             \\\\grstep{-(1/2)\\\\rho_2}\\n', '             \\\\begin{amat}[r]{2}\\n', '               1  &1  &2  \\\\\\\\\\n', '               0  &1  &1\\n', '             \\\\end{amat}                         \\n', '             \\\\grstep{-\\\\rho_2+\\\\rho_1}\\n', '             \\\\begin{amat}[r]{2}\\n', '               1  &0  &1  \\\\\\\\\\n', '               0  &1  &1\\n', '             \\\\end{amat}\\n', '           \\\\end{multline*}\\n', '         \\\\partsitem The solution set has one parameter.\\n', '            \\\\begin{equation*}\\n', '             \\\\begin{amat}[r]{3}\\n', '               1  &0  &-1  &4  \\\\\\\\\\n', '               2  &2  &0   &1\\n', '             \\\\end{amat}\\n', '             \\\\grstep{-2\\\\rho_1+\\\\rho_2}\\n', '             \\\\begin{amat}[r]{3}\\n', '               1  &0  &-1  &4  \\\\\\\\\\n', '               0  &2  &2   &-7\\n', '             \\\\end{amat}                    \\n', '             \\\\grstep{(1/2)\\\\rho_2}\\n', '             \\\\begin{amat}[r]{3}\\n', '               1  &0  &-1  &4  \\\\\\\\\\n', '               0  &1  &1   &-7/2\\n', '             \\\\end{amat}\\n', '           \\\\end{equation*}\\n', '         \\\\partsitem There is a unique solution.\\n', '           \\\\begin{multline*}\\n', '             \\\\begin{amat}[r]{2}\\n', '               3  &-2  &1  \\\\\\\\\\n', '               6  &1   &1/2\\n', '             \\\\end{amat}\\n', '             \\\\grstep{-2\\\\rho_1+\\\\rho_2}\\n', '             \\\\begin{amat}[r]{2}\\n', '               3  &-2  &1  \\\\\\\\\\n', '               0  &5   &-3/2\\n', '             \\\\end{amat}                            \\\\\\\\                       \\n', '             \\\\grstep[(1/5)\\\\rho_2]{(1/3)\\\\rho_1}\\n', '             \\\\begin{amat}[r]{2}\\n', '               1  &-2/3&1/3 \\\\\\\\\\n', '               0  &1   &-3/10\\n', '             \\\\end{amat}                       \\n', '             \\\\grstep{(2/3)\\\\rho_2+\\\\rho_1}\\n', '             \\\\begin{amat}[r]{2}\\n', '               1  &0   &2/15 \\\\\\\\\\n', '               0  &1   &-3/10\\n', '             \\\\end{amat}\\n', '          \\\\end{multline*}\\n', '        \\\\partsitem A row swap in the second step makes the arithmetic easier.\\n', '         \\\\begin{multline*}\\n', '          \\\\begin{amat}[r]{3}\\n', '            2  &-1  &0  &-1  \\\\\\\\\\n', '            1  &3   &-1 &5   \\\\\\\\\\n', '            0  &1   &2  &5\\n', '          \\\\end{amat}\\n', '          \\\\grstep{-(1/2)\\\\rho_1+\\\\rho_2}\\n', '          \\\\begin{amat}[r]{3}\\n', '            2  &-1  &0  &-1   \\\\\\\\\\n', '            0  &7/2 &-1 &11/2 \\\\\\\\\\n', '            0  &1   &2  &5\\n', '          \\\\end{amat}                                \\\\\\\\\\n', '          \\\\begin{aligned}\\n', '          &\\\\grstep{\\\\rho_2\\\\leftrightarrow\\\\rho_3}\\n', '          \\\\begin{amat}[r]{3}\\n', '            2  &-1  &0  &-1   \\\\\\\\\\n', '            0  &1   &2  &5    \\\\\\\\\\n', '            0  &7/2 &-1 &11/2\\n', '          \\\\end{amat}                      \\n', '            \\\\grstep{-(7/2)\\\\rho_2+\\\\rho_3}\\n', '            \\\\begin{amat}[r]{3}\\n', '              2  &-1  &0  &-1   \\\\\\\\\\n', '              0  &1   &2  &5    \\\\\\\\\\n', '              0  &0   &-8 &-12\\n', '            \\\\end{amat}                               \\\\\\\\     \\n', '            &\\\\grstep[-(1/8)\\\\rho_2]{(1/2)\\\\rho_1}\\n', '            \\\\begin{amat}[r]{3}\\n', '              1  &-1/2&0  &-1/2 \\\\\\\\\\n', '              0  &1   &2  &5    \\\\\\\\\\n', '              0  &0   &1  &3/2\\n', '            \\\\end{amat}                                \\n', '            \\\\grstep{-2\\\\rho_3+\\\\rho_2}\\n', '            \\\\begin{amat}[r]{3}\\n', '              1  &-1/2&0  &-1/2 \\\\\\\\\\n', '              0  &1   &0  &2    \\\\\\\\\\n', '              0  &0   &1  &3/2\\n', '            \\\\end{amat}                                    \\\\\\\\             \\n', '            &\\\\grstep{(1/2)\\\\rho_2+\\\\rho_1}\\n', '            \\\\begin{amat}[r]{3}\\n', '              1  &0   &0  &1/2  \\\\\\\\\\n', '              0  &1   &0  &2    \\\\\\\\\\n', '              0  &0   &1  &3/2\\n', '            \\\\end{amat}\\n', '          \\\\end{aligned}\\n', '        \\\\end{multline*}\\n', '       \\\\end{exparts}  \\n', '     \\\\end{answer}\\n', '  \\\\item Do Gauss-Jordan reduction.\\n', '    \\\\begin{exparts*}\\n', '      \\\\partsitem\\n', '        $\\\\begin{linsys}[t]{3}\\n', '          x  &+ &y &- &z &= &3 \\\\\\\\\\n', '          2x &- &y  &- &z &= &1 \\\\\\\\\\n', '          3x &+  &y  &+ &2z &= &0\\n', '        \\\\end{linsys}$\\n', '      \\\\partsitem\\n', '        $\\\\begin{linsys}[t]{3}\\n', '          x  &+ &y  &+ &2z  &= &0 \\\\\\\\\\n', '          2x  &- &y  &+  &z &= &1 \\\\\\\\\\n', '          4x &+ &y  &+ &5z &= &1  \\n', '        \\\\end{linsys}$\\n', '    \\\\end{exparts*}\\n', '    \\\\begin{answer}\\n', '      \\\\begin{exparts}\\n', '        \\\\partsitem\\n', '          \\\\begin{multline*}\\n', '            \\\\begin{amat}{3}\\n', '              1 &1  &-1 &3 \\\\\\\\\\n', '              2 &-1 &-1 &1 \\\\\\\\\\n', '              3 &1  &2  &0\\n', '            \\\\end{amat}\\n', '            \\\\grstep[-3\\\\rho_1+\\\\rho_3]{-2\\\\rho_1+\\\\rho_2}\\n', '            \\\\begin{amat}{3}\\n', '              1 &1  &-1 &3 \\\\\\\\\\n', '              0 &-3 &1  &-5 \\\\\\\\\\n', '              0 &-2  &5  &-9\\n', '            \\\\end{amat}                             \\\\\\\\\\n', '          \\\\begin{aligned}   \\n', '            &\\\\grstep{-(2/3)\\\\rho_2+\\\\rho_3}\\n', '            \\\\begin{amat}{3}\\n', '              1 &1  &-1    &3 \\\\\\\\\\n', '              0 &-3 &1     &-5 \\\\\\\\\\n', '              0 &0  &13/3  &-17/3\\n', '            \\\\end{amat}                                 \\n', '            \\\\grstep[(3/13)\\\\rho_3]{-(1/3)\\\\rho_2}\\n', '            \\\\begin{amat}{3}\\n', '              1 &1  &-1    &3 \\\\\\\\\\n', '              0 &1  &-1/3    &5/3 \\\\\\\\\\n', '              0 &0  &1      &-17/13\\n', '            \\\\end{amat}                                \\\\\\\\\\n', '            &\\\\grstep[(1/3)\\\\rho_3+\\\\rho_2]{\\\\rho_3+\\\\rho_1}\\n', '            \\\\begin{amat}{3}\\n', '              1 &1  &0    &22/13 \\\\\\\\\\n', '              0 &1  &0    &16/13 \\\\\\\\\\n', '              0 &0  &1      &-17/13\\n', '            \\\\end{amat}\\n', '            \\\\grstep{-\\\\rho_2+\\\\rho_1}\\n', '            \\\\begin{amat}{3}\\n', '              1 &0  &0    &6/13 \\\\\\\\\\n', '              0 &1  &0    &16/13 \\\\\\\\\\n', '              0 &0  &1      &-17/13\\n', '            \\\\end{amat}\\n', '          \\\\end{aligned}\\n', '          \\\\end{multline*}\\n', '        \\\\partsitem\\n', '          \\\\begin{multline*}\\n', '            \\\\begin{amat}{3}\\n', '              1 &1  &2 &0 \\\\\\\\\\n', '              2 &-1 &1 &1 \\\\\\\\\\n', '              4 &1  &5 &1\\n', '            \\\\end{amat}\\n', '            \\\\grstep[-4\\\\rho_1+\\\\rho_3]{-2\\\\rho_1+\\\\rho_2}\\n', '            \\\\begin{amat}{3}\\n', '              1 &1  &2  &0 \\\\\\\\\\n', '              0 &-3 &-3 &1 \\\\\\\\\\n', '              0 &-3 &-3 &1\\n', '            \\\\end{amat}\\n', '            \\\\grstep{-\\\\rho_2+\\\\rho_3}\\n', '            \\\\begin{amat}{3}\\n', '              1 &1  &2  &0 \\\\\\\\\\n', '              0 &-3 &-3 &1 \\\\\\\\\\n', '              0 &0  &0  &0\\n', '            \\\\end{amat}                              \\\\\\\\\\n', '            \\\\grstep{-(1/3)\\\\rho_2}\\n', '            \\\\begin{amat}{3}\\n', '              1 &1  &2  &0 \\\\\\\\\\n', '              0 &1  &1 &-1/3 \\\\\\\\\\n', '              0 &0  &0  &0\\n', '            \\\\end{amat}\\n', '            \\\\grstep{-\\\\rho_2+\\\\rho_1}\\n', '            \\\\begin{amat}{3}\\n', '              1 &0  &1  &1/3 \\\\\\\\\\n', '              0 &1  &1 &-1/3 \\\\\\\\\\n', '              0 &0  &0  &0\\n', '            \\\\end{amat}\\n', '          \\\\end{multline*}\\n', '      \\\\end{exparts}\\n', '    \\\\end{answer}\\n', '  \\\\recommended \\\\item \\n', '    Find the reduced echelon form of each matrix.\\n', '    \\\\begin{exparts*}\\n', '      \\\\partsitem \\\\( \\\\begin{mat}[r]\\n', '          2  &1  \\\\\\\\\\n', '          1  &3\\n', '        \\\\end{mat}  \\\\)\\n', '      \\\\partsitem \\\\( \\\\begin{mat}[r]\\n', '          1  &3  &1  \\\\\\\\\\n', '          2  &0  &4  \\\\\\\\\\n', '         -1  &-3 &-3\\n', '        \\\\end{mat}  \\\\)\\n', '      \\\\partsitem \\\\( \\\\begin{mat}[r]\\n', '          1  &0  &3  &1  &2  \\\\\\\\\\n', '          1  &4  &2  &1  &5  \\\\\\\\\\n', '          3  &4  &8  &1  &2\\n', '        \\\\end{mat}  \\\\)\\n', '      \\\\partsitem \\\\( \\\\begin{mat}[r]\\n', '          0  &1  &3  &2  \\\\\\\\\\n', '          0  &0  &5  &6  \\\\\\\\\\n', '          1  &5  &1  &5\\n', '        \\\\end{mat}  \\\\)\\n', '    \\\\end{exparts*}\\n', '    \\\\begin{answer}\\n', '      Use Gauss-Jordan reduction.\\n', '      \\\\begin{exparts}\\n', '        \\\\partsitem The reduced echelon form is all zeroes except\\n', '          for a diagonal of ones.\\n', '          \\\\begin{equation*}\\n', '            \\\\grstep{-(1/2)\\\\rho_1+\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              2  &1  \\\\\\\\\\n', '              0  &5/2\\n', '            \\\\end{mat}\\n', '            \\\\grstep[(2/5)\\\\rho_2]{(1/2)\\\\rho_1}\\n', '            \\\\begin{mat}[r]\\n', '              1  &1/2\\\\\\\\\\n', '              0  &1\\n', '            \\\\end{mat}                      \\n', '            \\\\grstep{-(1/2)\\\\rho_2+\\\\rho_1}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  \\\\\\\\\\n', '              0  &1\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '        \\\\partsitem As in the prior problem, the reduced echelon form is \\n', '          all zeroes but for a diagonal of ones.\\n', '          \\\\begin{multline*}\\n', '            \\\\grstep[\\\\rho_1+\\\\rho_3]{-2\\\\rho_1+\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &3  &1  \\\\\\\\\\n', '              0  &-6 &2  \\\\\\\\\\n', '              0  &0  &-2\\n', '            \\\\end{mat}\\n', '            \\\\grstep[-(1/2)\\\\rho_3]{-(1/6)\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &3  &1     \\\\\\\\\\n', '              0  &1  &-1/3  \\\\\\\\\\n', '              0  &0  &1\\n', '            \\\\end{mat}                                      \\\\\\\\              \\n', '            \\\\grstep[-\\\\rho_3+\\\\rho_1]{(1/3)\\\\rho_3+\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &3  &0     \\\\\\\\\\n', '              0  &1  &0     \\\\\\\\\\n', '              0  &0  &1\\n', '            \\\\end{mat}                  \\n', '            \\\\grstep{-3\\\\rho_2+\\\\rho_1}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &0     \\\\\\\\\\n', '              0  &1  &0     \\\\\\\\\\n', '              0  &0  &1\\n', '            \\\\end{mat}\\n', '           \\\\end{multline*}\\n', '        \\\\partsitem There are more columns than rows so we must get more\\n', '          than just a diagonal of ones.\\n', '          \\\\begin{multline*}\\n', '            \\\\grstep[-3\\\\rho_1+\\\\rho_3]{-\\\\rho_1+\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &3  &1  &2  \\\\\\\\\\n', '              0  &4  &-1 &0  &3  \\\\\\\\\\n', '              0  &4  &-1 &-2 &-4\\n', '            \\\\end{mat}\\n', '            \\\\grstep{-\\\\rho_2+\\\\rho_3}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &3  &1  &2  \\\\\\\\\\n', '              0  &4  &-1 &0  &3  \\\\\\\\\\n', '              0  &0  &0  &-2 &-7\\n', '            \\\\end{mat}                           \\\\\\\\\\n', '            \\\\grstep[-(1/2)\\\\rho_3]{(1/4)\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &3    &1  &2  \\\\\\\\\\n', '              0  &1  &-1/4 &0  &3/4  \\\\\\\\\\n', '              0  &0  &0    &1  &7/2\\n', '            \\\\end{mat}                           \\n', '            \\\\grstep{-\\\\rho_3+\\\\rho_1}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &3    &0  &-3/2  \\\\\\\\\\n', '              0  &1  &-1/4 &0  &3/4     \\\\\\\\\\n', '              0  &0  &0    &1  &7/2\\n', '            \\\\end{mat}\\n', '          \\\\end{multline*}\\n', '        \\\\partsitem As in the prior item, this is not a square matrix. \\n', '          \\\\begin{multline*}\\n', '            \\\\grstep{\\\\rho_1\\\\leftrightarrow\\\\rho_3}\\n', '            \\\\begin{mat}[r]\\n', '              1  &5  &1  &5  \\\\\\\\\\n', '              0  &0  &5  &6  \\\\\\\\\\n', '              0  &1  &3  &2\\n', '            \\\\end{mat}\\n', '            \\\\grstep{\\\\rho_2\\\\leftrightarrow\\\\rho_3}\\n', '            \\\\begin{mat}[r]\\n', '              1  &5  &1  &5  \\\\\\\\\\n', '              0  &1  &3  &2  \\\\\\\\\\n', '              0  &0  &5  &6\\n', '            \\\\end{mat}                    \\\\\\\\\\n', '            \\\\begin{aligned}\\n', '              &\\\\grstep{(1/5)\\\\rho_3}\\n', '              \\\\begin{mat}[r]\\n', '                1  &5  &1  &5  \\\\\\\\\\n', '                0  &1  &3  &2  \\\\\\\\\\n', '                0  &0  &1  &6/5\\n', '              \\\\end{mat}                  \\n', '              \\\\grstep[-\\\\rho_3+\\\\rho_1]{-3\\\\rho_3+\\\\rho_2}\\n', '              \\\\begin{mat}[r]\\n', '                1  &5  &0  &19/5  \\\\\\\\\\n', '                0  &1  &0  &-8/5  \\\\\\\\\\n', '                0  &0  &1  &6/5\\n', '              \\\\end{mat}                   \\\\\\\\\\n', '              &\\\\grstep{-5\\\\rho_2+\\\\rho_1}\\n', '              \\\\begin{mat}[r]\\n', '                1  &0  &0  &59/5  \\\\\\\\\\n', '                0  &1  &0  &-8/5  \\\\\\\\\\n', '                0  &0  &1  &6/5\\n', '              \\\\end{mat}\\n', '            \\\\end{aligned}\\n', '          \\\\end{multline*}\\n', '      \\\\end{exparts}  \\n', '    \\\\end{answer}\\n', '  \\\\item Get the reduced echelon form of each.\\n', '    \\\\begin{exparts*}\\n', '      \\\\partsitem $\\n', '        \\\\begin{mat}\\n', '          0  &2 &1 \\\\\\\\\\n', '          2  &-1 &1 \\\\\\\\\\n', '          -2 &-1 &0\\n', '        \\\\end{mat}$\\n', '      \\\\partsitem $\\n', '        \\\\begin{mat}\\n', '          1 &3 &1 \\\\\\\\\\n', '          2 &6 &2 \\\\\\\\\\n', '         -1 &0 &0\\n', '        \\\\end{mat}$\\n', '    \\\\end{exparts*}\\n', '    \\\\begin{answer}\\n', '      \\\\begin{exparts}\\n', '        \\\\partsitem Swap first.\\n', '          \\\\begin{equation*}\\n', '            \\\\grstep{\\\\rho_1\\\\leftrightarrow\\\\rho_2}\\n', '            \\\\grstep{\\\\rho_1+\\\\rho_3}\\n', '            \\\\grstep{\\\\rho_2+\\\\rho_3}\\n', '            \\\\grstep[(1/2)\\\\rho_2 \\\\\\\\ (1/2)\\\\rho_3]{(1/2)\\\\rho_1}\\n', '            \\\\grstep[(-1/2)\\\\rho_3+\\\\rho_2]{(-1/2)\\\\rho_3+\\\\rho_1}\\n', '            \\\\grstep{(1/2)\\\\rho_2+\\\\rho_1}\\n', '            \\\\begin{mat}\\n', '              1 &0 &0 \\\\\\\\\\n', '              0 &1 &0 \\\\\\\\\\n', '              0 &0 &1\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '        \\\\partsitem Here the swap is in the middle.\\n', '        \\\\begin{equation*}\\n', '          \\\\grstep[\\\\rho_1+\\\\rho_3]{-2\\\\rho_1+\\\\rho_2}\\n', '          \\\\grstep{\\\\rho_2\\\\leftrightarrow\\\\rho_3}\\n', '          \\\\grstep{(1/3)\\\\rho_2}\\n', '          \\\\grstep{-3\\\\rho_2+\\\\rho_1}\\n', '          \\\\begin{mat}\\n', '            1 &0 &0   \\\\\\\\\\n', '            0 &1 &1/3 \\\\\\\\\\n', '            0 &0 &0\\n', '          \\\\end{mat}\\n', '        \\\\end{equation*}\\n', '      \\\\end{exparts}\\n', '    \\\\end{answer}\\n', '  \\\\recommended \\\\item \\n', '    Find each solution set by using Gauss-Jordan reduction and\\n', '    then reading off the parametrization.\\n', '    \\\\begin{exparts}\\n', '      \\\\partsitem \\\\( \\\\begin{linsys}[t]{3}\\n', '                  2x  &+  &y  &-  &z  &=  &1  \\\\\\\\\\n', '                  4x  &-  &y  &   &   &=  &3  \\n', '                  \\\\end{linsys}  \\\\)\\n', '      \\\\partsitem \\\\( \\\\begin{linsys}[t]{4}\\n', '                   x  &   &   &-  &z  &   &   &=  &1  \\\\\\\\\\n', '                      &   &y  &+  &2z &-  &w  &=  &3  \\\\\\\\\\n', '                   x  &+  &2y &+  &3z &-  &w  &=  &7  \\n', '                    \\\\end{linsys}  \\\\)\\n', '      \\\\partsitem \\\\( \\\\begin{linsys}[t]{4}\\n', '                   x  &-  &y  &+  &z  &   &   &=  &0  \\\\\\\\\\n', '                      &   &y  &   &   &+  &w  &=  &0  \\\\\\\\\\n', '                  3x  &-  &2y &+  &3z &+  &w  &=  &0  \\\\\\\\\\n', '                      &   &-y &   &   &-  &w  &=  &0  \\n', '                  \\\\end{linsys}  \\\\)\\n', '      \\\\partsitem \\\\( \\\\begin{linsys}[t]{5}\\n', '                   a  &+  &2b &+  &3c &+  &d  &-  &e  &=  &1  \\\\\\\\\\n', '                  3a  &-  &b  &+  &c  &+  &d  &+  &e  &=  &3  \\n', '                  \\\\end{linsys}  \\\\)\\n', '    \\\\end{exparts}\\n', '    \\\\begin{answer}\\n', \"      For the Gauss's halves, see the answers to Chapter One's\\n\", '      section~I.2 question\\n', '      \\\\nearbyexercise{exer:SlvMatNot}.\\n', '      \\\\begin{exparts}\\n', \"      \\\\partsitem The ``Jordan'' half goes this way.\\n\", '        \\\\begin{equation*}\\n', '          \\\\grstep[-(1/3)\\\\rho_2]{(1/2)\\\\rho_1}\\n', '          \\\\begin{amat}[r]{3}\\n', '            1  &1/2 &-1/2 &1/2  \\\\\\\\\\n', '            0  &1   &-2/3 &-1/3\\n', '          \\\\end{amat}                           \\n', '          \\\\grstep{-(1/2)\\\\rho_2+\\\\rho_1}\\n', '          \\\\begin{amat}[r]{3}\\n', '            1  &0   &-1/6 &2/3  \\\\\\\\\\n', '            0  &1   &-2/3 &-1/3\\n', '          \\\\end{amat}\\n', '        \\\\end{equation*}\\n', '        The solution set is this\\n', '        \\\\begin{equation*}\\n', '          \\\\set{\\\\colvec[r]{2/3 \\\\\\\\ -1/3 \\\\\\\\ 0}\\n', '               +\\\\colvec[r]{1/6 \\\\\\\\ 2/3 \\\\\\\\ 1}z\\n', '              \\\\suchthat z\\\\in\\\\Re}\\n', '        \\\\end{equation*}\\n', '      \\\\partsitem The second half is\\n', '        \\\\begin{equation*}\\n', '          \\\\grstep{\\\\rho_3+\\\\rho_2}\\n', '          \\\\begin{amat}[r]{4}\\n', '            1  &0  &-1  &0  &1 \\\\\\\\\\n', '            0  &1  &2   &0  &3 \\\\\\\\\\n', '            0  &0  &0   &1  &0\\n', '          \\\\end{amat}\\n', '        \\\\end{equation*}\\n', '        so the solution is this.\\n', '        \\\\begin{equation*}\\n', '          \\\\set{\\\\colvec[r]{1 \\\\\\\\ 3 \\\\\\\\ 0 \\\\\\\\ 0}\\n', '               +\\\\colvec[r]{1 \\\\\\\\ -2 \\\\\\\\ 1 \\\\\\\\ 0}z\\n', '              \\\\suchthat z\\\\in\\\\Re}\\n', '        \\\\end{equation*}\\n', '      \\\\partsitem This Jordan half\\n', '        \\\\begin{equation*}\\n', '          \\\\grstep{\\\\rho_2+\\\\rho_1}\\n', '          \\\\begin{amat}[r]{4}\\n', '            1  &0  &1   &1  &0 \\\\\\\\\\n', '            0  &1  &0   &1  &0 \\\\\\\\\\n', '            0  &0  &0   &0  &0 \\\\\\\\\\n', '            0  &0  &0   &0  &0\\n', '          \\\\end{amat}\\n', '        \\\\end{equation*}\\n', '        gives \\n', '        \\\\begin{equation*}\\n', '          \\\\set{\\\\colvec[r]{0 \\\\\\\\ 0 \\\\\\\\ 0 \\\\\\\\ 0}\\n', '               +\\\\colvec[r]{-1 \\\\\\\\ 0 \\\\\\\\ 1 \\\\\\\\ 0}z\\n', '               +\\\\colvec[r]{-1 \\\\\\\\ -1 \\\\\\\\ 0 \\\\\\\\ 1}w\\n', '              \\\\suchthat z,w\\\\in\\\\Re}\\n', '        \\\\end{equation*}\\n', '        (of course, we could omit the zero vector from the description).\\n', \"      \\\\partsitem The ``Jordan'' half\\n\", '        \\\\begin{align*}\\n', '          &\\\\grstep{-(1/7)\\\\rho_2}\\n', '          \\\\begin{amat}[r]{5}\\n', '            1  &2  &3   &1   &-1   &1  \\\\\\\\\\n', '            0  &1  &8/7 &2/7 &-4/7 &0\\n', '          \\\\end{amat}                   \\\\\\\\\\n', '          &\\\\grstep{-2\\\\rho_2+\\\\rho_1}\\n', '          \\\\begin{amat}[r]{5}\\n', '            1  &0  &5/7 &3/7 &1/7  &1  \\\\\\\\\\n', '            0  &1  &8/7 &2/7 &-4/7 &0\\n', '          \\\\end{amat}\\n', '        \\\\end{align*}\\n', '        ends with this solution set.\\n', '        \\\\begin{equation*}\\n', '          \\\\set{\\\\colvec[r]{1 \\\\\\\\ 0 \\\\\\\\ 0 \\\\\\\\ 0 \\\\\\\\ 0}\\n', '               +\\\\colvec[r]{-5/7 \\\\\\\\ -8/7 \\\\\\\\ 1 \\\\\\\\ 0 \\\\\\\\ 0}c\\n', '               +\\\\colvec[r]{-3/7 \\\\\\\\ -2/7 \\\\\\\\ 0 \\\\\\\\ 1 \\\\\\\\ 0}d\\n', '               +\\\\colvec[r]{-1/7 \\\\\\\\ 4/7 \\\\\\\\ 0 \\\\\\\\ 0 \\\\\\\\ 1}e\\n', '              \\\\suchthat c,d,e\\\\in\\\\Re}\\n', '        \\\\end{equation*}\\n', '    \\\\end{exparts}\\n', '   \\\\end{answer}\\n', '  \\\\item \\n', '    Give two distinct echelon form versions of this matrix.\\n', '    \\\\begin{equation*}\\n', '      \\\\begin{mat}[r]\\n', '        2  &1  &1  &3  \\\\\\\\\\n', '        6  &4  &1  &2  \\\\\\\\\\n', '        1  &5  &1  &5\\n', '      \\\\end{mat}\\n', '    \\\\end{equation*}\\n', '    \\\\begin{answer}\\n', \"      Routine Gauss's Method gives one:\\n\", '      \\\\begin{equation*}\\n', '        \\\\grstep[-(1/2)\\\\rho_1+\\\\rho_3]{-3\\\\rho_1+\\\\rho_2}\\n', '        \\\\begin{mat}[r]\\n', '          2  &1  &1  &3  \\\\\\\\\\n', '          0  &1  &-2 &-7 \\\\\\\\\\n', '          0  &9/2&1/2&7/2\\n', '        \\\\end{mat}\\n', '        \\\\grstep{-(9/2)\\\\rho_2+\\\\rho_3}\\n', '        \\\\begin{mat}[r]\\n', '          2  &1  &1    &3  \\\\\\\\\\n', '          0  &1  &-2   &-7 \\\\\\\\\\n', '          0  &0  &19/2 &35\\n', '        \\\\end{mat}\\n', '      \\\\end{equation*}\\n', '      and any cosmetic change, such as multiplying the bottom row by \\\\( 2 \\\\),\\n', '      \\\\begin{equation*}\\n', '        \\\\begin{mat}[r]\\n', '          2  &1  &1    &3  \\\\\\\\\\n', '          0  &1  &-2   &-7 \\\\\\\\\\n', '          0  &0  &19   &70\\n', '        \\\\end{mat}\\n', '      \\\\end{equation*}\\n', '      gives another.  \\n', '    \\\\end{answer}\\n', '  \\\\recommended \\\\item \\\\label{exer:PossRedEchFrms} \\n', '    List the reduced echelon forms possible for each size.\\n', '    \\\\begin{exparts*}\\n', '      \\\\partsitem \\\\( \\\\nbyn{2} \\\\)\\n', '      \\\\partsitem \\\\( \\\\nbym{2}{3} \\\\)\\n', '      \\\\partsitem \\\\( \\\\nbym{3}{2} \\\\)\\n', '      \\\\partsitem \\\\( \\\\nbyn{3} \\\\)\\n', '    \\\\end{exparts*}\\n', '    \\\\begin{answer}\\n', '      In the cases listed below, we take $a,b\\\\in\\\\Re$.\\n', '      Thus, some canonical forms \\n', '      listed below actually include infinitely many cases.\\n', '      In particular, they includes the cases $a=0$ and $b=0$.\\n', '      \\\\begin{exparts}\\n', '        \\\\partsitem \\n', '          $\\\\begin{mat}[r]\\n', '            0  &0  \\\\\\\\\\n', '            0  &0\\n', '          \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '            1  &a  \\\\\\\\\\n', '            0  &0\\n', '          \\\\end{mat}$, \\n', '          $\\\\begin{mat}[r]\\n', '            0  &1  \\\\\\\\\\n', '            0  &0\\n', '          \\\\end{mat}$, \\n', '          $\\\\begin{mat}[r]\\n', '            1  &0  \\\\\\\\\\n', '            0  &1\\n', '          \\\\end{mat}$\\n', '        \\\\partsitem\\n', '          $\\\\begin{mat}[r]\\n', '               0  &0  &0  \\\\\\\\\\n', '               0  &0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               1  &a  &b  \\\\\\\\\\n', '               0  &0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               0  &1  &a  \\\\\\\\\\n', '               0  &0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               0  &0  &1  \\\\\\\\\\n', '               0  &0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               1  &0  &a  \\\\\\\\\\n', '               0  &1  &b\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               1  &a  &0  \\\\\\\\\\n', '               0  &0  &1\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               0  &1  &0  \\\\\\\\\\n', '               0  &0  &1\\n', '             \\\\end{mat}$\\n', '        \\\\partsitem\\n', '          $\\\\begin{mat}[r]\\n', '               0  &0  \\\\\\\\\\n', '               0  &0  \\\\\\\\\\n', '               0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               1  &a  \\\\\\\\\\n', '               0  &0  \\\\\\\\\\n', '               0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               0  &1  \\\\\\\\\\n', '               0  &0  \\\\\\\\\\n', '               0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               1  &0  \\\\\\\\\\n', '               0  &1  \\\\\\\\\\n', '               0  &0\\n', '             \\\\end{mat}$\\n', '        \\\\partsitem\\n', '          $\\\\begin{mat}[r]\\n', '               0  &0  &0  \\\\\\\\\\n', '               0  &0  &0  \\\\\\\\\\n', '               0  &0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               1  &a  &b  \\\\\\\\\\n', '               0  &0  &0  \\\\\\\\\\n', '               0  &0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               0  &1  &a  \\\\\\\\\\n', '               0  &0  &0  \\\\\\\\\\n', '               0  &0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               0  &1  &0  \\\\\\\\\\n', '               0  &0  &1  \\\\\\\\\\n', '               0  &0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               0  &0  &1  \\\\\\\\\\n', '               0  &0  &0  \\\\\\\\\\n', '               0  &0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               1  &0  &a  \\\\\\\\\\n', '               0  &1  &b  \\\\\\\\\\n', '               0  &0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               1  &a  &0  \\\\\\\\\\n', '               0  &0  &1  \\\\\\\\\\n', '               0  &0  &0\\n', '             \\\\end{mat}$,\\n', '          $\\\\begin{mat}[r]\\n', '               1  &0  &0  \\\\\\\\\\n', '               0  &1  &0  \\\\\\\\\\n', '               0  &0  &1\\n', '             \\\\end{mat}$\\n', '      \\\\end{exparts}  \\n', '    \\\\end{answer}\\n', '  \\\\recommended \\\\item  \\n', '    What results from applying Gauss-Jordan reduction to a\\n', '    nonsingular matrix?\\n', '    \\\\begin{answer}\\n', '      A nonsingular homogeneous linear system has a unique solution.\\n', '      So a nonsingular matrix must reduce to a (square) \\n', \"      matrix that is all \\\\( 0 \\\\)'s\\n\", \"      except for \\\\( 1 \\\\)'s down the upper-left to lower-right diagonal, \\n\", '      such as these.\\n', '      \\\\begin{equation*}\\n', '         \\\\begin{mat}[r]\\n', '           1  &0  \\\\\\\\\\n', '           0  &1  \\\\\\\\\\n', '         \\\\end{mat}\\n', '         \\\\qquad\\n', '         \\\\begin{mat}[r]\\n', '           1  &0  &0  \\\\\\\\\\n', '           0  &1  &0  \\\\\\\\\\n', '           0  &0  &1\\n', '         \\\\end{mat}\\n', '      \\\\end{equation*}  \\n', '    \\\\end{answer}\\n', ' \\\\item Decide whether each relation is an equivalence on the set of \\n', '   $\\\\nbyn{2}$ matrices.\\n', '   \\\\begin{exparts}\\n', '     \\\\partsitem two matrices are related if they have the same entry\\n', '       in the first row and first column\\n', '     % \\\\partsitem two matrices are related if their four entries sum to the \\n', '     %   same total\\n', '     \\\\partsitem two matrices are related if they have the same entry\\n', '       in the first row and first column, or the same entry in the \\n', '       second row and second column\\n', '   \\\\end{exparts}\\n', '   \\\\begin{answer}\\n', '     \\\\begin{exparts}\\n', '       \\\\partsitem  This is an equivalence.\\n', '        \\n', '          We can write $M_1\\\\sim M_2$ if they are related.\\n', '          The $\\\\sim$~relation is reflexive because any matrix has the \\n', '          same $1,1$ entry as itself.\\n', '          The relation is symmetric because if $M_1$ has the same $1,1$\\n', '          entry as~$M_2$ then clearly also $M_2$ has the same $1,1$ entry\\n', '          as~$M_1$.\\n', '          Finally, the relation is transitive because if $M_1\\\\sim M_2$ so they\\n', '          have the same $1,1$ entry as each other, \\n', '          and $M_2\\\\sim M_3$ so they have the \\n', '          same as each other, then all three have the same~$1,1$ entry, \\n', '          and $M_1\\\\sim M_3$. \\n', '       % \\\\partsitem  This is an equivalence.\\n', '       %    Write $M_1\\\\sim M_2$ if they are related.\\n', '\\n', '       %    This relation is reflexive because any matrix has the \\n', '       %    same sum of entries as itself.\\n', '       %    The $\\\\sim$~relation is symmetric because if $M_1$ has the same\\n', '       %    sum of \\n', '       %    entries as~$M_2$, then also $M_2$ has the same sum of entries\\n', '       %    as~$M_1$.\\n', '       %    Finally, the relation is transitive because if $M_1\\\\sim M_2$ so their\\n', '       %    entry sum is the same, \\n', '       %    and $M_2\\\\sim M_3$ so they have the \\n', '       %    same entry sum as each other, then all three have the same entry sum, \\n', '       %    and $M_1\\\\sim M_3$. \\n', '       \\\\partsitem\\n', '          This is not an equivalence because it is not transitive.\\n', '          The first and second matrix below are related by their $1,1$ entries,\\n', '          and the second and third are related by their $2,2$~entries.\\n', '          But the first and third are not related.\\n', '          \\\\begin{equation*}\\n', '            \\\\begin{mat}\\n', '              1 &0 \\\\\\\\\\n', '              0 &0\\n', '            \\\\end{mat}\\n', '            \\\\quad\\n', '            \\\\begin{mat}\\n', '              1 &0 \\\\\\\\\\n', '              0 &-1\\n', '            \\\\end{mat}\\n', '            \\\\quad\\n', '            \\\\begin{mat}\\n', '              0 &0 \\\\\\\\\\n', '              0 &-1\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '     \\\\end{exparts}\\n', '   \\\\end{answer}\\n', ' \\\\item \\\\cite{Cleary}\\n', '    Consider the following relationship on the set of $\\\\nbyn{2}$ matrices:  \\n', '    we say that $A$ is \\\\textit{sum-what like} $B$ if the sum of all of \\n', '    the entries in $A$ is the same as the sum of all the entries in $B$.  \\n', '    For instance, the zero matrix would be sum-what like the matrix \\n', '    whose first row had two sevens, and whose second row had two \\n', '    negative sevens.\\n', '    Prove or disprove that this is an equivalence relation on the set \\n', '    of $\\\\nbyn{2}$ matrices.\\n', '    \\\\begin{answer}\\n', '      It is an equivalence relation.\\n', '      To prove that we must check that the relation \\n', '      is reflexive, symmetric, and transitive.\\n', '\\n', '      Assume that all matrices are $\\\\nbyn{2}$.\\n', '      For reflexive, we note that a matrix has the same sum of entries as\\n', '      itself.\\n', '      For symmetric, we assume $A$ has the same sum of entries as~$B$ \\n', '      and obviously then $B$ has the same sum of entries as~$A$.\\n', '      Transitivity is no harder\\\\Dash if $A$ has the same sum of entries\\n', '      as $B$ and $B$ has the same sum of entries as $C$ then \\n', '      $A$ has the same as $C$.\\n', '    \\\\end{answer}\\n', ' \\\\item \\\\label{exer:INotJMakesRowOpsRev}\\n', '   The proof of \\\\nearbylemma{le:RowOpsRev} contains a reference to the \\n', '   $i\\\\neq j$ condition on the row combination operation.\\n', '   \\\\begin{exparts}\\n', '     \\\\partsitem Write down a $\\\\nbyn{2}$ matrix with nonzero entries,\\n', '        and show that the $-1\\\\cdot\\\\rho_1+\\\\rho_1$ operation is not\\n', '        reversed by $1\\\\cdot\\\\rho_1+\\\\rho_1$.\\n', '     \\\\partsitem Expand the proof of that lemma to make explicit exactly where \\n', '        it uses the $i\\\\neq j$ condition on combining.\\n', '   \\\\end{exparts}\\n', '   \\\\begin{answer}\\n', '    \\\\begin{exparts}\\n', '      \\\\partsitem For instance,\\n', '        \\\\begin{equation*}\\n', '          \\\\begin{mat}[r]\\n', '            1  &2  \\\\\\\\\\n', '            3  &4  \\n', '          \\\\end{mat}\\n', '          \\\\grstep{-\\\\rho_1+\\\\rho_1}\\n', '          \\\\begin{mat}[r]\\n', '            0  &0  \\\\\\\\\\n', '            3  &4  \\n', '          \\\\end{mat}\\n', '          \\\\grstep{\\\\rho_1+\\\\rho_1}\\n', '          \\\\begin{mat}[r]\\n', '            0  &0  \\\\\\\\\\n', '            3  &4  \\n', '          \\\\end{mat}\\n', '        \\\\end{equation*}\\n', '        leaves the matrix changed.\\n', '      \\\\partsitem This operation\\n', '        \\\\begin{equation*}\\n', '          \\\\begin{mat}\\n', '            \\\\vdotswithin{a_{i,1}}                     \\\\\\\\\\n', '            a_{i,1}  &\\\\cdots  &a_{i,n}  \\\\\\\\\\n', '            \\\\vdotswithin{a_{i,1}}                     \\\\\\\\\\n', '            a_{j,1}  &\\\\cdots  &a_{j,n}  \\\\\\\\\\n', '            \\\\vdotswithin{a_{i,1}}                     \\n', '          \\\\end{mat}\\n', '          \\\\grstep{k\\\\rho_i+\\\\rho_j}\\n', '          \\\\begin{mat}\\n', '            \\\\vdotswithin{a_{i,1}}                                      \\\\\\\\\\n', '            a_{i,1}           &\\\\cdots  &a_{i,n}          \\\\\\\\\\n', '            \\\\vdotswithin{a_{i,1}}                                      \\\\\\\\\\n', '            ka_{i,1}+a_{j,1}  &\\\\cdots  &ka_{i,n}+a_{j,n}  \\\\\\\\\\n', '            \\\\vdotswithin{a_{i,1}}                     \\n', '          \\\\end{mat}\\n', '        \\\\end{equation*}      \\n', '        leaves the $i$-th row unchanged because of the $i\\\\neq j$ restriction.\\n', '        Because the $i$-th row is unchanged, this operation \\n', '        \\\\begin{equation*}                                        \\n', '          \\\\grstep{-k\\\\rho_i+\\\\rho_j}\\n', '          \\\\begin{mat}\\n', '            \\\\vdotswithin{a_{i,1}}                                      \\\\\\\\\\n', '            a_{i,1}           &\\\\cdots  &a_{i,n}          \\\\\\\\\\n', '            \\\\vdotswithin{a_{i,1}}                                      \\\\\\\\\\n', '            -ka_{i,1}+ka_{i,1}+a_{j,1}  &\\\\cdots &-ka_{i,n}+ka_{i,n}+a_{j,n} \\\\\\\\\\n', '            \\\\vdotswithin{a_{i,1}}                     \\n', '          \\\\end{mat}\\n', '        \\\\end{equation*}\\n', '        returns the $j$-th row to its original state.\\n', '        % (If $i=j$ then the third matrix would have entries of the \\n', '        % form $-k(ka_{i,j}+a_{i,j})+ka_{i,j}+a_{i,j}$.)\\n', '    \\\\end{exparts}\\n', '   \\\\end{answer}\\n', ' \\\\recommended \\\\item \\\\cite{Cleary}\\n', '  Consider the set of students in a class.  \\n', '  Which of the following relationships are equivalence relations?  \\n', '  Explain each answer in at least a sentence.\\n', '  \\\\begin{exparts}\\n', '    \\\\item  Two students $x, y$ are related \\n', '      if $x$ has taken at least as many \\n', '      math classes as $y$.\\n', '    \\\\item Students $x, y$ are related if they have names \\n', '      that start with the same letter.\\n', '  \\\\end{exparts}\\n', '  \\\\begin{answer}\\n', '    To be an equivalence, each relation must be reflexive, symmetric, and\\n', '    transitive.\\n', '    \\\\begin{exparts}\\n', '      \\\\item This relation \\n', '        is not symmetric because if $x$ has taken $4$~classes and $y$\\n', '        has taken $3$ then $x$ is related to $y$ but $y$ is not related\\n', '        to $x$.\\n', \"      \\\\item This is reflexive because $x$'s name starts with the same\\n\", \"        letter as does $x$'s.\\n\", \"        It is symmetric because if $x$'s name starts with the same letter \\n\", \"        as $y$'s then $y$'s starts with the same letter as does~$x$'s.\\n\", \"        And it is transitive because if $x$'s name starts with the same letter\\n\", \"        as does~$y$'s and $y$'s name starts with the same letter as \\n\", \"        does $z$'s then $x$'s starts with the same letter as does $z$'s.\\n\", '        So it is an equivalence.\\n', '    \\\\end{exparts}\\n', '  \\\\end{answer}\\n', '  \\\\item\\n', '  Show that each of these is an equivalence on the set of $\\\\nbyn{2}$\\n', '  matrices.\\n', '  Describe the equivalence classes.\\n', '  \\\\begin{exparts}\\n', '    \\\\item Two matrices are related if they have the same product down the\\n', '      diagonal, that is, if the product of the entries in the upper left and\\n', '      lower right are equal.\\n', '    \\\\item Two matrices are related if they both have at least one entry \\n', '      that is a~$1$,\\n', '      or if neither does.\\n', '  \\\\end{exparts}\\n', '  \\\\begin{answer}\\n', '    For each we must check the three conditions of reflexivity, symmetry, and\\n', '    transitivity.\\n', '    \\\\begin{exparts}\\n', '      \\\\item Any matrix clearly has the same product down the diagonal as\\n', '        itself, so the relation is reflexive.\\n', '        The relation is symmetric because if $A$ has the same product down\\n', '        its diagonal as does~$B$,\\n', '        if $a_{1,1}\\\\cdot a_{2,2}=b_{1,1}\\\\cdot b_{2,2}$, \\n', '        then $B$ has the same product as does~$A$.\\n', ' \\n', \"        Transitivity is similar: suppose that $A$'s product is~$r$ and \\n\", \"        that it equals $B$'s product.\\n\", \"        Suppose also that $B$'s product equals $C$'s.\\n\", \"        Then all three have a product of~$r$, and $A$'s equals~$C$'s.\\n\", '\\n', '        There is an equivalence class for each real number, namely the \\n', '        class contains all $\\\\nbyn{2}$ matrices whose product down the\\n', '        diagonal is that real.\\n', '      \\\\item For reflexivity, if the matrix $A$ has a~$1$ entry then it is \\n', '        related to itself while if it does not then it is also related to \\n', '        itself.\\n', '        Symmetry also has two cases: suppose that $A$ and~$B$ are related.\\n', '        If $A$ has a~$1$ entry then so does~$B$, and thus $B$ is related to~$A$.\\n', '        If $A$ has no~$1$ then neither does $B$, and again $B$ is related to\\n', '        $A$.\\n', ' \\n', '        For transitivity, suppose that $A$ is related to~$B$ and $B$ to~$C$.\\n', '        If $A$ has a~$1$ entry then so does~$B$, and because $B$ is related\\n', '        to~$C$, therefore so does~$C$,\\n', '        and hence $A$ is related to~$C$.\\n', '        Likewise, if $A$ has no~$1$ then neither does~$B$, and consequently\\n', '        neither does~$C$, giving the conclusion that $A$ is related to~$C$. \\n', '\\n', '        There are exactly two equivalence classes, one containing any\\n', '        $\\\\nbyn{2}$ matrix that has at least one entry that is a~$1$,\\n', \"        and the other containing all the matrices that have no $1$'s.\\n\", '    \\\\end{exparts}\\n', '  \\\\end{answer}\\n', '  \\\\item Show that each is not an equivalence on the\\n', '    set of $\\\\nbyn{2}$ matrices.\\n', '    \\\\begin{exparts}\\n', '      \\\\item Two matrices $A,B$ are related if $a_{1,1}=-b_{1,1}$.\\n', '      \\\\item Two matrices are related if the sum of their entries are\\n', '        within $5$, that is, $A$ is related to~$B$ if\\n', '        $\\\\absval{(a_{1,1}+\\\\cdots+a_{2,2})-(b_{1,1}+\\\\cdots+b_{2,2})}<5$.\\n', '    \\\\end{exparts}\\n', '    \\\\begin{answer}\\n', '      \\\\begin{exparts}\\n', '        \\\\item This relation is not reflexive.\\n', '          For instance, any matrix with an upper-left entry of~$1$ is not\\n', '          related to itself.\\n', '        \\\\item This relation is not transitive.\\n', '          For these three, $A$ is related to~$B$, and $B$ is related to~$C$,\\n', '          but $A$ is not related to~$C$.\\n', '          \\\\begin{equation*}\\n', '            A=\\\\begin{mat}\\n', '              0 &0 \\\\\\\\\\n', '              0 &0\\n', '            \\\\end{mat},\\\\quad\\n', '            B=\\\\begin{mat}\\n', '              4 &0 \\\\\\\\\\n', '              0 &0\\n', '            \\\\end{mat},\\\\quad\\n', '            C=\\\\begin{mat}\\n', '              8 &0 \\\\\\\\\\n', '              0 &0\\n', '            \\\\end{mat},\\\\quad\\n', '          \\\\end{equation*}\\n', '      \\\\end{exparts}\\n', '    \\\\end{answer}\\n', '\\\\end{exercises}\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\\\subsection{The Linear Combination Lemma}\\n', 'We will close this chapter by proving \\n', 'that every matrix is row equivalent to one\\n', 'and only one reduced echelon form matrix.\\n', 'The ideas here will reappear, and be further developed, in the\\n', 'next chapter.\\n', '% Here is an informal argument that the reduced \\n', '% echelon form version of a matrix is unique.\\n', '% Consider again the example that started this section of a matrix that\\n', '% reduces to three different echelon form matrices.\\n', '% The first matrix of the three is the natural echelon form version.\\n', '% The second matrix is the same as \\n', '% the first except that a row has been halved.\\n', '% The third matrix, too, is just a cosmetic variant of the first. \\n', '% The definition of reduced echelon form outlaws this kind of fooling around.\\n', '% In reduced echelon form,\\n', '% halving a row is not possible because that would\\n', \"% change the row's leading entry away from one, and\\n\", '% neither is combining rows possible, because then a leading entry would no\\n', '% longer be alone in its column.\\n', '\\n', '% This informal justification is not a proof;\\n', '% the argument shows that no two different reduced echelon form matrices\\n', '% are related by a single row operation step, but the argument does not\\n', '% rule out the possibility that two different reduced echelon form\\n', '% matrices could be related by multiple steps.\\n', '% Before we go to the proof, we finish this subsection by \\n', '% rephrasing our work in a terminology that will be enlightening.\\n', 'The crucial observation concerns \\n', 'how row operations act to transform one matrix into another:\\n', 'the new rows are\\n', 'linear combinations of the old.\\n', '\\n', '\\\\begin{example}\\n', 'Consider this Gauss-Jordan reduction.\\n', '\\\\begin{align*}\\n', '  \\\\begin{amat}{2}\\n', '    2  &1  &0  \\\\\\\\\\n', '    1  &3  &5\\n', '  \\\\end{amat}\\n', '  &\\\\grstep{-(1/2)\\\\rho_1+\\\\rho_2}\\n', '  \\\\begin{amat}{2}\\n', '    2  &1    &0  \\\\\\\\\\n', '    0  &5/2  &5\\n', '  \\\\end{amat}                           \\\\\\\\\\n', '  &\\\\grstep[(2/5)\\\\rho_2]{(1/2)\\\\rho_1}\\n', '  \\\\begin{amat}{2}\\n', '    1  &1/2  &0  \\\\\\\\\\n', '    0  &1    &2\\n', '  \\\\end{amat}                        \\\\\\\\\\n', '  &\\\\grstep{-(1/2)\\\\rho_2+\\\\rho_1}\\\\;\\n', '  \\\\begin{amat}{2}\\n', '    1  &0    &-1  \\\\\\\\\\n', '    0  &1    &2\\n', '  \\\\end{amat}                       \\n', '\\\\end{align*}\\n', 'Denoting those matrices $A\\\\rightarrow D\\\\rightarrow G\\\\rightarrow B$\\n', 'and writing the rows of $A$ as $\\\\alpha_1$ and $\\\\alpha_2$, etc., we have this.\\n', '\\\\begin{align*}  % multline looks worse\\n', '  \\\\left(\\\\begin{array}{l}\\n', '    \\\\alpha_1 \\\\\\\\\\n', '    \\\\alpha_2\\n', '  \\\\end{array}\\\\right)\\n', '  &\\\\grstep{-(1/2)\\\\rho_1+\\\\rho_2}\\n', '  \\\\left(\\\\begin{array}{l}\\n', '    \\\\delta_1=\\\\alpha_1 \\\\\\\\\\n', '    \\\\delta_2=-(1/2)\\\\alpha_1+\\\\alpha_2\\n', '  \\\\end{array}\\\\right)                          \\\\\\\\\\n', '  &\\\\grstep[(2/5)\\\\rho_2]{(1/2)\\\\rho_1}\\n', '  \\\\left(\\\\begin{array}{l}\\n', '    \\\\gamma_1=(1/2)\\\\alpha_1 \\\\\\\\\\n', '    \\\\gamma_2=-(1/5)\\\\alpha_1+(2/5)\\\\alpha_2\\n', '  \\\\end{array}\\\\right)                          \\\\\\\\\\n', '  &\\\\grstep{-(1/2)\\\\rho_2+\\\\rho_1}\\n', '  \\\\left(\\\\begin{array}{l}\\n', '    \\\\beta_1=(3/5)\\\\alpha_1-(1/5)\\\\alpha_2  \\\\\\\\\\n', '    \\\\beta_2=-(1/5)\\\\alpha_1+(2/5)\\\\alpha_2\\n', '  \\\\end{array}\\\\right)                         \\n', '\\\\end{align*} \\n', '\\\\end{example}\\n', '\\n', '\\\\begin{example}\\n', 'The fact that Gaussian operations combine rows linearly \\n', 'also holds if there is a row swap.\\n', 'With this \\\\( A \\\\), \\\\( D \\\\), \\\\( G \\\\), and \\\\( B \\\\)\\n', '\\\\begin{equation*}\\n', '    \\\\begin{mat}[r]\\n', '       0  &2  \\\\\\\\\\n', '       1  &1\\n', '     \\\\end{mat}\\n', '    \\\\grstep{\\\\rho_1\\\\leftrightarrow\\\\rho_2}\\n', '    \\\\begin{mat}[r]\\n', '       1  &1  \\\\\\\\\\n', '       0  &2\\n', '     \\\\end{mat}                  \\n', '    \\\\grstep{(1/2)\\\\rho_2}\\n', '    \\\\begin{mat}[r]\\n', '       1  &1  \\\\\\\\\\n', '       0  &1\\n', '     \\\\end{mat}                   \\n', '    \\\\grstep{-\\\\rho_2+\\\\rho_1}\\n', '    \\\\begin{mat}[r]\\n', '       1  &0  \\\\\\\\\\n', '       0  &1\\n', '     \\\\end{mat}\\n', '\\\\end{equation*}\\n', 'we get these linear\\n', 'relationships. \\n', '\\\\begin{multline*}\\n', '  \\\\left(\\\\begin{array}{l}\\n', '    \\\\vec{\\\\alpha}_1 \\\\\\\\\\n', '    \\\\vec{\\\\alpha}_2\\n', '  \\\\end{array}\\\\right)\\n', '  \\\\,\\\\grstep{\\\\rho_1\\\\leftrightarrow\\\\rho_2}\\\\,\\n', '  \\\\left(\\\\begin{array}{l}\\n', '     \\\\vec{\\\\delta}_1 =\\\\vec{\\\\alpha}_2   \\\\\\\\\\n', '     \\\\vec{\\\\delta}_2 =\\\\vec{\\\\alpha}_1\\n', '  \\\\end{array}\\\\right)                                                 \\n', '  \\\\,\\\\grstep{(1/2)\\\\rho_2}\\\\,\\n', '  \\\\left(\\\\begin{array}{l}\\n', '     \\\\vec{\\\\gamma}_1 =\\\\vec{\\\\alpha}_2  \\\\\\\\\\n', '     \\\\vec{\\\\gamma}_2 =(1/2)\\\\vec{\\\\alpha}_1\\n', '  \\\\end{array}\\\\right)                                               \\\\\\\\\\n', '  \\\\,\\\\grstep{-\\\\rho_2+\\\\rho_1}\\\\,\\n', '  \\\\left(\\\\begin{array}{l}\\n', '     \\\\vec{\\\\beta}_1 =(-1/2)\\\\vec{\\\\alpha}_1+1\\\\cdot\\\\vec{\\\\alpha}_2   \\\\\\\\\\n', '     \\\\vec{\\\\beta}_2 =(1/2)\\\\vec{\\\\alpha}_1\\n', '  \\\\end{array}\\\\right)\\n', '\\\\end{multline*}\\n', '\\\\end{example}\\n', '\\n', 'In summary, \\n', \"Gauss's Method systematically finds a suitable \\n\", 'sequence of linear combinations \\n', 'of the rows.\\n', '\\n', '% \\\\begin{definition}\\n', '% A \\\\definend{linear combination}\\\\index{linear combination} of \\n', '% \\\\( x_1,\\\\ldots,x_m \\\\)\\n', '% is an expression of the form $c_1x_1+c_2x_2+\\\\,\\\\cdots\\\\,+c_mx_m$\\n', \"% where the \\\\( c \\\\)'s are scalars.\\n\", '%\\\\end{definition}\\n', '\\n', '% \\\\noindent (We have already used the phrase \\n', \"% `linear combination' in this book.\\n\", \"% The meaning is unchanged, but the next result's statement makes\\n\", '% a more formal definition in order.)\\n', '\\n', '\\\\begin{lemma}[Linear Combination Lemma] \\\\label{lm:LinearCombinationLemma} \\\\index{Linear Combination Lemma}\\n', '%<*lm:LinearCombinationLemma>\\n', 'A linear combination of linear combinations is a linear combination.\\n', '%</lm:LinearCombinationLemma>\\n', '\\\\end{lemma}\\n', '\\n', '\\\\begin{proof}\\n', '%<*pf:LinearCombinationLemma>\\n', 'Given the set  \\n', '$c_{1,1}x_1+\\\\dots+c_{1,n}x_n$ through $c_{m,1}x_1+\\\\dots+c_{m,n}x_n$\\n', \"of linear combinations of the $x$'s,\\n\", 'consider a combination of those\\n', '\\\\begin{equation*}\\n', '  d_1(c_{1,1}x_1+\\\\dots+c_{1,n}x_n)\\\\,+\\\\dots+\\\\,d_m(c_{m,1}x_1+\\\\dots+c_{m,n}x_n)\\n', '\\\\end{equation*}\\n', \"where the $d$'s are scalars along with the $c$'s.\\n\", \"Distributing those $d$'s and regrouping gives\\n\", '\\\\begin{equation*}\\n', '  %&=d_1c_{1,1}x_1+\\\\dots+d_1c_{1,n}x_n\\\\,\\n', '  % +d_2c_{2,1}x_1+\\\\dots+\\\\,\\n', '  % d_mc_{1,1}x_1+\\\\dots+d_mc_{1,n}x_n         \\\\\\\\\\n', '  =(d_1c_{1,1}+\\\\dots+d_mc_{m,1})x_1\\\\,+\\\\dots+\\\\,(d_1c_{1,n}+\\\\dots+d_mc_{m,n})x_n\\n', '\\\\end{equation*}\\n', \"which is also a linear combination of the $x$'s.\\n\", '%</pf:LinearCombinationLemma>\\n', '\\\\end{proof}\\n', '\\n', '\\n', '\\\\begin{corollary} \\\\label{cor:RowsOfEqMatsLinCombos}\\n', '%<*co:RowsOfEqMatsLinCombos>\\n', 'Where one matrix reduces to another, each row of the second\\n', 'is a linear combination of the rows of the first.\\n', '%</co:RowsOfEqMatsLinCombos>\\n', '\\\\end{corollary}\\n', '\\n', '% The proof \\n', '% uses induction. % \\\\appendrefs{mathematical induction}\\\\spacefactor=1000 %\\n', '% Before we proceed, here is an outline of the argument.\\n', '% For the base step, we\\n', '% will verify that the proposition is true when reduction \\n', '% can be done in zero row operations.\\n', '% For the inductive step, we will \\n', '% argue that if being able to reduce the first matrix to the second in some\\n', '% number $t\\\\geq 0$ of operations implies that each row of the second is a linear\\n', '% combination of the rows of the first, then being able to reduce the first to\\n', '% the second in $t+1$ operations implies the same thing.\\n', '% Together these prove the result because  \\n', '% the base step shows that it is true in the zero operations case,\\n', '% and then the inductive step\\n', '% implies that it is true in the one operation case, and then the inductive step\\n', '% applied again gives that it is therefore true for two operations, etc.\\n', '\\n', '\\\\begin{proof}\\n', '%<*pf:RowsOfEqMatsLinCombos0>\\n', 'For any two interreducible matrices $A$ and~$B$ there is some\\n', 'minimum number of row operations that will take one to the other.\\n', 'We proceed by induction on that number. \\n', '\\n', 'In the base step, that we can go from one matrix to another using\\n', 'zero reduction operations, the two are equal.\\n', 'Then each row of $B$ is trivially a combination of\\n', \"$A$'s rows $\\\\vec{\\\\beta}_i\\n\", '  =0\\\\cdot\\\\vec{\\\\alpha}_1+\\\\cdots+1\\\\cdot\\\\vec{\\\\alpha}_i+\\\\cdots+0\\\\cdot\\\\vec{\\\\alpha}_m$.\\n', '%</pf:RowsOfEqMatsLinCombos0>\\n', '\\n', '%<*pf:RowsOfEqMatsLinCombos1>\\n', 'For the inductive step assume the inductive hypothesis:~with $k\\\\geq 0$,\\n', 'any matrix that can be derived from \\\\( A \\\\) in \\\\( k \\\\) or fewer operations \\n', \"has rows that are linear combinations of $A$'s rows.\\n\", 'Consider a matrix~$B$ such that reducing \\\\( A \\\\) to~\\\\( B \\\\) \\n', 'requires $k+1$ operations.\\n', 'In that reduction there is a next-to-last matrix~$G$,  \\n', 'so that $A\\\\longrightarrow\\\\cdots\\\\longrightarrow G\\\\longrightarrow B$.\\n', 'The inductive hypothesis applies to this \\\\( G \\\\) \\n', 'because it is only $k$ steps away from \\\\( A \\\\). \\n', 'That is, each row of \\\\( G \\\\)\\n', 'is a linear combination of the rows of \\\\( A \\\\).\\n', '%</pf:RowsOfEqMatsLinCombos1>\\n', '\\n', '%<*pf:RowsOfEqMatsLinCombos2>\\n', 'We will verify that the rows of~$B$ are linear combinations of the rows\\n', 'of~$G$.\\n', 'Then the Linear Combination Lemma, \\\\nearbylemma{lm:LinearCombinationLemma},\\n', 'applies to show that the rows of~$B$ are linear combinations of the rows\\n', 'of~$A$.\\n', '\\n', 'If the row operation taking \\\\( G \\\\) to~\\\\( B \\\\) is a swap then\\n', 'the rows of $B$ are just the rows of $G$ reordered and each row of $B$\\n', 'is a linear combination of the rows of $G$.\\n', 'If the operation taking $G$ to~$B$ is multiplication of a row by a \\n', 'scalar~$c\\\\rho_i$\\n', 'then $\\\\vec{\\\\beta}_i=c\\\\vec{\\\\gamma}_i$ and the other rows are unchanged.\\n', 'Finally, if the row operation is adding a multiple of one row to \\n', 'another $r\\\\rho_i+\\\\rho_j$ \\n', 'then only row~$j$ of $B$ differs from the matching row of~$G$, and \\n', '$\\\\vec{\\\\beta}_j=r\\\\gamma_i+\\\\gamma_j$, \\n', 'which is indeed a linear combinations of the rows of $G$.\\n', '%</pf:RowsOfEqMatsLinCombos2>\\n', '\\n', 'Because we have proved both a base step and an inductive step,  \\n', 'the proposition follows by the principle of mathematical induction.\\n', '\\\\end{proof}\\n', '\\n', \"We now have the insight that Gauss's Method builds \\n\", 'linear combinations of the rows.\\n', 'But of course its goal is to end in echelon form, since that is \\n', 'a particularly\\n', 'basic version of a linear system,\\n', 'as it has isolated the variables.\\n', 'For instance, in this matrix\\n', '\\\\begin{equation*}\\n', '  R=\\\\begin{mat}[r]\\n', '    2  &3  &7  &8  &0  &0  \\\\\\\\\\n', '    0  &0  &1  &5  &1  &1  \\\\\\\\\\n', '    0  &0  &0  &3  &3  &0  \\\\\\\\\\n', '    0  &0  &0  &0  &2  &1\\n', '  \\\\end{mat}\\n', '\\\\end{equation*}\\n', \"$x_1$ has been removed from $x_5$'s equation.\\n\", \"That is, Gauss's Method has made $x_5$'s row in some way independent \\n\", \"of $x_1$'s row.\\n\", '\\n', 'The following result makes this intuition precise.\\n', \"We sometimes refer to Gauss's Method as Gaussian elimination.\\n\", 'What it eliminates is linear relationships among the rows.\\n', '\\n', '\\\\begin{lemma}      \\\\label{le:EchFormNoLinCombo}\\n', '%<*lm:EchFormNoLinCombo>\\n', 'In an echelon form matrix,\\n', 'no nonzero row is a linear combination of the other nonzero rows.\\n', '%</lm:EchFormNoLinCombo>\\n', '\\\\end{lemma}\\n', '\\n', '\\\\begin{proof}\\n', '%<*pf:EchFormNoLinCombo0>\\n', 'Let $R$ be an echelon form matrix and consider its  non-\\\\( \\\\vec{0} \\\\)  rows.\\n', 'First observe that\\n', 'if we have a row written as a combination\\n', 'of the others\\n', '$\\\\vec{\\\\rho}_i=c_1\\\\vec{\\\\rho}_1+\\\\cdots+c_{i-1}\\\\vec{\\\\rho}_{i-1}+\\n', '               c_{i+1}\\\\vec{\\\\rho}_{i+1}+\\\\cdots+c_m\\\\vec{\\\\rho}_m$\\n', 'then we can rewrite that equation as\\n', '\\\\begin{equation*}\\n', '   \\\\vec{0}=c_1\\\\vec{\\\\rho}_1+\\\\cdots+c_{i-1}\\\\vec{\\\\rho}_{i-1}+c_i\\\\vec{\\\\rho}_i+\\n', '               c_{i+1}\\\\vec{\\\\rho}_{i+1}+\\\\cdots+c_m\\\\vec{\\\\rho}_m\\n', '  \\\\tag{$*$}\\n', '\\\\end{equation*}\\n', 'where not all the coefficients are zero; specifically, $c_i=-1$.\\n', 'The converse holds also:~given equation~($*$) where some $c_i\\\\neq 0$ we \\n', 'could express $\\\\vec{\\\\rho}_i$ as a combination of the other rows by \\n', 'moving $c_i\\\\vec{\\\\rho}_i$ to the left and dividing by $-c_i$.\\n', 'Therefore we will have proved the theorem if we\\n', 'show that in~($*$) all of the coefficients are~$0$.\\n', 'For that we use induction on the row number~$i$.\\n', '%</pf:EchFormNoLinCombo0>\\n', '\\n', '%<*pf:EchFormNoLinCombo1>\\n', 'The base case is the first row~$i=1$\\n', '(if there is no such nonzero row, so that $R$ is the zero matrix, then the\\n', 'lemma holds vacuously).\\n', 'Let $\\\\ell_i$ be the column number of the leading entry in row~$i$.\\n', 'Consider the entry of each row that is in column~$\\\\ell_1$.\\n', 'Equation~($*$) gives this.\\n', '\\\\begin{equation*}\\n', '  0=c_1r_{1,\\\\ell_1}+c_2r_{2,\\\\ell_1}+\\\\cdots+c_mr_{m,\\\\ell_1}\\n', '  \\\\tag{$**$}\\n', '\\\\end{equation*}\\n', 'The matrix is in echelon form so\\n', 'every row after the first has a zero entry in that column \\n', '$r_{2,\\\\ell_1}=\\\\cdots=r_{m,\\\\ell_1}=0$.\\n', 'Thus equation~($**$) shows that $c_1=0$, because $r_{1,\\\\ell_1}\\\\neq 0$ as it\\n', 'leads the row.\\n', '%</pf:EchFormNoLinCombo1>\\n', '\\n', '%<*pf:EchFormNoLinCombo2>\\n', 'The inductive step is much the same as the base step.\\n', 'Again consider equation~($*$).\\n', 'We will prove that if the coefficient $c_i$ is $0$\\n', 'for each row index $i\\\\in\\\\set{1,\\\\ldots,k}$ \\n', 'then $c_{k+1}$ is also $0$. \\n', 'We focus on the entries from column~$\\\\ell_{k+1}$. \\n', '\\\\begin{equation*}\\n', '  0=c_1r_{1,\\\\ell_{k+1}}+\\\\cdots+c_{k+1}r_{k+1,\\\\ell_{k+1}}+\\\\cdots+c_mr_{m,\\\\ell_{k+1}}\\n', '\\\\end{equation*}\\n', 'By the inductive hypothesis $c_1$, \\\\ldots $c_k$ are\\n', 'all $0$ so this reduces to the equation\\n', '$0=c_{k+1}r_{k+1,\\\\ell_{k+1}}+\\\\cdots+c_mr_{m,\\\\ell_{k+1}}$.\\n', 'The matrix is in echelon form so the entries\\n', '$r_{k+2,\\\\ell_{k+1}}$, \\\\ldots, $r_{m,\\\\ell_{k+1}}$ are all~$0$.\\n', 'Thus $c_{k+1}=0$, because $r_{k+1,\\\\ell_{k+1}}\\\\neq 0$ as it is the leading entry.\\n', '%</pf:EchFormNoLinCombo2>\\n', '\\\\end{proof}\\n', '\\n', 'With that, we are ready to show that the end product of Gauss-Jordan reduction\\n', 'is unique.\\n', '\\n', '\\\\begin{theorem}\\n', '\\\\label{th:ReducedEchelonFormIsUnique}\\n', '%<*th:ReducedEchelonFormIsUnique>\\n', 'Each matrix is row equivalent to a unique reduced echelon form matrix.\\n', '%</th:ReducedEchelonFormIsUnique>\\n', '\\\\end{theorem}\\n', '\\n', '\\\\begin{proof} \\\\cite{Yuster}\\n', '%<*pf:ReducedEchelonFormIsUnique0>\\n', 'Fix a number of rows \\\\( m \\\\).\\n', 'We will proceed by induction on the number of columns \\\\( n \\\\).\\n', '\\n', 'The base case is that the matrix has \\\\( n=1 \\\\) column.\\n', 'If this is the zero matrix then its echelon form is the zero matrix. \\n', 'If instead it has any nonzero entries then when the matrix is brought to \\n', 'reduced echelon form it must have at least one nonzero entry, which must be a\\n', '\\\\( 1 \\\\) in the first row. \\n', 'Either way, its reduced echelon form is unique.\\n', '%</pf:ReducedEchelonFormIsUnique0>\\n', '\\n', '%<*pf:ReducedEchelonFormIsUnique1>\\n', 'For the inductive step we assume that \\\\( n>1 \\\\) and that all \\\\( m \\\\)~row\\n', 'matrices having fewer than~\\\\( n \\\\) columns have a unique reduced echelon form.\\n', 'Consider an \\\\( \\\\nbym{m}{n} \\\\) matrix \\\\( A \\\\) and suppose that \\n', '\\\\( B \\\\) and \\\\( C \\\\) are two reduced echelon form matrices derived from \\\\( A \\\\).\\n', 'We will show that these two must be equal.\\n', '%</pf:ReducedEchelonFormIsUnique1>\\n', '\\n', '%<*pf:ReducedEchelonFormIsUnique2>\\n', 'Let \\\\( \\\\hat{A} \\\\) be the matrix consisting of the first \\\\( n-1 \\\\) columns of\\n', '\\\\( A \\\\).\\n', 'Observe that \\n', '% if an $n$~column matrix is in reduced echelon form then any initial\\n', '% set of its columns is also in reduced echelon form, so \\\\( \\\\hat{A} \\\\)\\n', '% is in reduced echelon form. \\n', 'any sequence of row operations that bring \\\\( A \\\\) to reduced \\n', 'echelon form will also bring \\\\( \\\\hat{A} \\\\) to reduced echelon form.\\n', 'By the inductive hypothesis this reduced echelon form of \\\\( \\\\hat{A} \\\\)\\n', 'is unique, so if \\\\( B \\\\) and \\\\( C \\\\) differ then the difference must \\n', 'occur in column~\\\\( n \\\\).\\n', '%</pf:ReducedEchelonFormIsUnique2>\\n', '\\n', 'We finish the inductive step and the argument\\n', 'by showing that the two cannot differ only in that column.\\n', '%<*pf:ReducedEchelonFormIsUnique3>\\n', 'Consider a homogeneous system of equations for which \\\\( A \\\\) is the\\n', 'matrix of coefficients.  \\n', '\\\\begin{equation*}\\n', '  \\\\begin{linsys}{4}\\n', '    a_{1,1}x_1  &+  &a_{1,2}x_2  &+  &\\\\cdots  &+  &a_{1,n}x_n  &=  &0  \\\\\\\\\\n', '    a_{2,1}x_1  &+  &a_{2,2}x_2  &+  &\\\\cdots  &+  &a_{2,n}x_n  &=  &0  \\\\\\\\\\n', '              &&&&&&&\\\\vdotswithin{=}  \\\\\\\\\\n', '    a_{m,1}x_1  &+  &a_{m,2}x_2  &+  &\\\\cdots  &+  &a_{m,n}x_n  &=  &0  \\n', '  \\\\end{linsys}\\n', '  \\\\tag{$*$}\\n', '\\\\end{equation*}\\n', 'By Theorem~One.I.\\\\ref{th:GaussMethod}\\n', '%the first theorem of this chapter \\n', 'the set of solutions to that system\\n', \"is the same as the set of solutions to $B$'s system\\n\", '\\\\begin{equation*}\\n', '  \\\\begin{linsys}{4}\\n', '    b_{1,1}x_1  &+  &b_{1,2}x_2  &+  &\\\\cdots  &+  &b_{1,n}x_n  &=  &0  \\\\\\\\\\n', '    b_{2,1}x_1  &+  &b_{2,2}x_2  &+  &\\\\cdots  &+  &b_{2,n}x_n  &=  &0  \\\\\\\\\\n', '               &&&&&&&\\\\vdotswithin{=}  \\\\\\\\\\n', '    b_{m,1}x_1  &+  &b_{m,2}x_2  &+  &\\\\cdots  &+  &b_{m,n}x_n  &=  &0  \\n', '  \\\\end{linsys}\\n', '  \\\\tag{$**$}\\n', '\\\\end{equation*}\\n', \"and to $C$'s.\\n\", '\\\\begin{equation*}\\n', '  \\\\quad\\n', '  \\\\begin{linsys}{4}\\n', '    c_{1,1}x_1  &+  &c_{1,2}x_2  &+  &\\\\cdots  &+  &c_{1,n}x_n  &=  &0  \\\\\\\\\\n', '    c_{2,1}x_1  &+  &c_{2,2}x_2  &+  &\\\\cdots  &+  &c_{2,n}x_n  &=  &0  \\\\\\\\\\n', '               &&&&&&&\\\\vdotswithin{=}  \\\\\\\\\\n', '    c_{m,1}x_1  &+  &c_{m,2}x_2  &+  &\\\\cdots  &+  &c_{m,n}x_n  &=  &0  \\n', '  \\\\end{linsys}\\n', '  \\\\tag{$\\\\mathord{*}\\\\mathord{*}\\\\mathord{*}$}\\n', '\\\\end{equation*}\\n', '%</pf:ReducedEchelonFormIsUnique3>\\n', '%<*pf:ReducedEchelonFormIsUnique4>\\n', 'With \\\\( B  \\\\) and \\\\( C \\\\) different only in column~\\\\( n \\\\), suppose \\n', 'that they differ in row~\\\\( i \\\\).\\n', 'Subtract row~\\\\( i \\\\) of ($\\\\mathord{*}\\\\mathord{*}\\\\mathord{*}$) from \\n', 'row~\\\\( i \\\\) of ($**$)\\n', 'to get the equation \\n', '\\\\( (b_{i,n}-c_{i,n})\\\\cdot x_n=0 \\\\).\\n', \"We've assumed that \\\\( b_{i,n}\\\\neq c_{i,n} \\\\) and so we get $x_n=0$.\\n\", 'Thus $x_n$ is not a free variable and \\n', 'so in ($**$) and~($\\\\mathord{*}\\\\mathord{*}\\\\mathord{*}$)\\n', 'the \\\\( n \\\\)-th column contains the leading entry of some row, \\n', 'since in an echelon form matrix any\\n', 'column that does not contain a leading entry is associated with \\n', 'a free variable.\\n', '\\n', 'But now, with \\\\( B \\\\) and \\\\( C \\\\) equal on \\n', 'the first \\\\( n-1 \\\\)~columns, by the definition of \\n', 'reduced echeleon form their leading entries in the \\n', '\\\\( n \\\\)-th column are in the same row.\\n', 'And, both leading entries would\\n', 'have to be $1$, and would have to be the only nonzero entries in that column.\\n', 'Therefore \\\\( B=C \\\\).\\n', '%</pf:ReducedEchelonFormIsUnique4>\\n', '\\\\end{proof}\\n', '\\n', 'We have asked whether \\n', 'any two echelon form versions of a linear system \\n', 'have the same number of free variables, and if so are they\\n', 'exactly the same variables?\\n', \"With the prior result we can answer both questions ``yes.''\\n\", 'There is no linear system such\\n', \"that, say, we could apply Gauss's Method \\n\", 'one way and get $y$ and $z$ free but apply it another way \\n', 'and get $y$ and $w$ free.\\n', '\\n', 'Before the proof, \\n', 'recall the distinction between free variables and parameters.\\n', 'This system\\n', '\\\\begin{equation*}\\n', '  \\\\begin{linsys}{3}\\n', '    x &+ &y &  &  &= &1 \\\\\\\\ \\n', '      &  &y &+ &z &= &2  \\n', '  \\\\end{linsys}\\n', '\\\\end{equation*}\\n', 'has one free variable,~$z$, because it is the only variable not leading a row.\\n', 'We have the habit of parametrizing using the free variable $y=2-z$, $x=-1+z$,\\n', 'but we could also parametrize using another variable, such as \\n', '$z=2-y$, $x=1-y$. \\n', 'So the set of parameters is not unique, it is the set of free variables \\n', 'that is unique.\\n', '\\n', '\\\\begin{corollary}\\n', \"If from a starting linear systems we derive by Gauss's Method two \\n\", 'different echelon form systems, then the two have the same free variables.\\n', '\\\\end{corollary}\\n', '\\n', '\\\\begin{proof}\\n', 'The prior result says that the reduced echelon form is unique.\\n', 'We get from any echelon form version to the reduced echelon form by \\n', 'eliminating up,\\n', 'so any echelon form version of a system has the same free variables as the\\n', 'reduced echelon form version. \\n', '\\\\end{proof}\\n', '\\n', 'We close with a recap.\\n', \"In Gauss's Method we start with a matrix and then\\n\", 'derive a sequence of other matrices.\\n', 'We defined two matrices to be related if we can derive one from the other.\\n', 'That relation is an equivalence relation, %\\\\appendrefs{equivalence relation} \\n', 'called row equivalence, and\\n', 'so partitions the set of all matrices into row equivalence classes.\\n', '\\\\begin{center}\\n', '  \\\\includegraphics{gr/mp/ch1.30}\\n', '\\\\end{center}\\n', \"(There are infinitely many matrices in the pictured class, but we've only\\n\", 'got room to show two.)\\n', 'We have proved there is one and only one reduced echelon form matrix in\\n', 'each row equivalence class.\\n', '%<*ReducedEchelonFormIsCanonicalForm>\\n', 'So the reduced echelon form is a\\n', 'canonical form\\\\appendrefs{canonical representatives}\\\\spacefactor=1000\\n', '\\\\index{canonical form!for row equivalence}\\\\index{representative!for row equivalence classes}\\n', 'for row equivalence:\\n', 'the reduced echelon form matrices are\\n', 'representatives of the classes.\\n', '%</ReducedEchelonFormIsCanonicalForm>\\n', '\\\\begin{center}\\n', '  \\\\includegraphics{gr/mp/ch1.31}\\n', '\\\\end{center}\\n', '\\n', 'The idea here is that one way to understand a\\n', 'mathematical situation is by being able to classify the cases that can happen.\\n', 'This is a theme in this book and\\n', 'we have seen this several times already.\\n', 'We classified solution sets of linear systems into the no-elements, \\n', 'one-element, and infinitely-many elements cases.\\n', 'We also classified linear systems with the same number of equations \\n', 'as unknowns into the nonsingular and singular cases.\\n', '\\n', 'Here, where we are investigating row equivalence, we know that the set of all\\n', 'matrices breaks into the row equivalence classes\\n', 'and we now have a way to put our finger on each of those\\n', 'classes\\\\Dash we can think of the matrices in a class \\n', 'as derived by row operations from the\\n', 'unique reduced echelon form matrix in that class.\\n', '\\n', 'Put in more operational terms, uniqueness of reduced echelon form\\n', 'lets us\\n', 'answer questions about the classes by translating them\\n', 'into questions about the representatives.\\n', \"For instance, as promised in this section's opening, we now can\\n\", 'decide whether one matrix can be derived from another by row reduction.\\n', 'We apply the Gauss-Jordan procedure to both and see if\\n', 'they yield the same reduced echelon form.\\n', '\\n', '\\\\begin{example}  \\\\label{ex:MatsNotRowEq}\\n', 'These matrices are not row equivalent\\n', '\\\\begin{equation*}\\n', '  \\\\begin{mat}[r]\\n', '    1  &-3  \\\\\\\\\\n', '   -2  &6\\n', '  \\\\end{mat}\\n', '  \\\\qquad\\n', '  \\\\begin{mat}[r]\\n', '    1  &-3  \\\\\\\\\\n', '   -2  &5\\n', '  \\\\end{mat}\\n', '\\\\end{equation*}\\n', 'because their reduced echelon forms are not equal.\\n', '\\\\begin{equation*}\\n', '  \\\\begin{mat}[r]\\n', '    1  &-3  \\\\\\\\\\n', '    0  &0\\n', '  \\\\end{mat}\\n', '  \\\\qquad\\n', '  \\\\begin{mat}[r]\\n', '    1  &0   \\\\\\\\\\n', '    0  &1\\n', '  \\\\end{mat}\\n', '\\\\end{equation*}\\n', '\\\\end{example}\\n', '\\n', '\\\\begin{example}\\n', 'Any nonsingular \\\\( \\\\nbyn{3} \\\\) matrix Gauss-Jordan reduces to this.\\n', '\\\\begin{equation*}\\n', '    \\\\begin{mat}[r]\\n', '      1  &0  &0 \\\\\\\\\\n', '      0  &1  &0 \\\\\\\\\\n', '      0  &0  &1\\n', '    \\\\end{mat}\\n', '\\\\end{equation*}\\n', '\\\\end{example}\\n', '\\n', '\\\\begin{example} \\\\label{ex:RowEqClassTwoTwoMats}\\n', 'We can describe all the classes by listing all possible\\n', 'reduced echelon form matrices.\\n', 'Any $\\\\nbyn{2}$ matrix lies in one of these:~the class of matrices\\n', 'row equivalent to this,\\n', '\\\\begin{equation*}\\n', '  \\\\begin{mat}[r]\\n', '     0  &0  \\\\\\\\\\n', '     0  &0\\n', '  \\\\end{mat}\\n', '\\\\end{equation*}\\n', 'the infinitely many classes of matrices row equivalent to one of this type\\n', '\\\\begin{equation*}\\n', '  \\\\begin{mat}\\n', '     1  &a  \\\\\\\\\\n', '     0  &0\\n', '  \\\\end{mat}\\n', '\\\\end{equation*}\\n', 'where \\\\( a\\\\in\\\\Re \\\\) (including $a=0$),\\n', 'the class of matrices row equivalent to this,\\n', '\\\\begin{equation*}\\n', '  \\\\begin{mat}[r]\\n', '     0  &1  \\\\\\\\\\n', '     0  &0\\n', '  \\\\end{mat}\\n', '\\\\end{equation*}\\n', 'and the class of matrices row equivalent to this\\n', '\\\\begin{equation*}\\n', '  \\\\begin{mat}[r]\\n', '     1  &0  \\\\\\\\\\n', '     0  &1\\n', '  \\\\end{mat}\\n', '\\\\end{equation*}\\n', '(this is the class of nonsingular $\\\\nbyn{2}$ matrices).\\n', '\\\\end{example}\\n', '\\n', '\\n', '\\n', '\\\\begin{exercises}\\n', '  \\\\recommended \\\\item \\n', '    Decide if the matrices are row equivalent.\\n', '    \\\\begin{exparts*}\\n', '       \\\\partsitem \\\\(\\n', '           \\\\begin{mat}[r]\\n', '             1  &2  \\\\\\\\\\n', '             4  &8\\n', '           \\\\end{mat}, \\n', '           \\\\begin{mat}[r]\\n', '             0  &1  \\\\\\\\\\n', '             1  &2\\n', '           \\\\end{mat} \\\\)\\n', '       \\\\partsitem \\\\(\\n', '           \\\\begin{mat}[r]\\n', '             1  &0  &2  \\\\\\\\\\n', '             3  &-1 &1  \\\\\\\\\\n', '             5  &-1 &5\\n', '           \\\\end{mat},  \\n', '           \\\\begin{mat}[r]\\n', '             1  &0  &2  \\\\\\\\\\n', '             0  &2  &10 \\\\\\\\\\n', '             2  &0  &4\\n', '           \\\\end{mat} \\\\)\\n', '       \\\\partsitem \\\\(\\n', '           \\\\begin{mat}[r]\\n', '             2  &1  &-1 \\\\\\\\\\n', '             1  &1  &0  \\\\\\\\\\n', '             4  &3  &-1\\n', '           \\\\end{mat},  \\n', '           \\\\begin{mat}[r]\\n', '             1  &0  &2  \\\\\\\\\\n', '             0  &2  &10 \\\\\\\\\\n', '           \\\\end{mat} \\\\)\\n', '       \\\\partsitem \\\\(\\n', '           \\\\begin{mat}[r]\\n', '             1  &1  &1  \\\\\\\\\\n', '            -1  &2  &2\\n', '           \\\\end{mat},  \\n', '           \\\\begin{mat}[r]\\n', '             0  &3  &-1 \\\\\\\\\\n', '             2  &2  &5\\n', '           \\\\end{mat} \\\\)\\n', '       \\\\partsitem \\\\(\\n', '           \\\\begin{mat}[r]\\n', '             1  &1  &1  \\\\\\\\\\n', '             0  &0  &3\\n', '           \\\\end{mat},  \\n', '           \\\\begin{mat}[r]\\n', '             0  &1  &2  \\\\\\\\\\n', '             1  &-1 &1\\n', '           \\\\end{mat} \\\\)\\n', '    \\\\end{exparts*}\\n', '    \\\\begin{answer}\\n', '      Bring each to reduced echelon form and compare.\\n', '      \\\\begin{exparts}\\n', '        \\\\partsitem The first gives\\n', '          \\\\begin{equation*}\\n', '            \\\\grstep{-4\\\\rho_1+\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &2  \\\\\\\\\\n', '              0  &0\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          while the second gives\\n', '          \\\\begin{equation*}\\n', '            \\\\grstep{\\\\rho_1\\\\leftrightarrow\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &2  \\\\\\\\\\n', '              0  &1\\n', '            \\\\end{mat}\\n', '            \\\\grstep{-2\\\\rho_2+\\\\rho_1}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  \\\\\\\\\\n', '              0  &1\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          The two reduced echelon form matrices are not identical, and so the\\n', '          original matrices are not row equivalent.\\n', '        \\\\partsitem The first is this.\\n', '          \\\\begin{equation*}\\n', '            \\\\grstep[-5\\\\rho_1+\\\\rho_3]{-3\\\\rho_1+\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &2  \\\\\\\\\\n', '              0  &-1 &-5 \\\\\\\\\\n', '              0  &-1 &-5\\n', '            \\\\end{mat}\\n', '            \\\\grstep{-\\\\rho_2+\\\\rho_3}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &2  \\\\\\\\\\n', '              0  &-1 &-5 \\\\\\\\\\n', '              0  &0  &0\\n', '            \\\\end{mat}\\n', '            \\\\grstep{-\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &2  \\\\\\\\\\n', '              0  &1  &5  \\\\\\\\\\n', '              0  &0  &0\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          The second is this.\\n', '          \\\\begin{equation*}\\n', '            \\\\grstep{-2\\\\rho_1+\\\\rho_3}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &2  \\\\\\\\\\n', '              0  &2  &10 \\\\\\\\\\n', '              0  &0  &0\\n', '            \\\\end{mat}\\n', '            \\\\grstep{(1/2)\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &2  \\\\\\\\\\n', '              0  &1  &5  \\\\\\\\\\n', '              0  &0  &0\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          These two are row equivalent.\\n', '        \\\\partsitem These two are not row equivalent because they have different\\n', '          sizes.\\n', '        \\\\partsitem The first,\\n', '          \\\\begin{equation*}\\n', '            \\\\grstep{\\\\rho_1+\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &1  &1  \\\\\\\\\\n', '              0  &3  &3\\n', '            \\\\end{mat}\\n', '            \\\\grstep{(1/3)\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &1  &1  \\\\\\\\\\n', '              0  &1  &1\\n', '            \\\\end{mat}\\n', '            \\\\grstep{-\\\\rho_2+\\\\rho_1}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &0  \\\\\\\\\\n', '              0  &1  &1\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          and the second.\\n', '          \\\\begin{equation*}\\n', '            \\\\grstep{\\\\rho_1\\\\leftrightarrow\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              2  &2  &5  \\\\\\\\\\n', '              0  &3  &-1\\n', '            \\\\end{mat}\\n', '            \\\\grstep[(1/3)\\\\rho_2]{(1/2)\\\\rho_1}\\n', '            \\\\begin{mat}[r]\\n', '              1  &1  &5/2 \\\\\\\\\\n', '              0  &1  &-1/3\\n', '            \\\\end{mat}\\n', '            \\\\grstep{-\\\\rho_2+\\\\rho_1}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &17/6 \\\\\\\\\\n', '              0  &1  &-1/3\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          These are not row equivalent.\\n', '        \\\\partsitem Here the first is\\n', '          \\\\begin{equation*}\\n', '            \\\\grstep{(1/3)\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &1  &1  \\\\\\\\\\n', '              0  &0  &1\\n', '            \\\\end{mat}\\n', '            \\\\grstep{-\\\\rho_2+\\\\rho_1}\\n', '            \\\\begin{mat}[r]\\n', '              1  &1  &0  \\\\\\\\\\n', '              0  &0  &1\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          while this is the second.\\n', '          \\\\begin{equation*}\\n', '            \\\\grstep{\\\\rho_1\\\\leftrightarrow\\\\rho_2}\\n', '            \\\\begin{mat}[r]\\n', '              1  &-1 &1  \\\\\\\\\\n', '              0  &1  &2\\n', '            \\\\end{mat}\\n', '            \\\\grstep{\\\\rho_2+\\\\rho_1}\\n', '            \\\\begin{mat}[r]\\n', '              1  &0  &3  \\\\\\\\\\n', '              0  &1  &2\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          These are not row equivalent.\\n', '       \\\\end{exparts}  \\n', '     \\\\end{answer}\\n', '  \\\\item \\n', '    Which of these matrices are row equivalent to each other?\\n', '    \\\\begin{exparts*}\\n', '      \\\\partsitem\\n', '         \\\\(\\\\begin{mat}\\n', '             1 &3 \\\\\\\\\\n', '             2 &4\\n', '           \\\\end{mat}\\\\)\\n', '      \\\\partsitem\\n', '         \\\\(\\\\begin{mat}\\n', '             1 &5 \\\\\\\\\\n', '             2 &10\\n', '           \\\\end{mat}\\\\)\\n', '      \\\\partsitem\\n', '         \\\\(\\\\begin{mat}\\n', '             1 &-1 \\\\\\\\\\n', '             3 &0\\n', '           \\\\end{mat}\\\\)\\n', '      \\\\partsitem\\n', '         \\\\(\\\\begin{mat}\\n', '             2 &6 \\\\\\\\\\n', '             4 &10\\n', '           \\\\end{mat}\\\\)\\n', '      \\\\partsitem\\n', '         \\\\(\\\\begin{mat}\\n', '             0  &1 \\\\\\\\\\n', '             -1 &0\\n', '           \\\\end{mat}\\\\)\\n', '      \\\\partsitem\\n', '         \\\\(\\\\begin{mat}\\n', '             3 &3 \\\\\\\\\\n', '             2 &2\\n', '           \\\\end{mat}\\\\)\\n', '    \\\\end{exparts*}\\n', '    \\\\begin{answer}\\n', '      Perform Gauss-Jordan reduction on each.\\n', '      Two matrices are row-equivalent if and only if they have the same\\n', '      reduced echelon form.\\n', '      Here is the reduced form for each. \\n', '      % sage: M = matrix(QQ, [[1,3], [2,4]])\\n', '      % sage: gauss_jordan(M)\\n', '      % [1 3]\\n', '      % [2 4]\\n', '      %  take -2 times row 1 plus row 2\\n', '      % [ 1  3]\\n', '      % [ 0 -2]\\n', '      %  take -1/2 times row 2\\n', '      % [1 3]\\n', '      % [0 1]\\n', '      %  take -3 times row 2 plus row 1\\n', '      % [1 0]\\n', '      % [0 1]\\n', '      % sage: M = matrix(QQ, [[1,5], [2,10]])\\n', '      % sage: gauss_jordan(M)\\n', '      % [ 1  5]\\n', '      % [ 2 10]\\n', '      %  take -2 times row 1 plus row 2\\n', '      % [1 5]\\n', '      % [0 0]\\n', '      % sage: M = matrix(QQ, [[1,-1], [3,0]])\\n', '      % sage: gauss_jordan(M)\\n', '      % [ 1 -1]\\n', '      % [ 3  0]\\n', '      %  take -3 times row 1 plus row 2\\n', '      % [ 1 -1]\\n', '      % [ 0  3]\\n', '      %  take 1/3 times row 2\\n', '      % [ 1 -1]\\n', '      % [ 0  1]\\n', '      %  take 1 times row 2 plus row 1\\n', '      % [1 0]\\n', '      % [0 1]\\n', '      % sage: M = matrix(QQ, [[2,6], [4,10]])\\n', '      % sage: gauss_jordan(M)\\n', '      % [ 2  6]\\n', '      % [ 4 10]\\n', '      %  take -2 times row 1 plus row 2\\n', '      % [ 2  6]\\n', '      % [ 0 -2]\\n', '      %  take 1/2 times row 1\\n', '      %  take -1/2 times row 2\\n', '      % [1 3]\\n', '      % [0 1]\\n', '      %  take -3 times row 2 plus row 1\\n', '      % [1 0]\\n', '      % [0 1]\\n', '      % sage: M = matrix(QQ, [[0,1], [-1,0]])\\n', '      % sage: gauss_jordan(M)\\n', '      % [ 0  1]\\n', '      % [-1  0]\\n', '      %  swap row 1 with row 2\\n', '      % [-1  0]\\n', '      % [ 0  1]\\n', '      %  take -1 times row 1\\n', '      % [1 0]\\n', '      % [0 1]\\n', '      % sage: M = matrix(QQ, [[3,3], [2,2]])\\n', '      % sage: gauss_jordan(M)\\n', '      % [3 3]\\n', '      % [2 2]\\n', '      %  take -2/3 times row 1 plus row 2\\n', '      % [3 3]\\n', '      % [0 0]\\n', '      %  take 1/3 times row 1\\n', '      % [1 1]\\n', '      % [0 0]\\n', '      \\\\begin{exparts*}\\n', '        \\\\partsitem\\n', '          \\\\(\\\\begin{mat}\\n', '              1  &0  \\\\\\\\\\n', '              0  &1\\n', '            \\\\end{mat} \\\\)\\n', '        \\\\partsitem\\n', '          \\\\(\\\\begin{mat}\\n', '              1  &5  \\\\\\\\\\n', '              0  &0\\n', '            \\\\end{mat} \\\\)\\n', '        \\\\partsitem\\n', '          \\\\(\\\\begin{mat}\\n', '             1   &0  \\\\\\\\\\n', '             0   &1\\n', '            \\\\end{mat} \\\\)\\n', '        \\\\partsitem\\n', '          \\\\(\\\\begin{mat}\\n', '             1   &0  \\\\\\\\\\n', '             0   &1\\n', '            \\\\end{mat} \\\\)\\n', '        \\\\partsitem\\n', '          \\\\(\\\\begin{mat}\\n', '             1   &0  \\\\\\\\\\n', '             0   &1\\n', '            \\\\end{mat} \\\\)\\n', '        \\\\partsitem\\n', '          \\\\(\\\\begin{mat}\\n', '             1   &1  \\\\\\\\\\n', '             0   &0\\n', '            \\\\end{mat} \\\\)\\n', '      \\\\end{exparts*}\\n', '    \\\\end{answer}\\n', ' \\\\item Produce three other matrices row equivalent to the given one.\\n', '   \\\\begin{exparts*}\\n', '     \\\\partsitem \\n', '       \\\\(\\\\begin{mat}\\n', '           1 &3 \\\\\\\\\\n', '           4 &-1\\n', '         \\\\end{mat}\\\\)\\n', '     \\\\partsitem\\n', '       \\\\(\\\\begin{mat}\\n', '           0 &1 &2 \\\\\\\\\\n', '           1 &1 &1  \\\\\\\\\\n', '           2 &3 &4\\n', '         \\\\end{mat}\\\\)\\n', '   \\\\end{exparts*}\\n', '   \\\\begin{answer}\\n', '     For each you can just perform some row operations on the starting\\n', '     matrix.\\n', '     \\\\begin{exparts}\\n', '       \\\\partsitem\\n', '         Multiplying the first row by~$3$ gives this.\\n', '         \\\\begin{equation*}\\n', '           \\\\begin{mat}\\n', '             3 &9  \\\\\\\\\\n', '             4 &-1\\n', '           \\\\end{mat}\\n', '         \\\\end{equation*}\\n', '         (There is no sense to this particular choice of row operation; it is \\n', '         just the first thing that came to mind.)\\n', '         Two other row operations are a row swap $\\\\rho_1\\\\leftrightarrow\\\\rho_2$ \\n', '         and adding $\\\\rho_1+\\\\rho_2$.\\n', '         \\\\begin{equation*}\\n', '           \\\\begin{mat}\\n', '             4 &-1  \\\\\\\\\\n', '             1 &3\\n', '           \\\\end{mat}\\n', '           \\\\quad\\n', '           \\\\begin{mat}\\n', '             1 &3  \\\\\\\\\\n', '             5 &2\\n', '           \\\\end{mat}\\n', '         \\\\end{equation*}\\n', '       \\\\partsitem Doing the same three arbitrary row operations gives these\\n', '         three.\\n', '         \\\\begin{equation*}\\n', '          \\\\begin{mat} \\n', '           0 &3 &6 \\\\\\\\\\n', '           1 &1 &1  \\\\\\\\\\n', '           2 &3 &4  \\n', '          \\\\end{mat}\\n', '          \\\\quad         \\n', '          \\\\begin{mat} \\n', '           1 &1 &1  \\\\\\\\\\n', '           0 &1 &2 \\\\\\\\\\n', '           2 &3 &4  \\n', '          \\\\end{mat}\\n', '          \\\\quad         \\n', '          \\\\begin{mat} \\n', '           0 &1 &2 \\\\\\\\\\n', '           1 &2 &3  \\\\\\\\\\n', '           2 &3 &4  \\n', '          \\\\end{mat}\\n', '          \\\\quad         \\n', '         \\\\end{equation*}\\n', '     \\\\end{exparts}\\n', '   \\\\end{answer}\\n', \"  \\\\recommended \\\\item Perform Gauss's Method on this matrix.\\n\", '    Express each row of the final matrix as a linear combination of \\n', '    the rows of the starting matrix.\\n', '    \\\\begin{equation*}\\n', '      \\\\begin{mat}\\n', '        1 &2   &1 \\\\\\\\\\n', '        3 &-1  &0 \\\\\\\\\\n', '        0 &4   &0\\n', '      \\\\end{mat}\\n', '    \\\\end{equation*}\\n', '    \\\\begin{answer}\\n', '      The Gaussian reduction is routine.\\n', '      % sage: load(\"gauss_method.sage\")\\n', '      % sage: M = matrix (QQ, [[1,2,1], [3,-1,0], [0,4,0]])\\n', '      % sage: gauss_method(M)\\n', '      % [ 1  2  1]\\n', '      % [ 3 -1  0]\\n', '      % [ 0  4  0]\\n', '      %  take -3 times row 1 plus row 2\\n', '      % [ 1  2  1]\\n', '      % [ 0 -7 -3]\\n', '      % [ 0  4  0]\\n', '      %  take 4/7 times row 2 plus row 3\\n', '      % [    1     2     1]\\n', '      % [    0    -7    -3]\\n', '      % [    0     0 -12/7]\\n', '      \\\\begin{equation*}\\n', '        \\\\begin{mat}\\n', '          1 &2   &1 \\\\\\\\\\n', '          3 &-1  &0 \\\\\\\\\\n', '          0 &4   &0\\n', '        \\\\end{mat}\\n', '        \\\\grstep{-3\\\\rho_1+\\\\rho_2}    \\n', '        \\\\begin{mat}\\n', '          1 &2   &1 \\\\\\\\\\n', '          0 &-7  &-3 \\\\\\\\\\n', '          0 &4   &0\\n', '        \\\\end{mat}\\n', '        \\\\grstep{(4/7)\\\\rho_2+\\\\rho_3}    \\n', '        \\\\begin{mat}\\n', '          1 &2   &1 \\\\\\\\\\n', '          0 &-7  &-3 \\\\\\\\\\n', '          0 &0   &-12/7\\n', '        \\\\end{mat}\\n', '      \\\\end{equation*}\\n', '      Denoting those matrices $A$, $D$, and~$B$ respectively, we have this.\\n', '      \\\\begin{align*}\\n', '        \\\\begin{mat}\\n', '          \\\\alpha_1 \\\\\\\\\\n', '          \\\\alpha_2 \\\\\\\\\\n', '          \\\\alpha_3\\n', '        \\\\end{mat}\\n', '        &\\\\grstep{-3\\\\rho_1+\\\\rho_2}    \\n', '        \\\\begin{mat}\\n', '          \\\\delta_1=\\\\alpha_1 \\\\\\\\\\n', '          \\\\delta_2=-3\\\\alpha_1+\\\\alpha_2 \\\\\\\\\\n', '          \\\\delta_3=\\\\alpha_3\\n', '        \\\\end{mat}                                   \\\\\\\\\\n', '        & \\\\grstep{(4/7)\\\\rho_2+\\\\rho_3}\\n', '        \\\\begin{mat}\\n', '          \\\\beta_1=\\\\alpha_1  \\\\\\\\\\n', '          \\\\beta_2=-3\\\\alpha_1+\\\\alpha_2 \\\\\\\\\\n', '          \\\\beta_3=-(12/7)\\\\alpha_1+(4/7)\\\\alpha_2+\\\\alpha_3\\n', '        \\\\end{mat}\\n', '      \\\\end{align*}\\n', '    \\\\end{answer}\\n', '  \\\\item \\n', '     Describe the matrices in each of the classes represented in\\n', '     \\\\nearbyexample{ex:RowEqClassTwoTwoMats}.\\n', '     \\\\begin{answer}\\n', '       First, the only matrix row equivalent to the matrix of all\\n', \"       \\\\( 0 \\\\)'s is itself (since row operations have no effect).\\n\", '\\n', '       Second, the matrices that reduce to \\n', '       \\\\begin{equation*}\\n', '         \\\\begin{mat}\\n', '           1  &a  \\\\\\\\\\n', '           0  &0\\n', '         \\\\end{mat}\\n', '       \\\\end{equation*}\\n', '       have the form\\n', '       \\\\begin{equation*}\\n', '         \\\\begin{mat}\\n', '           b  &ba \\\\\\\\\\n', '           c  &ca\\n', '         \\\\end{mat}\\n', '       \\\\end{equation*}\\n', '       (where \\\\( a,b,c\\\\in\\\\Re \\\\), and \\\\(b\\\\) and \\\\(c\\\\) are not both zero).  \\n', '\\n', '       Next, the matrices that reduce to \\n', '       \\\\begin{equation*}\\n', '         \\\\begin{mat}[r]\\n', '           0  &1  \\\\\\\\\\n', '           0  &0\\n', '         \\\\end{mat}\\n', '       \\\\end{equation*}\\n', '       have the form\\n', '       \\\\begin{equation*}\\n', '         \\\\begin{mat}\\n', '           0  &a \\\\\\\\\\n', '           0  &b\\n', '         \\\\end{mat}\\n', '       \\\\end{equation*}\\n', '       (where \\\\( a,b\\\\in\\\\Re \\\\), and not both are zero).  \\n', '\\n', '       Finally, the matrices that reduce to \\n', '       \\\\begin{equation*}\\n', '         \\\\begin{mat}[r]\\n', '           1  &0  \\\\\\\\\\n', '           0  &1\\n', '         \\\\end{mat}\\n', '       \\\\end{equation*}\\n', '       are the nonsingular matrices.\\n', \"       That's because a linear system for which this is the matrix of\\n\", '       coefficients will have a unique solution, and that is the definition\\n', '       of nonsingular.\\n', '       (Another way to say the same thing is to say that they fall into none\\n', '       of the above classes.)\\n', '     \\\\end{answer}\\n', '  \\\\item \\n', '    Describe all matrices in the row equivalence class of\\n', '    these.\\n', '    \\\\begin{exparts*}\\n', '       \\\\partsitem  \\\\(\\n', '           \\\\begin{mat}[r]\\n', '             1  &0  \\\\\\\\\\n', '             0  &0\\n', '           \\\\end{mat}  \\\\)\\n', '       \\\\partsitem  \\\\(\\n', '           \\\\begin{mat}[r]\\n', '             1  &2      \\\\\\\\\\n', '             2  &4\\n', '           \\\\end{mat} \\\\)\\n', '       \\\\partsitem \\\\(\\n', '           \\\\begin{mat}[r]\\n', '             1  &1      \\\\\\\\\\n', '             1  &3\\n', '           \\\\end{mat} \\\\)\\n', '    \\\\end{exparts*}\\n', '    \\\\begin{answer}\\n', '      \\\\begin{exparts}\\n', '        \\\\partsitem They have the form\\n', '          \\\\begin{equation*}\\n', '            \\\\begin{mat}\\n', '              a  &0  \\\\\\\\\\n', '              b  &0\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          where at least one of \\\\( a,b\\\\in\\\\Re \\\\) is nonzero.\\n', '        \\\\partsitem They have this form \\n', '          \\\\begin{equation*}\\n', '            \\\\begin{mat}\\n', '             a  &2a \\\\\\\\\\n', '             b  &2b\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          where at least one of \\\\( a,b\\\\in\\\\Re \\\\) is nonzero.\\n', '        \\\\partsitem The given matrix is nonsingular.\\n', '          So the row equivalence class consists of all nonsinglar $\\\\nbyn{2}$\\n', '          matrices.\\n', '          (To give a formula, they have the form\\n', '          \\\\begin{equation*}\\n', '            \\\\begin{mat}\\n', '              a  &b  \\\\\\\\\\n', '              c  &d\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          for \\\\( a,b,c,d\\\\in\\\\Re \\\\)) where \\\\( ad-bc\\\\neq 0 \\\\).\\n', '          We will see in Chapter Four that this formula \\n', '          determines when a \\\\( \\\\nbyn{2} \\\\) matrix\\n', '          is nonsingular.)\\n', '      \\\\end{exparts}  \\n', '    \\\\end{answer}\\n', '  \\\\item \\n', '    How many row equivalence classes are there?\\n', '    \\\\begin{answer}\\n', '       Infinitely many.\\n', '       For instance, in \\n', '       \\\\begin{equation*}\\n', '         \\\\begin{mat}\\n', '           1  &k  \\\\\\\\\\n', '           0  &0\\n', '         \\\\end{mat}\\n', '       \\\\end{equation*}\\n', '       each $k\\\\in\\\\Re$ gives a different class.  \\n', '    \\\\end{answer}\\n', '  \\\\item \\n', '    Can row equivalence classes contain different-sized matrices?\\n', '    \\\\begin{answer}\\n', '      No.\\n', '      Row operations do not change the size of a matrix.  \\n', '    \\\\end{answer}\\n', '  \\\\item \\n', '    How big are the row equivalence classes?\\n', '    \\\\begin{exparts} \\n', '      \\\\partsitem Show that for any matrix of all zeros, the class is finite.\\n', '      \\\\partsitem Do any other classes contain only finitely many members?\\n', '    \\\\end{exparts}\\n', '    \\\\begin{answer}\\n', '     \\\\begin{exparts}\\n', '      \\\\partsitem A row operation on a matrix of zeros has no effect.\\n', '        Thus each such matrix is alone in its row equivalence class.  \\n', '      \\\\partsitem No.\\n', '        Any nonzero entry can be rescaled.\\n', '     \\\\end{exparts}\\n', '    \\\\end{answer}\\n', '  \\\\recommended \\\\item \\n', '    Give two reduced echelon form matrices that have their leading\\n', '    entries in the same columns,\\n', '    but that are not row equivalent.\\n', '    \\\\begin{answer}\\n', '      Here are two.\\n', '      \\\\begin{equation*}\\n', '        \\\\begin{mat}[r]\\n', '          1  &1  &0  \\\\\\\\\\n', '          0  &0  &1\\n', '        \\\\end{mat}\\n', '        \\\\quad\\\\text{and}\\\\quad\\n', '        \\\\begin{mat}[r]\\n', '          1  &0  &0  \\\\\\\\\\n', '          0  &0  &1\\n', '        \\\\end{mat}\\n', '      \\\\end{equation*}  \\n', '     \\\\end{answer}\\n', '  \\\\recommended \\\\item \\n', '    Show that any two \\\\( \\\\nbyn{n} \\\\) nonsingular matrices are\\n', '    row equivalent.\\n', '    Are any two singular matrices row equivalent?\\n', '    \\\\begin{answer}\\n', '      Any two \\\\( \\\\nbyn{n} \\\\) nonsingular matrices have\\n', '      the same reduced echelon\\n', \"      form, namely the matrix with all \\\\( 0 \\\\)'s except for \\\\( 1 \\\\)'s down\\n\", '      the diagonal.\\n', '      \\\\begin{equation*}\\n', '        \\\\begin{mat}\\n', '          1  &0  &       &0  \\\\\\\\\\n', '          0  &1  &       &0  \\\\\\\\\\n', '             &   &\\\\ddots &   \\\\\\\\\\n', '          0  &0  &       &1\\n', '        \\\\end{mat}\\n', '      \\\\end{equation*}\\n', '\\n', '      Two same-sized singular matrices need not be row equivalent.\\n', '      For example, these two \\\\( \\\\nbyn{2} \\\\) singular matrices\\n', '      are not row equivalent.\\n', '      \\\\begin{equation*}\\n', '        \\\\begin{mat}[r]\\n', '          1  &1  \\\\\\\\\\n', '          0  &0\\n', '        \\\\end{mat}\\n', '        \\\\quad\\\\text{and}\\\\quad\\n', '        \\\\begin{mat}[r]\\n', '          1  &0  \\\\\\\\\\n', '          0  &0\\n', '        \\\\end{mat}\\n', '      \\\\end{equation*}  \\n', '    \\\\end{answer}\\n', '  \\\\recommended \\\\item \\n', '    Describe all of the row equivalence classes containing these.\\n', '    \\\\begin{exparts*}\\n', '      \\\\partsitem \\\\( \\\\nbyn{2} \\\\)~matrices\\n', '      \\\\partsitem \\\\( \\\\nbym{2}{3} \\\\)~matrices\\n', '      \\\\partsitem \\\\( \\\\nbym{3}{2} \\\\)~matrices\\n', '      \\\\partsitem \\\\( \\\\nbyn{3} \\\\)~matrices\\n', '    \\\\end{exparts*}\\n', '    \\\\begin{answer}\\n', '      Since there is one and only one reduced echelon form matrix in each\\n', '      class, we can just list the possible reduced echelon form matrices.\\n', '\\n', '      For that list, see the answer for \\\\nearbyexercise{exer:PossRedEchFrms}. \\n', '    \\\\end{answer}\\n', '  \\\\item  \\n', '     \\\\begin{exparts}\\n', '          \\\\partsitem Show that a vector $\\\\vec{\\\\beta}_0$ is a linear combination\\n', '            of members of the set $\\\\set{\\\\vec{\\\\beta}_1,\\\\ldots,\\\\vec{\\\\beta}_n}$\\n', '            if and only if there is a linear relationship \\n', '            $\\\\zero=c_0\\\\vec{\\\\beta}_0+\\\\cdots+c_n\\\\vec{\\\\beta}_n$\\n', '            where $c_0$ is not zero.\\n', '            (\\\\textit{Hint.}   Watch out for the $\\\\vec{\\\\beta}_0=\\\\zero$ case.)\\n', '         \\\\partsitem Use that to simplify the proof of \\n', '            \\\\nearbylemma{le:EchFormNoLinCombo}.   \\n', '       \\\\end{exparts}\\n', '       \\\\begin{answer}\\n', '          \\\\begin{exparts}\\n', '           \\\\partsitem If there is a linear relationship where $c_0$ is not zero\\n', '             then we can subtract $c_0\\\\vec{\\\\beta}_0$ from both sides and divide\\n', '             by $-c_0$ to get $\\\\vec{\\\\beta}_0$ as a linear\\n', '             combination of the others.\\n', '             (Remark:  \\n', '             if there are no other vectors in the set\\\\Dash if the \\n', '             relationship is, say, \\n', '             $\\\\zero=3\\\\cdot\\\\zero$\\\\Dash then the statement is still true because\\n', '             the zero vector is by definition the sum of the empty set \\n', '             of vectors.)\\n', '\\n', '             Conversely, if $\\\\vec{\\\\beta}_0$ is a combination of the others \\n', '             $\\\\vec{\\\\beta}_0=c_1\\\\vec{\\\\beta}_1+\\\\dots+c_n\\\\vec{\\\\beta}_n$\\n', '             then subtracting\\n', '             $\\\\vec{\\\\beta}_0$ from both sides gives a relationship where \\n', '             at least one\\n', '             of the coefficients is nonzero; namely,\\n', '             the $-1$ in front of $\\\\vec{\\\\beta}_0$.\\n', '           \\\\partsitem The first row is not a linear combination of the\\n', '             others for\\n', '             the reason given in the proof:~in the equation of components from\\n', '             the column containing the leading entry of the first row, the\\n', '             only nonzero entry is the leading entry from the first row, so\\n', '             its coefficient must be zero.\\n', '             Thus, from the prior part of this exercise, the first row is in\\n', '             no linear relationship with the other rows.\\n', '\\n', '             Thus, when considering whether the second row can be in a linear \\n', '             relationship\\n', '             with the other rows, we can leave the first row out.\\n', '             But now the argument just applied to the first row will apply\\n', '             to the second row.\\n', '             (That is, we are arguing here by induction.)             \\n', '         \\\\end{exparts}\\n', '      \\\\end{answer}\\n', '  % \\\\item \\n', '  %   Why, in the proof of \\\\nearbytheorem{th:ReducedEchelonFormIsUnique},\\n', '  %   do we bother to restrict to the nonzero rows?\\n', '  %   Why not just stick to the relationship that we began with,\\n', '  %   $\\\\beta_i=c_{i,1}\\\\delta_1+\\\\dots+c_{i,m}\\\\delta_m$, with $m$ instead of $r$,\\n', '  %   and argue using it that the only nonzero coefficient\\n', '  %   is \\\\( c_{i,i}  \\\\), which is \\\\( 1 \\\\)?\\n', '  %   \\\\begin{answer}\\n', '  %      The zero rows could have nonzero coefficients, and\\n', '  %      so the statement would not be true.\\n', '  %   \\\\end{answer}\\n', '  \\\\recommended \\\\item \\n', '   \\\\cite{Trono}\\n', '   Three truck drivers went into a roadside cafe.\\n', '   One truck driver purchased four sandwiches, a cup of coffee, and ten \\n', '   doughnuts for \\\\$$8.45$.\\n', '   Another driver purchased three sandwiches, a cup of coffee, and seven\\n', '   doughnuts for \\\\$$6.30$.\\n', '   What did the third truck driver pay for a sandwich, a cup of coffee, and \\n', '   a doughnut?\\n', '   \\\\begin{answer}\\n', \"     We know that $4s+c+10d=8.45$ and that $3s+c+7d=6.30$, and we'd like to\\n\", '     know what $s+c+d$ is.\\n', '     Fortunately, $s+c+d$ is a linear combination of $4s+c+10d$ and $3s+c+7d$.\\n', '     Calling the unknown price $p$, we have this reduction.\\n', '     \\\\begin{align*}\\n', '       \\\\begin{amat}{3}\\n', '         4  &1  &10  &8.45 \\\\\\\\\\n', '         3  &1  &7   &6.30 \\\\\\\\\\n', '         1  &1  &1   &p\\n', '       \\\\end{amat}\\n', '       &\\\\grstep[-(1/4)\\\\rho_1+\\\\rho_3]{-(3/4)\\\\rho_1+\\\\rho_2}\\n', '       \\\\begin{amat}{3}\\n', '         4  &1    &10     &8.45      \\\\\\\\\\n', '         0  &1/4  &-1/2   &-0.037\\\\,5 \\\\\\\\\\n', '         0  &3/4  &-3/2   &p-2.112\\\\,5\\n', '       \\\\end{amat}                                      \\\\\\\\\\n', '       &\\\\grstep{-3\\\\rho_2+\\\\rho_3}\\n', '       \\\\begin{amat}{3}\\n', '         4  &1    &10     &8.45      \\\\\\\\\\n', '         0  &1/4  &-1/2   &-0.037\\\\,5 \\\\\\\\\\n', '         0  &0    &0      &p-2.00\\n', '       \\\\end{amat}\\n', '     \\\\end{align*}\\n', '     The price paid is \\\\$$2.00$.\\n', '   \\\\end{answer}\\n', '  % \\\\item\\n', '  %  The fact that Gaussian reduction disallows multiplication of\\n', '  %  a row by zero is needed for the proof of uniqueness of reduced echelon form,\\n', '  %  or else every matrix would\\n', '  %  be row equivalent to a matrix of all zeros.\\n', '  %  Where is it used?\\n', '  %  \\\\begin{answer}\\n', '  %    If multiplication of a row by zero were allowed then\\n', '  %    \\\\nearbylemma{le:EquivMatsSameForm}\\n', '  %    would not hold.\\n', '  %    That is, where\\n', '  %    \\\\begin{equation*}\\n', '  %      \\\\begin{mat}[r]\\n', '  %        1  &3  \\\\\\\\\\n', '  %        2  &1\\n', '  %      \\\\end{mat}\\n', '  %      \\\\grstep{0\\\\rho_2}\\n', '  %      \\\\begin{mat}[r]\\n', '  %        1  &3  \\\\\\\\\\n', '  %        0  &0\\n', '  %      \\\\end{mat}\\n', '  %    \\\\end{equation*}\\n', '  %    all the rows of the second matrix can be expressed as linear combinations\\n', '  %    of the rows of the first, but the converse does not hold.\\n', '  %    The second row of the first matrix is not a linear combination of the\\n', '  %    rows of the second matrix.  \\n', '  %  \\\\end{answer}\\n', '  \\\\item \\n', '   The Linear Combination Lemma says which equations can be gotten from\\n', '   Gaussian reduction of a given linear system.\\n', '   \\\\begin{enumerate}\\n', '     \\\\item Produce an equation not implied by this system.\\n', '       \\\\begin{equation*}\\n', '         \\\\begin{linsys}{2}\\n', '           3x  &+  &4y  &=  &8 \\\\\\\\\\n', '           2x  &+  & y  &=  &3 \\n', '         \\\\end{linsys}\\n', '       \\\\end{equation*}\\n', '     \\\\item Can any equation be derived from an inconsistent system?\\n', '   \\\\end{enumerate}\\n', '   \\\\begin{answer}\\n', '     \\\\begin{enumerate}\\n', '        \\\\item An easy answer is this.\\n', '          \\\\begin{equation*}\\n', '            0=3\\n', '          \\\\end{equation*}\\n', '          For a less wise-guy-ish answer, solve the system:\\n', '          \\\\begin{equation*}\\n', '            \\\\begin{amat}[r]{2}\\n', '              3  &4  &8  \\\\\\\\\\n', '              2  &1   &3\\n', '            \\\\end{amat}\\n', '            \\\\grstep{-(2/3)\\\\rho_1+\\\\rho_2}\\n', '            \\\\begin{amat}[r]{2}\\n', '              3  &4    &8    \\\\\\\\\\n', '              0  &-5/3 &-7/3\\n', '            \\\\end{amat}\\n', '          \\\\end{equation*}\\n', '          gives \\\\( y=7/5 \\\\) and \\\\( x=4/5 \\\\).\\n', '          Now any equation not satisfied by \\\\( (7/5,4/5) \\\\) will do,\\n', '          e.g., \\\\( 5x+5y=10 \\\\).\\n', '        \\\\item Every equation can be derived from an inconsistent system.\\n', '          For instance, here is how to derive \\\\( 3x+2y=4 \\\\) from\\n', '          \\\\( 0=5 \\\\).\\n', '          First,\\n', '          \\\\begin{equation*}\\n', '            0=5\\n', '            \\\\grstep{(3/5)\\\\rho_1}\\n', '            0=3\\n', '            \\\\grstep{x\\\\rho_1}\\n', '            0=3x\\n', '          \\\\end{equation*}\\n', '          (validity of the \\\\( x=0 \\\\) case is separate but clear).\\n', '          Similarly, \\\\( 0=2y \\\\).\\n', '          Ditto for \\\\( 0=4 \\\\).\\n', '          But now, \\\\( 0+0=0 \\\\) gives \\\\( 3x+2y=4 \\\\).\\n', '     \\\\end{enumerate}  \\n', '    \\\\end{answer}\\n', '  \\\\item \\n', '    \\\\cite{HoffmanKunze}\\n', '    Extend the definition of row equivalence to linear systems.\\n', '    Under your definition, do equivalent systems have the same solution set?\\n', '    \\\\begin{answer}\\n', '      Define linear systems to be equivalent if their augmented\\n', '      matrices are row equivalent.\\n', '      The proof that equivalent systems have the same solution set is easy.  \\n', '    \\\\end{answer}\\n', '  \\\\item \\n', '    In this matrix\\n', '    \\\\begin{equation*}\\n', '      \\\\begin{mat}[r]\\n', '        1  &2  &3  \\\\\\\\\\n', '        3  &0  &3  \\\\\\\\\\n', '        1  &4  &5\\n', '      \\\\end{mat}\\n', '    \\\\end{equation*}\\n', '    the first and second columns add to the third.\\n', '    \\\\begin{exparts}\\n', '      \\\\partsitem Show that remains true under any row operation.\\n', '      \\\\partsitem Make a conjecture.\\n', '      \\\\partsitem Prove that it holds.\\n', '    \\\\end{exparts}\\n', '    \\\\begin{answer}\\n', '      \\\\begin{exparts}\\n', '        \\\\partsitem The three possible row swaps are easy, \\n', '          as are the three possible rescalings.\\n', '          One of the six possible row combinations is \\\\( k\\\\rho_1+\\\\rho_2 \\\\):\\n', '          \\\\begin{equation*}\\n', '            \\\\begin{mat}\\n', '              1           &2           &3  \\\\\\\\\\n', '              k\\\\cdot 1+3  &k\\\\cdot 2+0  &k\\\\cdot 3+3  \\\\\\\\\\n', '              1           &4           &5\\n', '            \\\\end{mat}\\n', '          \\\\end{equation*}\\n', '          and again the first and second columns add to the third.\\n', '          The other five combinations are similar.\\n', '        \\\\partsitem The obvious conjecture is that row operations do not change\\n', '          linear relationships among columns.\\n', '        \\\\partsitem A case-by-case \\n', '          proof follows the sketch given in the first item.\\n', '      \\\\end{exparts}  \\n', '   \\\\end{answer}\\n', '\\\\end{exercises}\\n']\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "feb23f19-0c88-4e7f-b94b-5d7f000f1c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_latex_to_text(latex_line):\n",
    "    patterns = {\n",
    "        r'\\\\cite\\{[^}]*\\}': '',  # Remove citations\n",
    "        r'\\\\(begin|end)\\{[a-zA-Z]*\\*?\\}': '',  # Remove \\begin{} and \\end{} commands\n",
    "        # Specific handling for text preserving macros\n",
    "        r'\\\\definend\\{([^}]*)\\}': r'\\1',  # Preserve the text inside \\definend{}\n",
    "        r'\\\\index\\{[^}]*\\}': '',  # Remove index but keep the text outside it\n",
    "        # General LaTeX command removal, adjusted not to remove encapsulated text\n",
    "        r'\\\\[a-zA-Z]+\\*?(?:\\[[^\\]]*\\])?(?:\\{[^}]*\\})*': '',  # Adjusted to prevent removal of nested text\n",
    "        r'%.*$': '',  # Remove comments\n",
    "        r'\\\\\\\\': '\\n',  # Replace double backslashes with new lines\n",
    "        r'\\\\vec\\{(\\w+)\\}': r'\\1',  # Remove vector command but keep the variable\n",
    "        r'\\\\cdot': '·',  # Convert \\cdot to dot symbol\n",
    "        r'\\$': '',  # Remove dollar signs that might be left from math mode\n",
    "        r'\\\\left|\\\\right': '',  # Remove \\left and \\right modifiers\n",
    "        r'\\\\[()|]': '',  # Remove unnecessary LaTeX symbols like brackets\n",
    "        r'~': ' ',  # Replace tilde with space\n",
    "        r'\\&': '',  # Remove alignment tabs used in equations\n",
    "        r'\\n\\s*\\n': '\\n',  # Replace multiple newlines with a single one\n",
    "        r'\\s{2,}': ' ',  # Replace multiple spaces with a single one\n",
    "    }\n",
    "\n",
    "    for pattern, replacement in patterns.items():\n",
    "        latex_line = re.sub(pattern, replacement, latex_line)\n",
    "    \n",
    "    return latex_line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee986ef4-e2b1-459b-a944-f038afce7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_content = [convert_latex_to_text(line) for line in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d1f9063-2baa-4c34-ba47-4d479305f11b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '{If you have seen the elements of vectors then', 'this section is an optional review.', 'However, later work will refer to this material', 'so if this is not a review then it is not optional.}', '', 'In the first section we had to do a bit of work to show', 'that there are only three types of solution sets singleton, empty, and', 'infinite.', 'But', 'this is easy to see geometrically', 'in the case of systems with two equations and two unknowns.', 'Draw each two-unknowns equation as a line in the plane and then', 'the two lines could have a unique intersection,', 'be parallel, or be the same line.', '', '', '[b]{1.45in}', '[8pt][0pt]{ {@{}l}', '', '}', '', '[.75ex]', '{2}', '3x + 2y = 7', 'x - y = -1', '', '', '', '', '[b]{1.45in}', '[8pt][0pt]{ {@{}l}', '', '}', '', '[.75ex]', '{2}', '3x + 2y = 7', '3x + 2y = 4', '', '', '', '', '[b]{1.45in}', '[8pt][0pt]{ [t]{@{}l}', '', '', '}', '', '[.75ex]', '{2}', '3x + 2y = 7', '6x + 4y = 14', '', '', '', '', '', \"These pictures aren't a short way to prove\", 'the results from the prior section, because those results apply', 'to linear systems with any number of variables.', 'But they do provide a visual insight, another way of seeing those results.', '', 'This section develops what we need to', 'express our results geometrically.', 'In particular, while', 'the two-dimensional case is familiar, to extend to systems with', 'more than two unknowns we shall need some higher-dimensional geometry.', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', \"``Higher-dimensional geometry'' sounds exotic.\", 'It is exotic interesting and eye-opening.', \"But it isn't distant or unreachable.\", '', 'We begin by defining one-dimensional space to be .', 'To see that the definition is reasonable,', 'picture a one-dimensional space', '', '', '', 'and pick a point to label 0 and another to label 1.', '', '', '', 'Now, with a scale and a direction, we have a correspondence with .', 'For instance, to find the point matching', '+2.17 , start at 0 and head in the direction of 1 ,', 'and go 2.17 times as far.', '', 'The basic idea here, combining magnitude with direction, is the', 'key to extending to higher dimensions.', '', 'An object in an ^n that is', 'comprised of a magnitude and a direction is a', 'vector\\\\/', '(we use the same word as in the prior section because we shall show', 'below how to describe such an object with a column vector).', 'We can draw a vector as having some length and pointing in some direction.', '', '', '', 'There is a subtlety involved in the definition of a vector', 'as consisting of a', 'magnitude and a direction these', '', '', '', 'are equal, even though they start in different places', 'They are equal because they have equal lengths and equal directions.', 'Again: those vectors are not just alike, they are equal.', '', 'How can things that are in different places be equal?', 'Think of a vector as representing a displacement', \"(the word `vector' is Latin for ``carrier'' or ``traveler'').\", 'These two squares undergo displacements that are equal', 'despite that they start in different places.', '', '', '', 'When we want to emphasize this property vectors have of not being anchored', 'we refer to them as free vectors.', 'Thus, these free vectors are equal,', 'as each is a displacement of one over and two up.', '', '', '', 'More generally, vectors in the plane', 'are the same if and only if they have the same', 'change in first components and the same change in second components: the', 'vector extending from (a_1,a_2)', 'to (b_1,b_2) equals the vector from', '(c_1,c_2) to (d_1,d_2)', 'if and only if', 'b_1-a_1=d_1-c_1 and b_2-a_2=d_2-c_2 .', '', 'Saying `the vector that, were it to start at (a_1,a_2) ,', \"would extend to (b_1,b_2) ' would be unwieldy.\", 'We instead describe that vector as', '', '', '', \"so that we represent the `one over and two up' arrows shown above in\", 'this way.', '', '', '', 'We often draw the arrow as starting at the origin, and we', 'then say it is in the', 'canonical position', '(or natural position', 'or standard position).', 'When', '', '=', '', 'is in canonical position then it', 'extends from the origin to the endpoint (v_1,v_2).', '', 'We will typically say ``the point', '', '', '', \"rather than ``the endpoint of the canonical position of'' that vector.\", '', '', '', 'Thus, we will call each of these ^2 .', '', '', '', 'x_1,x_2}', '', '', 'In the prior section we defined vectors and vector operations', 'with an algebraic motivation;', '', 'r', '=', '', '', '', '+', '', '=', '', '', 'we can now understand those operations geometrically.', '', '', 'For instance, if represents a displacement', 'then 3\\\\, represents a displacement in the same direction but', 'three times as far', 'and -1\\\\, represents a displacement of the same distance as', '\\\\, but in the opposite direction.', '', '', '', 'And, where and represent displacements,', '+\\\\/ represents those displacements combined.', '', '', '', 'The long arrow is the combined displacement in this sense: imagine that you are', \"walking on a ship's deck.\", 'Suppose that in one minute', \"the ship's motion gives it a displacement\", 'relative to the sea of , and in the same minute your', \"walking gives you a displacement relative to the ship's deck of .\", 'Then +\\\\/ is', 'your displacement relative to the sea.', '', 'Another way to understand the vector sum is with the', 'parallelogram rule.', '', 'Draw the parallelogram', 'formed by the vectors and .', 'Then the sum +', 'extends along the diagonal', 'to the far corner.', '', '', '', '', 'The above drawings show how vectors and vector operations', 'behave in ^2 .', 'We can extend to ^3, or to even higher-dimensional spaces', 'where we have no pictures, with the obvious generalization: the', 'free vector that,', 'if it starts at (a_1,,a_n) , ends at (b_1,,b_n) ,', 'is represented by this column.', '', 'b_n-a_n}', '', 'Vectors are equal if they have the same representation.', \"We aren't too careful about distinguishing between a point and the vector whose\", 'canonical representation ends at that point.', '', '^n=', 'v_n} v_1,,v_n}', '', 'And, we do addition and scalar multiplication component-wise.', '', 'Having considered points, we next turn to lines.', 'In ^2, the line through (1,2) and (3,1)', 'is comprised of (the endpoints of) the vectors in this set.', '', '', '', '', '', '', '', 'In the description the vector that is associated with the parameter t', '', '=-', '', 'is the one shown in the picture as having its whole body in the line it', 'is a direction vector', 'for the line.', 'Note that points on the line to the left of x=1 are described', 'using negative values of t .', '', '', '', 'In ^3 ,', 'the line through (1,2,1) and (0,3,2) is the set of', '(endpoints of) vectors of this form', '', '', '', '', 'and lines in even higher-dimensional spaces work in the same way.', '', 'In ^3,', 'a line uses one parameter so that a particle on that line', 'would be free to move back and forth', 'in one dimension.', 'A plane involves two parameters.', 'For example, the plane through the points', '(1,0,5) , (2,1,-3) , and (-2,4,0.5) consists of', '(endpoints of) the vectors in this set.', '', '', '+t', '+s', 't,s }', '', 'The column vectors associated with the parameters come from', 'these calculations.', '', '', '=', '', '-', '', '', '', '=', '', '-', '', '', 'As with the line, note that we describe some points in this plane', \"with negative t's or negative s's or both.\", '', 'Calculus books often describe a plane by using', 'a single linear equation.', '', '', '', '', '', '', '}', '', '', '', '', 'To translate from this to the vector description,', 'think of this as a one-equation linear system', 'and parametrize: x=2-y/2-z/2 .', '', '}', '', 'Shown in grey are the vectors associated with y and z, offset', 'from the origin by 2 units along the x-axis, so that their entire body lies', 'in the plane.', 'Thus the vector sum of the two, shown in black,', 'has its entire body in the plane along with', 'the rest of the parallelogram.', '', '', '', '', '', '', '', '', '', 'Generalizing, a set of the form', '+t_1_1+t_2_2++t_k_k', 't_1, ,t_k}', 'where _1,,_k^n', 'and k n is a', 'k -dimensional linear surface', '(or k -flat).', 'For example, in ^4', '', '', '+t', 't}', '', 'is a line,', '', '{', '', '+t', '+s', 't,s}', '', 'is a plane, and', '', '{', '', '+r', '+s', '+t', 'r,s,t}', '', 'is a three-dimensional linear surface.', 'Again, the intuition is that a line permits motion in one direction,', 'a plane permits motion in', 'combinations of two directions, etc.', 'When the dimension of the linear surface is one less than the dimension', 'of the space, that is, when in ^n we have an', '(n-1)-flat,', 'the surface is called a hyperplane.', '', 'A description of', 'a linear surface can be misleading about the dimension.', 'For example, this', '', 'L={', '', '+t', '+s', 't,s}', '', 'is a degenerate plane because it is actually a line,', 'since the', 'vectors are multiples of each other and we', 'can omit one.', '', 'L={', '', '+r', 'r}', '', 'We shall see in the Linear Independence section of Chapter Two', 'what relationships among vectors causes the linear surface', 'they generate to be degenerate.', '', 'We now can', 'restate in geometric terms our conclusions from earlier.', 'First, the solution set of a linear system with n unknowns', 'is a linear surface in ^n .', 'Specifically, it is a k -dimensional linear surface, where', 'k is the number of free variables in an echelon form version', 'of the system.', 'For instance, in the single equation case the solution set is an', 'n-1-dimensional hyperplane in ^n, where n 1.', 'Second, the solution set of a homogeneous linear system is a linear surface', 'passing through the origin.', 'Finally, we can view the general solution set of any', 'linear system as being the solution set of its associated homogeneous system', 'offset from the origin by a vector,', 'namely by any particular solution.', '', '', '', '', '', '', 'Find the canonical name for each vector.', '', 'the vector from (2,1) to (4,2) in ^2', 'the vector from (3,3) to (2,5) in ^2', 'the vector from (1,0,6) to (5,0,3) in ^3', 'the vector from (6,8,8) to (6,8,8) in ^3', '', '', '', '', '', '', '', '', '', '', 'Decide if the two vectors are equal.', '', 'the vector from (5,3) to (6,2) and the vector', 'from (1,-2) to (1,1)', 'the vector from (2,1,1) to (3,0,4) and the vector', 'from (5,1,4) to (6,0,7)', '', '', '', 'No, their canonical positions are different.', '', '', '', '', '', 'Yes, their canonical positions are the same.', '', '', '', '', '', '', 'Does (1,0,2,1) lie on the line through', '(-2,1,1,0) and (5,10,-1,4) ?', '', 'That line is this set.', '', '', '+t t }', '', 'Note that this system', '', '{2}', '-2 + 7t = 1', '1 + 9t = 0', '1 - 2t = 2', '0 + 4t = 1', '', '', 'has no solution.', 'Thus the given point is not in the line.', '', '', '', 'Describe the plane through (1,1,5,-1) ,', '(2,2,2,0) , and (3,1,0,4) .', 'Is the origin in that plane?', '', '', '', 'Note that', '', '', '-', '=', '', '', '-', '=', '', 'and so the plane is this set.', '', '', '+t', '+s', 't,s}', '', 'No; this system', '', '{3}', '1 + 1t + 2s = 0', '1 + 1t = 0', '5 - 3t - 5s = 0', '-1 + 1t + 5s = 0', '', '', 'has no solution.', '', '', 'Give a vector description of each.', '', 'the plane subset of ^3 with equation x-2y+z=4', 'the plane in ^3 with equation 2x+y+4z=-1', 'the hyperplane subset of ^4 with equation x+y+z+w=10', '', '', '', 'Think of x-2y+z=4 as a one-equation linear system and', 'parametrize with the variables y and z to get', 'x=4+2y-z.', 'That gives this vector description of the plane.', '', '=', '+ y', '+ z', 'y,z}', '', 'Parametrizing gives x=-(1/2)-(1/2)y-2z,', 'so this is the vector description.', '', '=', '+ y', '+ z', '', 'Here', 'x=10-y-z-w and so we get a vector description with three', 'parameters.', '', '=', '+ y', '+ z', '+ w', '', '', '', '', 'Describe the plane that contains this point and line.', '', '', '', '', '+t', 't}', '', '', 'The vector', '', '', '', 'is not in the line.', 'Because', '', '', '-', '=', '', 'we can describe that plane in this way.', '', '', '+m', '+n', 'm,n}', '', '', '', 'Intersect these planes.', '', 't+', 's', 't,s}', '', '', '+k+', 'm', 'k,m}', '', '', 'The points of coincidence are solutions of this system.', '', '{2}', 't = 1+2m', 't + s = 1+3k', 't + 3s = 4m', '', '', \"Gauss's Method\", '', '{4}', '1 0 0 -2 1', '1 1 -3 0 1', '1 3 0 -4 0', '', '', '{4}', '1 0 0 -2 1', '0 1 -3 2 0', '0 3 0 -2 -1', '', '', '{4}', '1 0 0 -2 1', '0 1 -3 2 0', '0 0 9 -8 -1', '', '', 'gives k=-(1/9)+(8/9)m , so s=-(1/3)+(2/3)m and t=1+2m .', 'The intersection is this.', '', '+', '(-+m)+', 'm', 'm}', '=', '+m', 'm}', '', '', '', 'Intersect each pair, if possible.', '', '+t', 't} ,\\\\,', '+s', 's}', '+t', 't} ,\\\\,', '', '+w', 's,w}', '', '', '', 'The system', '', '{1}', '1 = 1', '1+t = 3+s', '2+t = -2+2s', '', '', 'gives s=6 and t=8 , so this is the solution set.', '', '}', '', 'This system', '', '{1}', '2+t = 0', 't = s+4w', '1-t = 2s+w', '', '', 'gives t=-2 , w=-1 , and s=2 so their intersection', 'is this point.', '', '', '', '', '', '', 'How should we define ^0?', '', 'We shall later define it to be a set with one element an', \"``origin''.\", '', '', '', 'A person traveling eastward at a rate of', '3 miles per hour finds that the wind appears to blow directly', 'from the north.', 'On doubling his speed it appears to come from the north east.', \"What was the wind's velocity?\", '', '', 'The vector triangle is as follows, so =3', 'from the north west.', '', '', '(20,12)(0,0)', '(0,10){(1,0){20} }', '(0,10){(1,-1){10} }', '(3.8,5){(0,0)[r]{ } }', '(10,0){(1,1){10} }', '(10,0){(0,1){10} }', '', '', '', '', 'Euclid describes a plane as', \"``a surface which lies evenly with the straight lines on itself''.\", 'Commentators such as Heron have interpreted this to mean,', '``(A plane surface is) such that, if a straight line pass through', 'two points', \"on it, the line coincides wholly with it at every spot, all ways''.\", '(Translations from , pp. 171-172.)', 'Do planes, as described in this section, have that property?', 'Does this description adequately define planes?', '', 'Euclid no doubt is picturing a plane inside of ^3 .', 'Observe, however, that both ^1 and ^2 also satisfy', 'that definition.', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', \"We've translated the first section's results about solution sets into\", 'geometric terms, to better understand those sets.', 'But we must be careful not to be misled by our own terms', 'labeling subsets of', '^k of the forms', '+t t} and', '+t+s t,s}', \"as `lines' and `planes' doesn't make them act like the lines\", 'and planes of our past experience.', 'Rather, we must ensure that the names suit the sets.', \"While we can't prove that the sets satisfy our intuition we can't\", \"prove anything about intuition in this subsection we'll observe that\", 'a result familiar from ^2 and ^3 , when generalized to', 'arbitrary ^n , supports the idea that a line is straight', 'and a plane is flat.', \"Specifically, we'll see how to do Euclidean geometry in a `plane' by giving\", 'a definition of the angle between two ^n vectors, in the plane that they', 'generate.', '', '', '', 'The length', '', 'of a vector', '^n is the square root of the sum of the squares of its', 'components.', '', '\\\\,}=', '', '', '', '', '', 'This is a natural generalization of the Pythagorean Theorem.', 'A classic motivating discussion is in .', '', '', 'For any nonzero , the vector /}', 'has length one.', 'We say that the second', 'normalizes', 'to length one.', '', 'We can use that to get a formula', 'for the angle between two vectors.', 'Consider two vectors in ^3', 'where neither is a multiple of the other', '', '', '', '(the special case of multiples will turn out below not to be an exception).', 'They determine a two-dimensional plane', 'for instance, put them in canonical position and take the plane formed', 'by the origin and the endpoints.', 'In that plane consider the triangle with sides', ', , and - .', '', '', '', 'Apply the Law of Cosines:', '-\\\\,}^2', '=', '\\\\,}^2+\\\\,}^2-', '2\\\\,\\\\,}\\\\,\\\\,}', 'where is the angle between the vectors.', 'The left side gives', '', '(u_1-v_1)^2+(u_2-v_2)^2+(u_3-v_3)^2', '=(u_1^2-2u_1v_1+v_1^2)+(u_2^2-2u_2v_2+v_2^2)+(u_3^2-2u_3v_3+v_3^2)', '', 'while the right side gives this.', '', '(u_1^2+u_2^2+u_3^2)+(v_1^2+v_2^2+v_3^2)-', '2\\\\,\\\\,}\\\\,\\\\,}', '', 'Canceling squares u_1^2, , v_3^2 and dividing by 2 gives', 'a formula for the angle.', '', '', '=', '(\\\\,{', '\\\\,}\\\\,\\\\,} }\\\\,)', '', '', 'In higher dimensions', 'we cannot draw pictures as above but', 'we can instead make the argument analytically.', 'First, the form of the numerator is clear; it comes from the middle terms', 'of (u_i-v_i)^2 .', '', '', '', 'The dot product', '(or inner product', 'or scalar product)', 'of two n -component', 'real vectors is the linear combination of their components.', '', '=', '', '', '', 'Note that the dot product of two vectors is a real number,', 'not a vector, and', 'that the dot product is only defined if the two vectors have the same', 'number of components.', 'Note also that dot product is related to length:', '=u_1u_1++u_nu_n=\\\\,}^2 .', '', '', 'Some authors require that the first vector be a row vector and that the', 'second vector be a column vector.', 'We shall not be that strict and will allow the dot product operation between', 'two column vectors.', '', '', 'Still reasoning analytically but guided by the pictures,', 'we use the next theorem to argue that the triangle formed by', 'the line segments making the bodies of', ', , and + in ^n', 'lies in the planar subset of ^n generated by and', '(see the figure below).', '', '[Triangle Inequality]', '', '', 'For any ,^n ,', '', '+\\\\,}\\\\,}+\\\\,}', '', 'with equality if and only if one of the vectors is a nonnegative scalar', 'multiple of the other one.', '', '', '', 'This is the source of the familiar saying,', \"``The shortest distance between two points is in a straight line.''\", '', '', '', '', '', \"(We'll use some algebraic properties of dot product\", 'that we have not yet checked, for instance that', '(+)', '=+', 'and that =.', 'See .)', '', 'Since all the numbers are positive,', 'the inequality holds if and only if its square holds.', '', '+\\\\,}^2', '(\\\\,\\\\,}+\\\\,}\\\\,)^2', '(\\\\,+\\\\,)(\\\\,+\\\\,)', '\\\\,}^2+2\\\\,\\\\,}\\\\,\\\\,}', '+\\\\,}^2', '+', '++', '+2\\\\,\\\\,}\\\\,\\\\,}', '+', '2\\\\,', '2\\\\,\\\\,}\\\\,\\\\,}', '', '', '', 'That, in turn, holds if and only if', 'the relationship obtained by multiplying both sides by the nonnegative numbers', '\\\\,}', 'and \\\\,}', '', '2\\\\,(\\\\,\\\\,}\\\\,\\\\,)(\\\\,\\\\,}\\\\,\\\\,)', '', '2\\\\,\\\\,}^2\\\\,\\\\,}^2', '', 'and rewriting', '', '0', '', '\\\\,}^2\\\\,\\\\,}^2', '-2\\\\,(\\\\,\\\\,}\\\\,\\\\,)(\\\\,\\\\,}\\\\,\\\\,)', '+\\\\,}^2\\\\,\\\\,}^2', '', 'is true.', 'But factoring shows that it is true', '', '0', '(\\\\,\\\\,}\\\\,-\\\\,}\\\\,\\\\,)', '(\\\\,\\\\,}\\\\,-\\\\,}\\\\,\\\\,)', '', 'since it only says that the', 'square of the length of the vector', '\\\\,}\\\\,-\\\\,}\\\\,\\\\, is', 'not negative.', '', '', 'As for equality, it holds when, and only when,', '\\\\,}\\\\,-\\\\,}\\\\, is .', 'The check that', '\\\\,}\\\\,=\\\\,}\\\\,\\\\, if and only if', 'one vector is a nonnegative real scalar multiple of the other is easy.', '', '', '', 'This result supports the intuition that even in higher-dimensional', 'spaces, lines are straight and planes are flat.', 'We can easily check from the definition that linear surfaces have the', 'property that', 'for any two points in that surface,', 'the line segment between them is contained in that surface.', 'But if the linear surface were not flat then that would allow', 'for a shortcut.', '', '', '', 'Because the Triangle Inequality says that in any ^n the shortest cut', 'between two endpoints is simply the line segment connecting them,', 'linear surfaces have no bends.', '', 'Back to the definition of angle measure.', \"The heart of the Triangle Inequality's proof is the\", '\\\\,}\\\\,\\\\,}', 'line.', 'We might wonder if some pairs of vectors', 'satisfy the inequality in this way: while', 'is a large number, with absolute value bigger than the right-hand side,', 'it is a negative large number.', 'The next result says that does not happen.', '', '[Cauchy-Schwarz Inequality]', '', '', '', 'For any ,^n ,', '', '\\\\,}', '', '\\\\,}\\\\,\\\\,}', '', 'with equality if and only if one vector is a scalar multiple of', 'the other.', '', '', '', '', '', \"The Triangle Inequality's proof shows that\", '\\\\,}\\\\,\\\\,} so', 'if is positive or zero then we are done.', 'If is negative then this holds.', '', '\\\\,}', '=-(\\\\,\\\\,)', '=(-\\\\,)', '', '\\\\,}\\\\,\\\\,}', '=\\\\,}\\\\,\\\\,}', '', 'The equality condition is .', '', '', '', 'The Cauchy-Schwarz inequality assures us that the next definition makes sense', 'because the fraction has absolute value less than or equal to one.', '', '', '', 'The angle', 'between two nonzero vectors ,^n is', '', '', '=', '(\\\\,}{', '\\\\,}\\\\,\\\\,} }\\\\,)', '', '(if either is the zero vector then we take the angle to be a right angle).', '', '', '', '', '', 'Vectors from ^n are', 'orthogonal,', 'that is, perpendicular,', 'if and only if their dot product is zero.', 'They are parallel if and only if their dot product equals the', 'product of their lengths.', '', '', '', '', 'These vectors are orthogonal.', '', '{0.6in}', '', '', '', '=0', '', \"We've drawn the arrows away from canonical position\", 'but nevertheless the vectors are orthogonal.', '', '', '', 'The ^3 angle formula given at the start of this subsection', 'is a special case of the definition.', 'Between these two', '', '', '', 'the angle is', '', '(})', '=(})', '', 'approximately 0.94 .', 'Notice that these vectors are not orthogonal.', 'Although the yz -plane may appear to be perpendicular to the', 'xy -plane, in fact the two planes are that way only in the weak sense that', 'there are vectors in each orthogonal to all vectors in the other.', 'Not every vector in each is orthogonal to all vectors in the other.', '', '', '', '', '', '', '', '', 'Find the length of each vector.', '', '', '', '', '', '', '', '', '', '=', '', '', '0', '', '', '', '', 'Find the angle between each two, if it is defined.', '', '', ',', '', ',', '', ',', '', '', '', '(9/) 0.22', '(8/) 0.52', 'Not defined.', '', '', '', '', 'During maneuvers preceding the Battle of Jutland,', 'the British battle cruiser moved as follows (in nautical', 'miles): 1.2 miles north, 6.1 miles 38 degrees', 'east of south, 4.0 miles at 89 degrees east of', 'north, and 6.5 miles at 31 degrees east of north.', 'Find the distance between starting and ending positions.', \"(Ignore the earth's curvature.)\", '', 'We express each displacement as a vector, rounded to one', \"decimal place because that's the accuracy of the problem's statement,\", 'and add to find the total displacement', '(ignoring the curvature of the earth).', '', '', '+', '+', '+', '=', '', 'The distance is 11.3 .', '', '', 'Find k so that these two vectors are perpendicular.', '', '', '', '', '', '', 'Solve (k)(4)+(1)(3)=0 to get k=-3/4 .', '', '', 'Describe the set of vectors in ^3 orthogonal to the one', 'with entries 1, 3, and -1.', '', '', '', '', 'We could describe the set', '', '1x+3y-1z=0}', '', 'with parameters in this way.', '', 'y+z', 'y,z}', '', '', '', '', 'Find the angle between the diagonal of the unit square in', '^2 and any one of the axes.', 'Find the angle between the diagonal of the unit cube in', '^3 and one of the axes.', 'Find the angle between the diagonal of the unit cube in', '^n and one of the axes.', 'What is the limit, as n goes to ,', 'of the angle between the diagonal of the unit cube in ^n', 'and any one of the axes?', '', '', '', 'We can use the x -axis.', '', '(})', '0.79', '', 'Again, use the x -axis.', '', '(})', '0.96', '', 'The x -axis worked before and it will work again.', '', '(})', '= (})', '', 'Using the formula from the prior item,', '_{n} (1/)', '=/2.', '', '', '', 'Is any vector perpendicular to itself?', '', 'Clearly u_1u_1++u_nu_n is zero if and only if', 'each u_i is zero.', 'So only ^n is perpendicular to itself.', '', '', 'Describe the algebraic properties of dot product.', '', 'Is it right-distributive over addition:', '', '(+)', '=', '+ ?', 'Is it left-distributive (over addition)?', 'Does it commute?', 'Associate?', 'How does it interact with scalar multiplication?', '', 'As always, you must back any assertion with a suitable argument.', '', 'In each item below, assume that the vectors', ',,^n', 'have components', 'u_1,,u_n,v_1,,w_n .', '', 'Dot product is right-distributive.', '', '(+)', '=[ u_n}', '+ v_n}]', 'w_n}', '=', 'u_n+v_n}', 'w_n}', '=', '(u_1+v_1)w_1++(u_n+v_n)w_n', '=', '(u_1w_1++u_nw_n)+(v_1w_1++v_nw_n)', '=', '+', '', 'Dot product is also left distributive:', '(+)=', '+.', 'The proof is just like the prior one.', 'Dot product commutes.', '', 'u_n}', 'v_n}', '=u_1v_1++u_nv_n', '=v_1u_1++v_nu_n', '= v_n}', 'u_n}', '', 'Because', 'is a scalar, not a vector,', 'the expression () makes no', 'sense; the dot product of a scalar and a vector is not defined.', 'This is a vague question so it has many answers.', 'Some are', '(1) k()=(k)', 'and k()=(k) ,', '(2) k() (k)(k)', '(in general; an example is easy to produce), and', '(3) \\\\,}= k\\\\,}', '(the connection between', 'length and dot product is that the square of the length is the', 'dot product of a vector with itself).', '', '', '', 'Verify the equality condition in ,', 'the Cauchy-Schwarz Inequality.', '', 'Show that if is a negative scalar multiple of', 'then and', 'are less than or equal to zero.', 'Show that }=', '\\\\,}\\\\,\\\\,}', 'if and only if one vector is a scalar multiple of the other.', '', '', '', 'Verifying that', '(k)=k()', '=(k) for k and', ',^n is easy.', 'Now, for k and ,^n ,', 'if =k then', '=(k)', '=k() ,', 'which is k times a nonnegative', 'real.', '', 'The =k half is similar (actually, taking the', 'k in this paragraph to be the reciprocal of the k', 'above gives that we need only worry about the k=0 case).', 'We first consider the 0 case.', 'From the Triangle Inequality we know that', '=\\\\,}\\\\,\\\\,}', 'if and only if one vector is a nonnegative scalar multiple of the', 'other.', \"But that's all we need because the\", 'first part of this exercise shows that,', 'in a context where the dot product of the two vectors is positive,', 'the two statements', '`one vector is a', \"scalar multiple of the other' and `one vector is a nonnegative\", \"scalar multiple of the other', are equivalent.\", '', 'We finish by considering the < 0 case.', 'Because', '0<}=-()', '=(-) and', '\\\\,}\\\\,\\\\,}', '=\\\\,}\\\\,\\\\,},', 'we have that', '0<(-)=\\\\,}\\\\,\\\\,}.', 'Now the prior paragraph applies to give that one of the two vectors', '- and is a scalar multiple of the other.', \"But that's equivalent to the assertion that one of the two vectors\", 'and is a scalar multiple of the other,', 'as desired.', '', '', '', 'Suppose that =', 'and .', 'Must = ?', '', 'No.', 'These give an example.', '', '=', '', '=', '', '=', '', '', '', 'Does any vector have', 'length zero except a zero vector?', \"(If ``yes'', produce an example.\", \"If ``no'', prove it.)\", '', 'We prove that a vector has length zero if and only if all its', 'components are zero.', '', 'Let ^n have components u_1,,u_n .', 'Recall that the square of any real number is greater than or equal to', 'zero, with equality only when that real is zero.', 'Thus', '\\\\,}^2={u_1}^2++{u_n}^2 is a sum of numbers', 'greater than or equal to zero, and so is itself greater than or equal', 'to zero, with equality if and only if each u_i is zero.', 'Hence \\\\,}=0 if and only if all the components of', 'are zero.', '', '', 'Find the midpoint of the line segment connecting', '(x_1,y_1) with (x_2,y_2) in ^2 .', 'Generalize to ^n .', '', 'We can easily check that', '', '( , )', '', 'is on the line connecting the two, and is equidistant from both.', 'The generalization is obvious.', '', '', 'Show that if then', '/\\\\,} has length one.', 'What if = ?', '', 'Assume that ^n has components v_1,,v_n .', 'If then we have this.', '', '^2++{v_n}^2}})^2+', '+(^2++{v_n}^2}})^2}', '', '', '=^2}{{v_1}^2++{v_n}^2})+', '+(^2}{{v_1}^2++{v_n}^2})}', '=1', '', '', 'If = then /\\\\,} is not', 'defined.', '', '', 'Show that if r 0 then', 'r is r times as long', 'as .', 'What if r< 0 ?', '', 'For the first question, assume that ^n and', 'r 0 , take the root, and factor.', '', '\\\\,}', '=', '=^2++{v_n}^2}', '=r\\\\,}', '', 'For the second question, the result is r times as long, but it', 'points in the opposite direction in that', 'r+(-r)= .', '', '', 'A vector ^n of length one is a', 'unit vector.', 'Show that the dot product of two unit vectors has absolute value', 'less than or equal to one.', \"Can `less than' happen?\", \"Can `equal to'?\", '', 'Assume that ,^n both have length 1 .', 'Apply Cauchy-Schwarz:', '}', '\\\\,}\\\\,\\\\,}=1.', '', \"To see that `less than' can happen, in ^2 take\", '', '=', '', '=', '', 'and note that =0 .', \"For `equal to', note that =1 .\", '', '', 'When a plane does not pass through the origin, performing', 'operations on vectors whose bodies lie in it', 'is more complicated than when', 'the plane does pass through the origin.', 'Consider the picture in this subsection of the plane', '', '', '+ y', '+ z', 'y,z}', '', 'and the three vectors with endpoints', '(2,0,0), (1.5,1,0), and (1.5,0,1).', '', 'Redraw the picture, including the vector starting at (2,0,0)', 'whose body is in the plane, and that is twice as long as the vector', 'shown in the plane whose endpoint is (1.5,1,0).', 'The endpoint of this vector is not (3,2,0); what is it?', 'Redraw the picture, including the parallelogram', 'in the plane that shows the sum of the vectors', 'ending at (1.5,0,1) and (1.5,1,0).', 'The endpoint of the sum, on the diagonal, is not (3,1,1); what is it?', '', '', '', 'The vector shown', '', '', '', 'is not the result of doubling', '', '', '+ 1', '=', '', 'instead it is the result of doubling the parameter.', '', '', '+ 2', '=', '', 'This compares the lengths.', '', '', '=', '=', '=2', '', 'The vector', '', '', '', 'is not the result of adding', '', '(', '+ 1)', '+', '(', '+ 1)', '', 'instead it is', '', '', '+ 1', '+ 1', '=', '', 'which adds the parameters.', '', '', '', 'Show that the line segments', 'and', '', 'have the same lengths and slopes if', 'b_1-a_1=d_1-c_1 and b_2-a_2=d_2-c_2 .', 'Is that only if?', '', \"The ``if'' half is straightforward.\", 'If b_1-a_1=d_1-c_1 and b_2-a_2=d_2-c_2 then', '', '', '=', '', 'so they have the same lengths, and the slopes are just as easy:', '', '', '=', '', '(if the denominators are 0 they both have undefined slopes).', '', \"For ``only if'', assume that\", 'the two segments have the same length and slope', '(the case of undefined slopes is easy; we will do the case where both', 'segments have a slope m ).', 'Also assume, without loss of generality, that a_1<b_1 and that', 'c_1<d_1.', 'The first segment is', '=', '', '(for some intercept n_1)', 'and the second segment is =', '', '(for some n_2).', 'Then the lengths of those segments are', '', '', '=', '', 'and, similarly, .', 'Therefore, = .', 'Thus, as we assumed that a_1<b_1 and c_1<d_1 , we have', 'that b_1-a_1=d_1-c_1 .', '', 'The other equality is similar.', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Is', '_1++_n}', '_1}++_n} ?', 'If it is true then it would generalize the Triangle Inequality.', '', 'Yes;', 'we can prove this by induction.', '', 'Assume that the vectors are in some ^k .', 'Clearly the statement applies to one vector.', 'The Triangle Inequality is this statement applied to two vectors.', 'For an inductive step assume the statement is true for n or fewer', 'vectors.', 'Then this', '', '_1++_n+_{n+1}}', '', '_1++_n}+_{n+1}}', '', 'follows by the Triangle Inequality for two vectors.', 'Now the inductive hypothesis, applied to the first summand on the right,', 'gives that as less than or equal to', '_1}++_n}+_{n+1}} .', '', '', 'What is the ratio between the sides in the Cauchy-Schwarz inequality?', '', 'By definition', '', '}{', '\\\\,}\\\\,\\\\,}}=', '', 'where is the angle between the vectors.', 'Thus the ratio is .', '', '', 'Why is the zero vector defined to be perpendicular to every vector?', '', 'So that the statement `vectors are orthogonal iff their', \"dot product is zero' has no exceptions.\", '', '', 'Describe the angle between two vectors in ^1 .', '', 'We can find the angle between (a) and (b)', '(for a,b 0 ) with', '', '(}).', '', 'If a or b is zero then the angle is /2 radians.', 'Otherwise, if a and b are of opposite signs then the angle is', 'radians, else the angle is zero radians.', '', '', 'Give a simple necessary and sufficient condition to determine', 'whether the angle between two vectors is acute, right, or obtuse.', '', 'The angle between and is acute', 'if > 0 , is right if', '=0 , and is obtuse if', '<0 .', \"That's because, in the formula for the angle, the denominator is never\", 'negative.', '', '', 'Generalize to ^n the converse of the Pythagorean', 'Theorem, that', 'if and are', 'perpendicular then', '+\\\\,}^2=\\\\,}^2+\\\\,}^2 .', '', 'Suppose that ,^n .', 'If and are perpendicular then', '', '+\\\\,}^2', '=(+)(+)', '=+2\\\\,', '+', '=+', '=\\\\,}^2+\\\\,}^2', '', '(the third equality holds because =0 ).', '', '', 'Show that \\\\,}=\\\\,}', 'if and only if + and', '- are perpendicular.', 'Give an example in ^2 .', '', 'Where ,^n , the vectors', '+ and - are perpendicular if and', 'only if', '0=(+)(-)', '=-,', 'which shows that those two are perpendicular if and only if', '= .', 'That holds if and only if \\\\,}=\\\\,} .', '', '', 'Show that if a vector is perpendicular to each of two others then', 'it is perpendicular to each vector in the plane they generate.', '(', 'They could generate a', 'degenerate plane a line or a point but', 'the statement remains true.)', '', 'Suppose ^n is perpendicular to both', '^n and ^n .', 'Then, for any k,m we have this.', '', '(k+m)', '=k()+m()', '=k(0)+m(0)=0', '', '', '', 'Prove that, where ,^n are nonzero vectors,', 'the vector', '', '}{\\\\,} }+}{\\\\,} }', '', 'bisects the angle between them.', 'Illustrate in ^2 .', '', 'We will show something more general: if', '_1}=_2} for', '_1,_2^n , then _1+_2', 'bisects the angle between _1 and _2', '', '', '(37,12)(0,0)', '(0,0){(12,12)(0,0)', '', '(0,0){(2,1){8} }', '(0,0){(1,2){4} }', '(0,0){(1,1){12} }', '', '(8,4){(1,2){4} }', '(4,8){(2,1){8} }', '}', '(18.5,7){(0,0){ gives} }', '(25,0){(12,12)(0,0)', '', '(0,0){(2,1){8} }', '(0,0){(1,2){4} }', '(0,0){(1,1){12} }', '(8,4){(1,2){4} }', '(4,8){(2,1){8} }', '', '(2,3.8){ }', '(4.2,1.5){ }', '(5.7,5.2)(0.5,0.5){2}{ }', '(9.0,5.8)(0.5,1.0){3}{ }', '(6.6,8.7)(0.6,0.3){3}{ }', '}', '', '', '(we ignore the case where _1 and _2 are', 'the zero vector).', '', 'The _1+_2= case is easy.', 'For the rest, by the definition of angle,', 'we will be finished if we show this.', '', '_1(_1+_2)}{', '_1}\\\\,_1+_2} }', '=', '_2(_1+_2)}{', '_2}\\\\,_1+_2} }', '', 'But distributing inside each expression gives', '', '_1_1+_1_2}{', '_1}\\\\,_1+_2} }', '', '_2_1+_2_2}{', '_2}\\\\,_1+_2} }', '', 'and _1_1=_1}^2', '=_2}^2=_2_2 , so the', 'two are equal.', '', '', 'Verify that the definition of angle is dimensionally correct:', '(1) if k>0 then the cosine of the angle between k', 'and equals the cosine of the angle between', 'and , and (2) if k<0 then the cosine of the angle', 'between k and is the negative of the cosine', 'of the angle between and .', '', 'We can show the two statements together.', 'Let , ^n , write', '', '= u_n}', '', '= v_n}', '', 'and calculate.', '', '=', '{', '^2++{(ku_n)}^2}^2++{b_n}^2} }', '=}', '}{\\\\,}\\\\,\\\\,} }', '=', '}{\\\\,}\\\\,\\\\,} }', '', '', '', 'Show that the inner product operation is linear: for', ',,^n and k,m ,', '(k+m)=', 'k()+m().', '', 'Let', '', '= u_n},', '', '= v_n}', '', '= w_n}', '', 'and then', '', '(k+m)', '= u_n}', '( kv_n}', '+ mw_n} )', '= u_n}', 'kv_n+mw_n}', '=u_1(kv_1+mw_1)++u_n(kv_n+mw_n)', '=ku_1v_1+mu_1w_1++ku_nv_n+mu_nw_n', '=(ku_1v_1++ku_nv_n)+(mu_1w_1++mu_nw_n)', '=k()+m()', '', 'as required.', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Astrologers claim to be able to recognize trends in personality and', \"fortune that depend on an individual's birthday by incorporating\", 'where the stars were 2000 years ago.', '', 'Suppose that instead of star-gazers coming up with stuff, math teachers', \"who like linear algebra (we'll call them vectologers) had come up with\", 'a similar system as follows: Consider your birthday as a row vector', '}.', 'For instance, I was born on July 12 so my vector would be', '.', 'Vectologers have made the rule that how well individuals get along', 'with each other depends on the angle between vectors.', 'The smaller the angle, the more harmonious the relationship.', '', 'Find the angle between your vector and mine,', 'in radians.', 'Would you get along better with me,', 'or with a professor born on September 19?', 'For maximum harmony in a relationship,', 'when should the other person be born?', \"Is there a person with whom you have a ``worst case'' relationship,\", 'i.e., your vector and theirs are orthogonal?', 'If so, what are the birthdate(s) for such people?', 'If not, explain why not.', '', '', '', 'For instance, a birthday of October 12 gives this.', '', '', '=', '(\\\\,}{', '\\\\,}\\\\,} }\\\\,)', '=(})', '', '', 'Applying the same equation to gives', 'about 0.09 radians.', 'The angle will measure 0 radians if the other person is', 'born on the same day.', 'It will also measure 0 if one birthday is a scalar multiple', 'of the other. For instance, a person born on Mar 6 would', 'be harmonious with a person born on Feb 4.', '', 'Given a birthday, we can get', 'to plot the angle for other dates.', 'This example shows the relationship of all dates with July 12.', '', 'sage: plot3d(lambda x, y: math.acos((x*7+y*12)/(math.sqrt(7**2+12**2)*math.sqrt(x**2+y**2))),', '(1,12),(1,31))', '', '', '', '', '', 'We want to maximize this.', '', '', '=', '(\\\\,}{', '\\\\,}\\\\,} }\\\\,)', '', 'Of course, we cannot take m or d negative and so we cannot', 'get a vector orthogonal to the given one.', 'This Python script finds the largest angle by brute force.', '', 'import math', 'days={1:31, # Jan', '2:29, 3:31, 4:30, 5:31, 6:30, 7:31, 8:31, 9:30, 10:31, 11:30, 12:31}', 'BDAY=(7,12)', 'max_res=0', 'max_res_date=(-1,-1)', 'for month in range(1,13):', 'for day in range(1,days[month]+1):', 'num=BDAY[0]*month+BDAY[1]*day', 'denom=math.sqrt(BDAY[0]**2+BDAY[1]**2)*math.sqrt(month**2+day**2)', 'if denom>0:', 'res=math.acos(min(num*1.0/denom,1))', 'print \"day:\",str(month),str(day),\" angle:\",str(res)', 'if res>max_res:', 'max_res=res', 'max_res_date=(month,day)', 'print \"For \",str(BDAY),\"worst case\",str(max_res),\"rads, date\",str(max_res_date)', 'print \" That is \",180*max_res/math.pi,\"degrees\"', '', 'The result is', '', 'For (7, 12) worst case 0.95958064648 rads, date (12, 1)', 'That is 54.9799211457 degrees', '', '', 'A more conceptual approach is to consider the relation of all points', '(,) to the point (7,12).', 'The picture below', 'makes clear that the answer is either Dec 1 or Jan 31, depending', 'on which is further from the birthdate.', 'The dashed line bisects the angle between the line from the', 'origin to Dec 1, and the line from the origin to Jan 31.', 'Birthdays above the line are furthest from Dec 1 and', 'birthdays below the line are furthest from Jan 31.', '', '', '', '', '', '', '', 'A ship is sailing with speed and direction _1 ; the wind blows', 'apparently (judging by the vane on the mast) in the direction of a vector', '; on changing the direction and speed of the ship from', '_1 to _2 the apparent wind is in the direction', 'of a vector .', '', 'Find the vector velocity of the wind.', '', '', 'The actual velocity of the wind is the sum of the', \"ship's velocity and the apparent velocity of the wind.\", 'Without loss of generality we may assume and', 'to be unit vectors, and may write', '', '=_1+s=_2+t', '', 'where s and t are undetermined scalars.', 'Take the dot product first by and then by', 'to obtain', '', 's-t', '=(_2-_1)', 's-t', '=(_2-_1)', '', 'Multiply the second by ,', 'subtract the result from the first, and find', '', 's=', '-()]', '(_2-_1)', '}{1-()^2}.', '', 'Substituting in the original displayed equation, we get', '', '=_1+', '-()]', '(_2-_1)', '}{1-()^2}.', '', '', '', 'Verify the Cauchy-Schwarz inequality by first proving', \"Lagrange's identity:\", '', '(_{1 j n} a_jb_j )^2', '=', '(_{1 j n}a_j^2)', '(_{1 j n}b_j^2)', '-', '_{1 k < j n}(a_kb_j-a_jb_k)^2', '', 'and then noting that the final term is positive.', '', '', '', '', '', '', '', '', '', '', '', 'This result', 'is an improvement over Cauchy-Schwarz because it gives a formula for', 'the difference between the two sides.', 'Interpret that difference in ^2 .', '', 'We use induction on n .', '', 'In the n=1 base case the identity reduces to', '', '(a_1b_1)^2=({a_1}^2)({b_1}^2)-0', '', 'and clearly holds.', '', 'For the inductive step assume that', 'the formula holds for the 0 , , n cases.', 'We will show that it then holds in the n+1 case.', 'Start with the right-hand side', '', '( _{1 j n+1}{a_j}^2)', '( _{1 j n+1}{b_j}^2)', '-', '_{1 k<j n+1}(a_kb_j-a_jb_k)^2', '', '=', '', '', '-', '[_{1 k<j n}(a_kb_j-a_jb_k)^2+', '_{1 k n}(a_kb_{n+1}-a_{n+1}b_k)^2 ]', '=', '( _{1 j n}{a_j}^2)', '( _{1 j n}{b_j}^2)', '+', '_{1 j n}{b_j}^2{a_{n+1}}^2', '+', '_{1 j n}{a_j}^2{b_{n+1}}^2', '+', '{a_{n+1}}^2{b_{n+1}}^2', '-', '[_{1 k<j n}(a_kb_j-a_jb_k)^2+', '_{1 k n}(a_kb_{n+1}-a_{n+1}b_k)^2 ]', '=', '( _{1 j n}{a_j}^2)', '( _{1 j n}{b_j}^2)', '-_{1 k<j n}(a_kb_j-a_jb_k)^2', '+', '_{1 j n}{b_j}^2{a_{n+1}}^2', '+', '_{1 j n}{a_j}^2{b_{n+1}}^2', '+', '{a_{n+1}}^2{b_{n+1}}^2', '-', '_{1 k n}(a_kb_{n+1}-a_{n+1}b_k)^2', '', '', 'and apply the inductive hypothesis.', '', '=', '( _{1 j n}a_jb_j)^2', '+', '_{1 j n}{b_j}^2{a_{n+1}}^2', '+', '_{1 j n}{a_j}^2{b_{n+1}}^2', '+', '{a_{n+1}}^2{b_{n+1}}^2', '-', '[_{1 k n}{a_k}^2{b_{n+1}}^2', '-2_{1 k n}a_kb_{n+1}a_{n+1}b_k', '+_{1 k n}{a_{n+1}}^2{b_k}^2]', '=', '( _{1 j n}a_jb_j)^2', '+2(_{1 k n}a_kb_{n+1}a_{n+1}b_k)', '+{a_{n+1}}^2{b_{n+1}}^2', '=', '^2', '', 'to derive the left-hand side.', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(processed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6dae11aa-3eb7-4b73-828f-560e2af7fd32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    After developing the mechanics of Gauss's Method, we observed that it can be done in more than one way. For example, from this matrix  [r] 2 2 4 3   we could derive any of these three echelon form matrices.  [r] 2 2 0 -1   [r] 1 1 0 -1   [r] 2 0 0 -1   The first results from -2_1+_2. The second comes from doing (1/2)_1 and then -4_1+_2. The third comes from -2_1+_2 followed by 2_2+_1 (after the first row combination the matrix is already in echelon form but it is nonetheless a legal row operation).  In this chapter's first section we noted that this raises questions. Will any two echelon form versions of a linear system have the same number of free variables? If yes, will the two have exactly the same free variables? In this section we will give a way to decide if one linear system can be derived from another by row operations. The answers to both questions, both ``yes,'' will follow from that.            Here is an extension of Gauss's Method that has some advantages.   To solve  {3} x + y - 2z = -2 y + 3z = 7 x - z = -1   we can start as usual by reducing it to echelon form.   [r]{3} 1 1 -2 -2 0 1 3 7 0 -1 1 1   [r]{3} 1 1 -2 -2 0 1 3 7 0 0 4 8   We can keep going to a second stage by making the leading entries into 1 's   [r]{3} 1 1 -2 -2 0 1 3 7 0 0 1 2   and then to a third stage that uses the leading entries to eliminate all of the other entries in each column by combining upwards.   [r]{3} 1 1 0 2 0 1 0 1 0 0 1 2   [r]{3} 1 0 0 1 0 1 0 1 0 0 1 2   The answer is x=1 , y=1 , and z=2 .   Using one entry to clear out the rest of a column is pivoting on that entry.   Notice that the row combination operations in the first stage move left to right while the combination operations in the third stage move right to left.   The middle stage operations that turn the leading entries into 1 's don't interact so we can combine multiple ones into a single step.  [r]{2} 2 1 7 4 -2 6   [r]{2} 2 1 7 0 -4 -8   [r]{2} 1 1/2 7/2 0 1 2   [r]{2} 1 0 5/2 0 1 2   The answer is x=5/2 and y=2.    This extension of Gauss's Method is the Gauss-Jordan Method or Gauss-Jordan reduction.       A matrix or linear system is in reduced echelon form\\/ if, in addition to being in echelon form, each leading entry is a 1 and is the only nonzero entry in its column.      The cost of using Gauss-Jordan reduction to solve a system is the additional arithmetic. The benefit is that we can just read off the solution set description.   In any echelon form system, reduced or not, we can read off when the system has an empty solution set because there is a contradictory equation. We can read off when the system has a one-element solution set because there is no contradiction and every variable is the leading variable in some row. And, we can read off when the system has an infinite solution set because there is no contradiction and at least one variable is free.  However, in reduced echelon form we can read off not just the size of the solution set but also its description. We have no trouble describing the solution set when it is empty, of course. and show how in a single element solution set case the single element is in the column of constants. The next example shows how to read the parametrization of an infinite solution set.    [r]{4} 2 6 1 2 5 0 3 1 4 1 0 3 1 2 5   [r]{4} 2 6 1 2 5 0 3 1 4 1 0 0 0 -2 4     [r]{4} 1 0 -1/2 0 -9/2 0 1 1/3 0 3 0 0 0 1 -2   As a linear system this is  {4} x_1 -1/2x_3 = -9/2 x_2 +1/3x_3 = 3 {}x_4 = -2   so a solution set description is this.  S= = +x_3 x_3}    Thus, echelon form isn't some kind of one best form for systems. Other forms, such as reduced echelon form, have advantages and disadvantages. Instead of picturing linear systems (and the associated matrices) as things we operate on, always directed toward the goal of echelon form, we can think of them as interrelated, where we can get from one to another by row operations. The rest of this subsection develops this thought.    Elementary row operations are reversible.      For any matrix A , the effect of swapping rows is reversed by swapping them back, multiplying a row by a nonzero k is undone by multiplying by 1/k, and adding a multiple of row i to row j (with i j) is undone by subtracting the same multiple of row i from row j .  A   A  A   A  A   A   (We need the i j condition; see .)   Again, the point of view that we are developing, supported now by the lemma, is that the term `reduces to' is misleading: where A B , we shouldn't think of B as after A or simpler than A. Instead we should think of the two matrices as interrelated. Below is a picture. It shows the matrices from the start of this section and their reduced echelon form version in a cluster, as interreducible.      We say that matrices that reduce to each other are equivalent with respect to the relationship of row reducibility. The next result justifies this, using the definition of an equivalence.     Between matrices, `reduces to' is an equivalence re\\-la\\-tion.      We must check the conditions (i) reflexivity, that any matrix reduces to itself, (ii) symmetry, that if A reduces to B then B reduces to A , and (iii) transitivity, that if A reduces to B and B reduces to C then A reduces to C .    Reflexivity is easy; any matrix reduces to itself in zero-many operations.  The relationship is symmetric by the prior lemma if A reduces to B by some row operations then also B reduces to A by reversing those operations.    For transitivity, suppose that A reduces to B and that B reduces to C . Following the reduction steps from A B with those from B C gives a reduction from A to C .      Two matrices that are interreducible by elementary row operations are row equivalent.      The diagram below shows the collection of all matrices as a box. Inside that box each matrix lies in a class. Matrices are in the same class if and only if they are interreducible. The classes are disjoint no matrix is in two distinct classes. We have partitioned the collection of matrices into row equivalence classes.     One of the classes is the cluster of interrelated matrices from the start of this section sketched above (it includes all of the nonsingular matrices).  The next subsection proves that the reduced echelon form of a matrix is unique. Rephrased in terms of the row-equivalence relationship, we shall prove that every matrix is row equivalent to one and only one reduced echelon form matrix. In terms of the partition what we shall prove is: every equivalence class contains one and only one reduced echelon form matrix. So each reduced echelon form matrix serves as a representative of its class.    Use Gauss-Jordan reduction to solve each system.   [t]{2} x + y = 2 x - y = 0   [t]{3} x - z = 4 2x + 2y = 1   [t]{2} 3x - 2y = 1 6x + y = 1/2   [t]{3} 2x - y = -1 x + 3y - z = 5 y + 2z= 5    These answers show only the Gauss-Jordan reduction. With it, describing the solution set is easy.  The solution set contains only a single element.  [r]{2} 1 1 2 1 -1 0   [r]{2} 1 1 2 0 -2 -2   [r]{2} 1 1 2 0 1 1   [r]{2} 1 0 1 0 1 1   The solution set has one parameter.  [r]{3} 1 0 -1 4 2 2 0 1   [r]{3} 1 0 -1 4 0 2 2 -7   [r]{3} 1 0 -1 4 0 1 1 -7/2   There is a unique solution.  [r]{2} 3 -2 1 6 1 1/2   [r]{2} 3 -2 1 0 5 -3/2   [r]{2} 1 -2/31/3 0 1 -3/10   [r]{2} 1 0 2/15 0 1 -3/10   A row swap in the second step makes the arithmetic easier.  [r]{3} 2 -1 0 -1 1 3 -1 5 0 1 2 5   [r]{3} 2 -1 0 -1 0 7/2 -1 11/2 0 1 2 5    [r]{3} 2 -1 0 -1 0 1 2 5 0 7/2 -1 11/2   [r]{3} 2 -1 0 -1 0 1 2 5 0 0 -8 -12   [r]{3} 1 -1/20 -1/2 0 1 2 5 0 0 1 3/2   [r]{3} 1 -1/20 -1/2 0 1 0 2 0 0 1 3/2   [r]{3} 1 0 0 1/2 0 1 0 2 0 0 1 3/2      Do Gauss-Jordan reduction.   [t]{3} x + y - z = 3 2x - y - z = 1 3x + y + 2z = 0   [t]{3} x + y + 2z = 0 2x - y + z = 1 4x + y + 5z = 1       {3} 1 1 -1 3 2 -1 -1 1 3 1 2 0   {3} 1 1 -1 3 0 -3 1 -5 0 -2 5 -9    {3} 1 1 -1 3 0 -3 1 -5 0 0 13/3 -17/3   {3} 1 1 -1 3 0 1 -1/3 5/3 0 0 1 -17/13   {3} 1 1 0 22/13 0 1 0 16/13 0 0 1 -17/13   {3} 1 0 0 6/13 0 1 0 16/13 0 0 1 -17/13      {3} 1 1 2 0 2 -1 1 1 4 1 5 1   {3} 1 1 2 0 0 -3 -3 1 0 -3 -3 1   {3} 1 1 2 0 0 -3 -3 1 0 0 0 0   {3} 1 1 2 0 0 1 1 -1/3 0 0 0 0   {3} 1 0 1 1/3 0 1 1 -1/3 0 0 0 0      Find the reduced echelon form of each matrix.  [r] 2 1 1 3  [r] 1 3 1 2 0 4 -1 -3 -3  [r] 1 0 3 1 2 1 4 2 1 5 3 4 8 1 2  [r] 0 1 3 2 0 0 5 6 1 5 1 5    Use Gauss-Jordan reduction.  The reduced echelon form is all zeroes except for a diagonal of ones.   [r] 2 1 0 5/2   [r] 1 1/2 0 1   [r] 1 0 0 1   As in the prior problem, the reduced echelon form is all zeroes but for a diagonal of ones.   [r] 1 3 1 0 -6 2 0 0 -2   [r] 1 3 1 0 1 -1/3 0 0 1   [r] 1 3 0 0 1 0 0 0 1   [r] 1 0 0 0 1 0 0 0 1   There are more columns than rows so we must get more than just a diagonal of ones.   [r] 1 0 3 1 2 0 4 -1 0 3 0 4 -1 -2 -4   [r] 1 0 3 1 2 0 4 -1 0 3 0 0 0 -2 -7   [r] 1 0 3 1 2 0 1 -1/4 0 3/4 0 0 0 1 7/2   [r] 1 0 3 0 -3/2 0 1 -1/4 0 3/4 0 0 0 1 7/2   As in the prior item, this is not a square matrix.   [r] 1 5 1 5 0 0 5 6 0 1 3 2   [r] 1 5 1 5 0 1 3 2 0 0 5 6    [r] 1 5 1 5 0 1 3 2 0 0 1 6/5   [r] 1 5 0 19/5 0 1 0 -8/5 0 0 1 6/5   [r] 1 0 0 59/5 0 1 0 -8/5 0 0 1 6/5      Get the reduced echelon form of each.    0 2 1 2 -1 1 -2 -1 0    1 3 1 2 6 2 -1 0 0     Swap first.         1 0 0 0 1 0 0 0 1   Here the swap is in the middle.       1 0 0 0 1 1/3 0 0 0      Find each solution set by using Gauss-Jordan reduction and then reading off the parametrization.  [t]{3} 2x + y - z = 1 4x - y = 3  [t]{4} x - z = 1 y + 2z - w = 3 x + 2y + 3z - w = 7  [t]{4} x - y + z = 0 y + w = 0 3x - 2y + 3z + w = 0 -y - w = 0  [t]{5} a + 2b + 3c + d - e = 1 3a - b + c + d + e = 3    For the Gauss's halves, see the answers to Chapter One's section I.2 question .  The ``Jordan'' half goes this way.   [r]{3} 1 1/2 -1/2 1/2 0 1 -2/3 -1/3   [r]{3} 1 0 -1/6 2/3 0 1 -2/3 -1/3   The solution set is this   +z z}  The second half is   [r]{4} 1 0 -1 0 1 0 1 2 0 3 0 0 0 1 0   so the solution is this.   +z z}  This Jordan half   [r]{4} 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0   gives   +z +w z,w}  (of course, we could omit the zero vector from the description). The ``Jordan'' half   [r]{5} 1 2 3 1 -1 1 0 1 8/7 2/7 -4/7 0   [r]{5} 1 0 5/7 3/7 1/7 1 0 1 8/7 2/7 -4/7 0   ends with this solution set.   +c +d +e c,d,e}     Give two distinct echelon form versions of this matrix.  [r] 2 1 1 3 6 4 1 2 1 5 1 5    Routine Gauss's Method gives one:   [r] 2 1 1 3 0 1 -2 -7 0 9/21/27/2   [r] 2 1 1 3 0 1 -2 -7 0 0 19/2 35   and any cosmetic change, such as multiplying the bottom row by 2 ,  [r] 2 1 1 3 0 1 -2 -7 0 0 19 70   gives another.   List the reduced echelon forms possible for each size.        In the cases listed below, we take a,b. Thus, some canonical forms listed below actually include infinitely many cases. In particular, they includes the cases a=0 and b=0.   [r] 0 0 0 0 , [r] 1 a 0 0 , [r] 0 1 0 0 , [r] 1 0 0 1   [r] 0 0 0 0 0 0 , [r] 1 a b 0 0 0 , [r] 0 1 a 0 0 0 , [r] 0 0 1 0 0 0 , [r] 1 0 a 0 1 b , [r] 1 a 0 0 0 1 , [r] 0 1 0 0 0 1   [r] 0 0 0 0 0 0 , [r] 1 a 0 0 0 0 , [r] 0 1 0 0 0 0 , [r] 1 0 0 1 0 0   [r] 0 0 0 0 0 0 0 0 0 , [r] 1 a b 0 0 0 0 0 0 , [r] 0 1 a 0 0 0 0 0 0 , [r] 0 1 0 0 0 1 0 0 0 , [r] 0 0 1 0 0 0 0 0 0 , [r] 1 0 a 0 1 b 0 0 0 , [r] 1 a 0 0 0 1 0 0 0 , [r] 1 0 0 0 1 0 0 0 1     What results from applying Gauss-Jordan reduction to a nonsingular matrix?  A nonsingular homogeneous linear system has a unique solution. So a nonsingular matrix must reduce to a (square) matrix that is all 0 's except for 1 's down the upper-left to lower-right diagonal, such as these.  [r] 1 0 0 1   [r] 1 0 0 0 1 0 0 0 1    Decide whether each relation is an equivalence on the set of matrices.  two matrices are related if they have the same entry in the first row and first column   two matrices are related if they have the same entry in the first row and first column, or the same entry in the second row and second column    This is an equivalence.  We can write M_1 M_2 if they are related. The relation is reflexive because any matrix has the same 1,1 entry as itself. The relation is symmetric because if M_1 has the same 1,1 entry as M_2 then clearly also M_2 has the same 1,1 entry as M_1. Finally, the relation is transitive because if M_1 M_2 so they have the same 1,1 entry as each other, and M_2 M_3 so they have the same as each other, then all three have the same 1,1 entry, and M_1 M_3.                This is not an equivalence because it is not transitive. The first and second matrix below are related by their 1,1 entries, and the second and third are related by their 2,2 entries. But the first and third are not related.   1 0 0 0    1 0 0 -1    0 0 0 -1      Consider the following relationship on the set of matrices: we say that A is B if the sum of all of the entries in A is the same as the sum of all the entries in B. For instance, the zero matrix would be sum-what like the matrix whose first row had two sevens, and whose second row had two negative sevens. Prove or disprove that this is an equivalence relation on the set of matrices.  It is an equivalence relation. To prove that we must check that the relation is reflexive, symmetric, and transitive.  Assume that all matrices are . For reflexive, we note that a matrix has the same sum of entries as itself. For symmetric, we assume A has the same sum of entries as B and obviously then B has the same sum of entries as A. Transitivity is no harder if A has the same sum of entries as B and B has the same sum of entries as C then A has the same as C.   The proof of contains a reference to the i j condition on the row combination operation.  Write down a matrix with nonzero entries, and show that the -1_1+_1 operation is not reversed by 1_1+_1. Expand the proof of that lemma to make explicit exactly where it uses the i j condition on combining.    For instance,  [r] 1 2 3 4   [r] 0 0 3 4   [r] 0 0 3 4   leaves the matrix changed. This operation   } a_{i,1} a_{i,n} } a_{j,1} a_{j,n} }    } a_{i,1} a_{i,n} } ka_{i,1}+a_{j,1} ka_{i,n}+a_{j,n} }   leaves the i-th row unchanged because of the i j restriction. Because the i-th row is unchanged, this operation    } a_{i,1} a_{i,n} } -ka_{i,1}+ka_{i,1}+a_{j,1} -ka_{i,n}+ka_{i,n}+a_{j,n} }   returns the j-th row to its original state.      Consider the set of students in a class. Which of the following relationships are equivalence relations? Explain each answer in at least a sentence.  Two students x, y are related if x has taken at least as many math classes as y. Students x, y are related if they have names that start with the same letter.   To be an equivalence, each relation must be reflexive, symmetric, and transitive.  This relation is not symmetric because if x has taken 4 classes and y has taken 3 then x is related to y but y is not related to x. This is reflexive because x's name starts with the same letter as does x's. It is symmetric because if x's name starts with the same letter as y's then y's starts with the same letter as does x's. And it is transitive because if x's name starts with the same letter as does y's and y's name starts with the same letter as does z's then x's starts with the same letter as does z's. So it is an equivalence.    Show that each of these is an equivalence on the set of matrices. Describe the equivalence classes.  Two matrices are related if they have the same product down the diagonal, that is, if the product of the entries in the upper left and lower right are equal. Two matrices are related if they both have at least one entry that is a 1, or if neither does.   For each we must check the three conditions of reflexivity, symmetry, and transitivity.  Any matrix clearly has the same product down the diagonal as itself, so the relation is reflexive. The relation is symmetric because if A has the same product down its diagonal as does B, if a_{1,1} a_{2,2}=b_{1,1} b_{2,2}, then B has the same product as does A.  Transitivity is similar: suppose that A's product is r and that it equals B's product. Suppose also that B's product equals C's. Then all three have a product of r, and A's equals C's.  There is an equivalence class for each real number, namely the class contains all matrices whose product down the diagonal is that real. For reflexivity, if the matrix A has a 1 entry then it is related to itself while if it does not then it is also related to itself. Symmetry also has two cases: suppose that A and B are related. If A has a 1 entry then so does B, and thus B is related to A. If A has no 1 then neither does B, and again B is related to A.  For transitivity, suppose that A is related to B and B to C. If A has a 1 entry then so does B, and because B is related to C, therefore so does C, and hence A is related to C. Likewise, if A has no 1 then neither does B, and consequently neither does C, giving the conclusion that A is related to C.  There are exactly two equivalence classes, one containing any matrix that has at least one entry that is a 1, and the other containing all the matrices that have no 1's.   Show that each is not an equivalence on the set of matrices.  Two matrices A,B are related if a_{1,1}=-b_{1,1}. Two matrices are related if the sum of their entries are within 5, that is, A is related to B if ++a_{2,2})-(b_{1,1}++b_{2,2})}<5.    This relation is not reflexive. For instance, any matrix with an upper-left entry of 1 is not related to itself. This relation is not transitive. For these three, A is related to B, and B is related to C, but A is not related to C.  A= 0 0 0 0 , B= 4 0 0 0 , C= 8 0 0 0 ,                          We will close this chapter by proving that every matrix is row equivalent to one and only one reduced echelon form matrix. The ideas here will reappear, and be further developed, in the next chapter.                       The crucial observation concerns how row operations act to transform one matrix into another: the new rows are linear combinations of the old.   Consider this Gauss-Jordan reduction.  {2} 2 1 0 1 3 5   {2} 2 1 0 0 5/2 5   {2} 1 1/2 0 0 1 2  \\; {2} 1 0 -1 0 1 2   Denoting those matrices A D G B and writing the rows of A as _1 and _2, etc., we have this.  ({l} _1 _2 )  ({l} _1=_1 _2=-(1/2)_1+_2 )  ({l} _1=(1/2)_1 _2=-(1/5)_1+(2/5)_2 )  ({l} _1=(3/5)_1-(1/5)_2 _2=-(1/5)_1+(2/5)_2 )     The fact that Gaussian operations combine rows linearly also holds if there is a row swap. With this A , D , G , and B  [r] 0 2 1 1   [r] 1 1 0 2   [r] 1 1 0 1   [r] 1 0 0 1   we get these linear relationships.  ({l} _1 _2 ) \\,\\, ({l} _1 =_2 _2 =_1 ) \\,\\, ({l} _1 =_2 _2 =(1/2)_1 ) \\,\\, ({l} _1 =(-1/2)_1+1_2 _2 =(1/2)_1 )    In summary, Gauss's Method systematically finds a suitable sequence of linear combinations of the rows.              [Linear Combination Lemma]  A linear combination of linear combinations is a linear combination.      Given the set c_{1,1}x_1++c_{1,n}x_n through c_{m,1}x_1++c_{m,n}x_n of linear combinations of the x's, consider a combination of those  d_1(c_{1,1}x_1++c_{1,n}x_n)\\,++\\,d_m(c_{m,1}x_1++c_{m,n}x_n)  where the d's are scalars along with the c's. Distributing those d's and regrouping gives     =(d_1c_{1,1}++d_mc_{m,1})x_1\\,++\\,(d_1c_{1,n}++d_mc_{m,n})x_n  which is also a linear combination of the x's.       Where one matrix reduces to another, each row of the second is a linear combination of the rows of the first.                       For any two interreducible matrices A and B there is some minimum number of row operations that will take one to the other. We proceed by induction on that number.  In the base step, that we can go from one matrix to another using zero reduction operations, the two are equal. Then each row of B is trivially a combination of A's rows _i =0_1++1_i++0_m.    For the inductive step assume the inductive hypothesis: with k 0, any matrix that can be derived from A in k or fewer operations has rows that are linear combinations of A's rows. Consider a matrix B such that reducing A to B requires k+1 operations. In that reduction there is a next-to-last matrix G, so that A G B. The inductive hypothesis applies to this G because it is only k steps away from A . That is, each row of G is a linear combination of the rows of A .    We will verify that the rows of B are linear combinations of the rows of G. Then the Linear Combination Lemma, , applies to show that the rows of B are linear combinations of the rows of A.  If the row operation taking G to B is a swap then the rows of B are just the rows of G reordered and each row of B is a linear combination of the rows of G. If the operation taking G to B is multiplication of a row by a scalar c_i then _i=c_i and the other rows are unchanged. Finally, if the row operation is adding a multiple of one row to another r_i+_j then only row j of B differs from the matching row of G, and _j=r_i+_j, which is indeed a linear combinations of the rows of G.   Because we have proved both a base step and an inductive step, the proposition follows by the principle of mathematical induction.   We now have the insight that Gauss's Method builds linear combinations of the rows. But of course its goal is to end in echelon form, since that is a particularly basic version of a linear system, as it has isolated the variables. For instance, in this matrix  R=[r] 2 3 7 8 0 0 0 0 1 5 1 1 0 0 0 3 3 0 0 0 0 0 2 1   x_1 has been removed from x_5's equation. That is, Gauss's Method has made x_5's row in some way independent of x_1's row.  The following result makes this intuition precise. We sometimes refer to Gauss's Method as Gaussian elimination. What it eliminates is linear relationships among the rows.    In an echelon form matrix, no nonzero row is a linear combination of the other nonzero rows.      Let R be an echelon form matrix and consider its non- rows. First observe that if we have a row written as a combination of the others _i=c_1_1++c_{i-1}_{i-1}+ c_{i+1}_{i+1}++c_m_m then we can rewrite that equation as  =c_1_1++c_{i-1}_{i-1}+c_i_i+ c_{i+1}_{i+1}++c_m_m   where not all the coefficients are zero; specifically, c_i=-1. The converse holds also: given equation (*) where some c_i 0 we could express _i as a combination of the other rows by moving c_i_i to the left and dividing by -c_i. Therefore we will have proved the theorem if we show that in (*) all of the coefficients are 0. For that we use induction on the row number i.    The base case is the first row i=1 (if there is no such nonzero row, so that R is the zero matrix, then the lemma holds vacuously). Let _i be the column number of the leading entry in row i. Consider the entry of each row that is in column _1. Equation (*) gives this.  0=c_1r_{1,_1}+c_2r_{2,_1}++c_mr_{m,_1}   The matrix is in echelon form so every row after the first has a zero entry in that column r_{2,_1}==r_{m,_1}=0. Thus equation (**) shows that c_1=0, because r_{1,_1} 0 as it leads the row.    The inductive step is much the same as the base step. Again consider equation (*). We will prove that if the coefficient c_i is 0 for each row index i then c_{k+1} is also 0. We focus on the entries from column _{k+1}.  0=c_1r_{1,_{k+1}}++c_{k+1}r_{k+1,_{k+1}}++c_mr_{m,_{k+1}}  By the inductive hypothesis c_1, c_k are all 0 so this reduces to the equation 0=c_{k+1}r_{k+1,_{k+1}}++c_mr_{m,_{k+1}}. The matrix is in echelon form so the entries r_{k+2,_{k+1}}, , r_{m,_{k+1}} are all 0. Thus c_{k+1}=0, because r_{k+1,_{k+1}} 0 as it is the leading entry.    With that, we are ready to show that the end product of Gauss-Jordan reduction is unique.     Each matrix is row equivalent to a unique reduced echelon form matrix.      Fix a number of rows m . We will proceed by induction on the number of columns n .  The base case is that the matrix has n=1 column. If this is the zero matrix then its echelon form is the zero matrix. If instead it has any nonzero entries then when the matrix is brought to reduced echelon form it must have at least one nonzero entry, which must be a 1 in the first row. Either way, its reduced echelon form is unique.    For the inductive step we assume that n>1 and that all m row matrices having fewer than n columns have a unique reduced echelon form. Consider an matrix A and suppose that B and C are two reduced echelon form matrices derived from A . We will show that these two must be equal.    Let be the matrix consisting of the first n-1 columns of A . Observe that    any sequence of row operations that bring A to reduced echelon form will also bring to reduced echelon form. By the inductive hypothesis this reduced echelon form of is unique, so if B and C differ then the difference must occur in column n .   We finish the inductive step and the argument by showing that the two cannot differ only in that column.  Consider a homogeneous system of equations for which A is the matrix of coefficients.  {4} a_{1,1}x_1 + a_{1,2}x_2 + + a_{1,n}x_n = 0 a_{2,1}x_1 + a_{2,2}x_2 + + a_{2,n}x_n = 0  a_{m,1}x_1 + a_{m,2}x_2 + + a_{m,n}x_n = 0    By Theorem One.I.  the set of solutions to that system is the same as the set of solutions to B's system  {4} b_{1,1}x_1 + b_{1,2}x_2 + + b_{1,n}x_n = 0 b_{2,1}x_1 + b_{2,2}x_2 + + b_{2,n}x_n = 0  b_{m,1}x_1 + b_{m,2}x_2 + + b_{m,n}x_n = 0    and to C's.   {4} c_{1,1}x_1 + c_{1,2}x_2 + + c_{1,n}x_n = 0 c_{2,1}x_1 + c_{2,2}x_2 + + c_{2,n}x_n = 0  c_{m,1}x_1 + c_{m,2}x_2 + + c_{m,n}x_n = 0  }    With B and C different only in column n , suppose that they differ in row i . Subtract row i of () from row i of (**) to get the equation (b_{i,n}-c_{i,n}) x_n=0 . We've assumed that b_{i,n} c_{i,n} and so we get x_n=0. Thus x_n is not a free variable and so in (**) and () the n -th column contains the leading entry of some row, since in an echelon form matrix any column that does not contain a leading entry is associated with a free variable.  But now, with B and C equal on the first n-1 columns, by the definition of reduced echeleon form their leading entries in the n -th column are in the same row. And, both leading entries would have to be 1, and would have to be the only nonzero entries in that column. Therefore B=C .    We have asked whether any two echelon form versions of a linear system have the same number of free variables, and if so are they exactly the same variables? With the prior result we can answer both questions ``yes.'' There is no linear system such that, say, we could apply Gauss's Method one way and get y and z free but apply it another way and get y and w free.  Before the proof, recall the distinction between free variables and parameters. This system  {3} x + y = 1 y + z = 2   has one free variable, z, because it is the only variable not leading a row. We have the habit of parametrizing using the free variable y=2-z, x=-1+z, but we could also parametrize using another variable, such as z=2-y, x=1-y. So the set of parameters is not unique, it is the set of free variables that is unique.   If from a starting linear systems we derive by Gauss's Method two different echelon form systems, then the two have the same free variables.    The prior result says that the reduced echelon form is unique. We get from any echelon form version to the reduced echelon form by eliminating up, so any echelon form version of a system has the same free variables as the reduced echelon form version.   We close with a recap. In Gauss's Method we start with a matrix and then derive a sequence of other matrices. We defined two matrices to be related if we can derive one from the other. That relation is an equivalence relation, called row equivalence, and so partitions the set of all matrices into row equivalence classes.    (There are infinitely many matrices in the pictured class, but we've only got room to show two.) We have proved there is one and only one reduced echelon form matrix in each row equivalence class.  So the reduced echelon form is a canonical form=1000  for row equivalence: the reduced echelon form matrices are representatives of the classes.      The idea here is that one way to understand a mathematical situation is by being able to classify the cases that can happen. This is a theme in this book and we have seen this several times already. We classified solution sets of linear systems into the no-elements, one-element, and infinitely-many elements cases. We also classified linear systems with the same number of equations as unknowns into the nonsingular and singular cases.  Here, where we are investigating row equivalence, we know that the set of all matrices breaks into the row equivalence classes and we now have a way to put our finger on each of those classes we can think of the matrices in a class as derived by row operations from the unique reduced echelon form matrix in that class.  Put in more operational terms, uniqueness of reduced echelon form lets us answer questions about the classes by translating them into questions about the representatives. For instance, as promised in this section's opening, we now can decide whether one matrix can be derived from another by row reduction. We apply the Gauss-Jordan procedure to both and see if they yield the same reduced echelon form.   These matrices are not row equivalent  [r] 1 -3 -2 6   [r] 1 -3 -2 5   because their reduced echelon forms are not equal.  [r] 1 -3 0 0   [r] 1 0 0 1      Any nonsingular matrix Gauss-Jordan reduces to this.  [r] 1 0 0 0 1 0 0 0 1      We can describe all the classes by listing all possible reduced echelon form matrices. Any matrix lies in one of these: the class of matrices row equivalent to this,  [r] 0 0 0 0   the infinitely many classes of matrices row equivalent to one of this type   1 a 0 0   where a (including a=0), the class of matrices row equivalent to this,  [r] 0 1 0 0   and the class of matrices row equivalent to this  [r] 1 0 0 1   (this is the class of nonsingular matrices).       Decide if the matrices are row equivalent.   [r] 1 2 4 8 , [r] 0 1 1 2   [r] 1 0 2 3 -1 1 5 -1 5 , [r] 1 0 2 0 2 10 2 0 4   [r] 2 1 -1 1 1 0 4 3 -1 , [r] 1 0 2 0 2 10   [r] 1 1 1 -1 2 2 , [r] 0 3 -1 2 2 5   [r] 1 1 1 0 0 3 , [r] 0 1 2 1 -1 1    Bring each to reduced echelon form and compare.  The first gives   [r] 1 2 0 0   while the second gives   [r] 1 2 0 1   [r] 1 0 0 1   The two reduced echelon form matrices are not identical, and so the original matrices are not row equivalent. The first is this.   [r] 1 0 2 0 -1 -5 0 -1 -5   [r] 1 0 2 0 -1 -5 0 0 0   [r] 1 0 2 0 1 5 0 0 0   The second is this.   [r] 1 0 2 0 2 10 0 0 0   [r] 1 0 2 0 1 5 0 0 0   These two are row equivalent. These two are not row equivalent because they have different sizes. The first,   [r] 1 1 1 0 3 3   [r] 1 1 1 0 1 1   [r] 1 0 0 0 1 1   and the second.   [r] 2 2 5 0 3 -1   [r] 1 1 5/2 0 1 -1/3   [r] 1 0 17/6 0 1 -1/3   These are not row equivalent. Here the first is   [r] 1 1 1 0 0 1   [r] 1 1 0 0 0 1   while this is the second.   [r] 1 -1 1 0 1 2   [r] 1 0 3 0 1 2   These are not row equivalent.    Which of these matrices are row equivalent to each other?    1 3 2 4    1 5 2 10    1 -1 3 0    2 6 4 10    0 1 -1 0    3 3 2 2    Perform Gauss-Jordan reduction on each. Two matrices are row-equivalent if and only if they have the same reduced echelon form. Here is the reduced form for each.                                                                       1 0 0 1    1 5 0 0    1 0 0 1    1 0 0 1    1 0 0 1    1 1 0 0    Produce three other matrices row equivalent to the given one.    1 3 4 -1    0 1 2 1 1 1 2 3 4    For each you can just perform some row operations on the starting matrix.   Multiplying the first row by 3 gives this.   3 9 4 -1   (There is no sense to this particular choice of row operation; it is just the first thing that came to mind.) Two other row operations are a row swap _1_2 and adding _1+_2.   4 -1 1 3    1 3 5 2   Doing the same three arbitrary row operations gives these three.   0 3 6 1 1 1 2 3 4    1 1 1 0 1 2 2 3 4    0 1 2 1 2 3 2 3 4      Perform Gauss's Method on this matrix. Express each row of the final matrix as a linear combination of the rows of the starting matrix.   1 2 1 3 -1 0 0 4 0    The Gaussian reduction is routine.                 1 2 1 3 -1 0 0 4 0    1 2 1 0 -7 -3 0 4 0    1 2 1 0 -7 -3 0 0 -12/7   Denoting those matrices A, D, and B respectively, we have this.   _1 _2 _3    _1=_1 _2=-3_1+_2 _3=_3    _1=_1 _2=-3_1+_2 _3=-(12/7)_1+(4/7)_2+_3     Describe the matrices in each of the classes represented in .  First, the only matrix row equivalent to the matrix of all 0 's is itself (since row operations have no effect).  Second, the matrices that reduce to   1 a 0 0   have the form   b ba c ca   (where a,b,c , and b and c are not both zero).  Next, the matrices that reduce to  [r] 0 1 0 0   have the form   0 a 0 b   (where a,b , and not both are zero).  Finally, the matrices that reduce to  [r] 1 0 0 1   are the nonsingular matrices. That's because a linear system for which this is the matrix of coefficients will have a unique solution, and that is the definition of nonsingular. (Another way to say the same thing is to say that they fall into none of the above classes.)   Describe all matrices in the row equivalence class of these.   [r] 1 0 0 0   [r] 1 2 2 4   [r] 1 1 1 3     They have the form   a 0 b 0   where at least one of a,b is nonzero. They have this form   a 2a b 2b   where at least one of a,b is nonzero. The given matrix is nonsingular. So the row equivalence class consists of all nonsinglar matrices. (To give a formula, they have the form   a b c d   for a,b,c,d ) where ad-bc 0 . We will see in Chapter Four that this formula determines when a matrix is nonsingular.)    How many row equivalence classes are there?  Infinitely many. For instance, in   1 k 0 0   each k gives a different class.   Can row equivalence classes contain different-sized matrices?  No. Row operations do not change the size of a matrix.   How big are the row equivalence classes?  Show that for any matrix of all zeros, the class is finite. Do any other classes contain only finitely many members?    A row operation on a matrix of zeros has no effect. Thus each such matrix is alone in its row equivalence class. No. Any nonzero entry can be rescaled.    Give two reduced echelon form matrices that have their leading entries in the same columns, but that are not row equivalent.  Here are two.  [r] 1 1 0 0 0 1   [r] 1 0 0 0 0 1     Show that any two nonsingular matrices are row equivalent. Are any two singular matrices row equivalent?  Any two nonsingular matrices have the same reduced echelon form, namely the matrix with all 0 's except for 1 's down the diagonal.   1 0 0 0 1 0  0 0 1    Two same-sized singular matrices need not be row equivalent. For example, these two singular matrices are not row equivalent.  [r] 1 1 0 0   [r] 1 0 0 0     Describe all of the row equivalence classes containing these.  matrices matrices matrices matrices   Since there is one and only one reduced echelon form matrix in each class, we can just list the possible reduced echelon form matrices.  For that list, see the answer for .    Show that a vector _0 is a linear combination of members of the set _1,,_n} if and only if there is a linear relationship =c_0_0++c_n_n where c_0 is not zero. ( Watch out for the _0= case.) Use that to simplify the proof of .    If there is a linear relationship where c_0 is not zero then we can subtract c_0_0 from both sides and divide by -c_0 to get _0 as a linear combination of the others. (Remark: if there are no other vectors in the set if the relationship is, say, =3 then the statement is still true because the zero vector is by definition the sum of the empty set of vectors.)  Conversely, if _0 is a combination of the others _0=c_1_1++c_n_n then subtracting _0 from both sides gives a relationship where at least one of the coefficients is nonzero; namely, the -1 in front of _0. The first row is not a linear combination of the others for the reason given in the proof: in the equation of components from the column containing the leading entry of the first row, the only nonzero entry is the leading entry from the first row, so its coefficient must be zero. Thus, from the prior part of this exercise, the first row is in no linear relationship with the other rows.  Thus, when considering whether the second row can be in a linear relationship with the other rows, we can leave the first row out. But now the argument just applied to the first row will apply to the second row. (That is, we are arguing here by induction.)                Three truck drivers went into a roadside cafe. One truck driver purchased four sandwiches, a cup of coffee, and ten doughnuts for \\8.45. Another driver purchased three sandwiches, a cup of coffee, and seven doughnuts for \\6.30. What did the third truck driver pay for a sandwich, a cup of coffee, and a doughnut?  We know that 4s+c+10d=8.45 and that 3s+c+7d=6.30, and we'd like to know what s+c+d is. Fortunately, s+c+d is a linear combination of 4s+c+10d and 3s+c+7d. Calling the unknown price p, we have this reduction.  {3} 4 1 10 8.45 3 1 7 6.30 1 1 1 p   {3} 4 1 10 8.45 0 1/4 -1/2 -0.037\\,5 0 3/4 -3/2 p-2.112\\,5   {3} 4 1 10 8.45 0 1/4 -1/2 -0.037\\,5 0 0 0 p-2.00   The price paid is \\2.00.                              The Linear Combination Lemma says which equations can be gotten from Gaussian reduction of a given linear system.  Produce an equation not implied by this system.  {2} 3x + 4y = 8 2x + y = 3   Can any equation be derived from an inconsistent system?    An easy answer is this.  0=3  For a less wise-guy-ish answer, solve the system:  [r]{2} 3 4 8 2 1 3   [r]{2} 3 4 8 0 -5/3 -7/3   gives y=7/5 and x=4/5 . Now any equation not satisfied by (7/5,4/5) will do, e.g., 5x+5y=10 . Every equation can be derived from an inconsistent system. For instance, here is how to derive 3x+2y=4 from 0=5 . First,  0=5  0=3  0=3x  (validity of the x=0 case is separate but clear). Similarly, 0=2y . Ditto for 0=4 . But now, 0+0=0 gives 3x+2y=4 .     Extend the definition of row equivalence to linear systems. Under your definition, do equivalent systems have the same solution set?  Define linear systems to be equivalent if their augmented matrices are row equivalent. The proof that equivalent systems have the same solution set is easy.   In this matrix  [r] 1 2 3 3 0 3 1 4 5   the first and second columns add to the third.  Show that remains true under any row operation. Make a conjecture. Prove that it holds.    The three possible row swaps are easy, as are the three possible rescalings. One of the six possible row combinations is k_1+_2 :   1 2 3 k 1+3 k 2+0 k 3+3 1 4 5   and again the first and second columns add to the third. The other five combinations are similar. The obvious conjecture is that row operations do not change linear relationships among columns. A case-by-case proof follows the sketch given in the first item.   \n"
     ]
    }
   ],
   "source": [
    "pros_cont_str = ' '.join(processed_content)\n",
    "print(pros_cont_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b3634-ffa3-4884-8f7a-f5731860e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a previous pattern that worked but some staff were not adapted.\n",
    "# patterns = {\n",
    "#         r'\\\\cite\\{[^}]*\\}': '',  # Remove citations\n",
    "#         r'\\\\(begin|end)\\{[a-zA-Z]*\\*?\\}': '',  # Remove \\begin{} and \\end{} commands\n",
    "#         r'\\\\[a-zA-Z]+\\*?(?:\\[[^\\]]+\\])?(?:\\{[^}]+\\})*': '',  # Remove general LaTeX commands, adjust as needed\n",
    "#         r'%.*$': '',  # Remove comments\n",
    "#         r'\\\\\\\\': '\\n',  # Replace double backslashes with new lines\n",
    "#         # Handle vector and scalar notation\n",
    "#         r'\\\\vec\\{(\\w+)\\}': r'\\1',  # Remove vector command but keep the variable\n",
    "#         r'\\\\cdot': '·',  # Convert \\cdot to dot symbol\n",
    "#         r'\\$': '',  # Remove dollar signs that might be left from math mode\n",
    "#         r'\\\\left|\\\\right': '',  # Remove \\left and \\right modifiers\n",
    "#         r'\\\\[()|]': '',  # Remove unnecessary LaTeX symbols like brackets\n",
    "#         r'~': ' ',  # Replace tilde with space\n",
    "#         r'\\&': '',  # Remove alignment tabs used in equations\n",
    "#         r'\\n\\s*\\n': '\\n',  # Replace multiple newlines with a single one\n",
    "#         r'\\s{2,}': ' ',  # Replace multiple spaces with a single one\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36af61f3-1042-41cd-a1ff-13943638e9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
